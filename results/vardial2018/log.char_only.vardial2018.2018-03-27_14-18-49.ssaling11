############# train @ Tue Mar 27 14:18:49 CEST 2018 GPUS= HOST=ssaling11 PWD=/home/michon/projects/VarDial2018/to_export/multi_input_modular
2018-03-27 14:18:58.230670: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
2018-03-27 14:18:58.581201: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1030] Found device 0 with properties: 
name: GeForce GTX 1080 major: 6 minor: 1 memoryClockRate(GHz): 1.7335
pciBusID: 0000:01:00.0
totalMemory: 7.92GiB freeMemory: 7.81GiB
2018-03-27 14:18:58.809293: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1030] Found device 1 with properties: 
name: GeForce GTX 1080 major: 6 minor: 1 memoryClockRate(GHz): 1.7335
pciBusID: 0000:02:00.0
totalMemory: 7.92GiB freeMemory: 7.81GiB
2018-03-27 14:18:59.045082: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1030] Found device 2 with properties: 
name: GeForce GTX 1080 major: 6 minor: 1 memoryClockRate(GHz): 1.7335
pciBusID: 0000:03:00.0
totalMemory: 7.92GiB freeMemory: 7.81GiB
2018-03-27 14:18:59.277340: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1030] Found device 3 with properties: 
name: GeForce GTX 1080 major: 6 minor: 1 memoryClockRate(GHz): 1.7335
pciBusID: 0000:04:00.0
totalMemory: 7.92GiB freeMemory: 7.81GiB
2018-03-27 14:18:59.282297: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Device peer to peer matrix
2018-03-27 14:18:59.282349: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1051] DMA: 0 1 2 3 
2018-03-27 14:18:59.282355: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1061] 0:   Y Y Y Y 
2018-03-27 14:18:59.282359: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1061] 1:   Y Y Y Y 
2018-03-27 14:18:59.282362: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1061] 2:   Y Y Y Y 
2018-03-27 14:18:59.282365: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1061] 3:   Y Y Y Y 
2018-03-27 14:18:59.282374: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1120] Creating TensorFlow device (/device:GPU:0) -> (device: 0, name: GeForce GTX 1080, pci bus id: 0000:01:00.0, compute capability: 6.1)
2018-03-27 14:18:59.282379: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1120] Creating TensorFlow device (/device:GPU:1) -> (device: 1, name: GeForce GTX 1080, pci bus id: 0000:02:00.0, compute capability: 6.1)
2018-03-27 14:18:59.282383: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1120] Creating TensorFlow device (/device:GPU:2) -> (device: 2, name: GeForce GTX 1080, pci bus id: 0000:03:00.0, compute capability: 6.1)
2018-03-27 14:18:59.282387: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1120] Creating TensorFlow device (/device:GPU:3) -> (device: 3, name: GeForce GTX 1080, pci bus id: 0000:04:00.0, compute capability: 6.1)
Loading data
Data Configurations loaded
Loading data
(13806, 8)
(1509, 8)
EGY    3085
LAV    2940
NOR    2866
GLF    2707
MSA    2208
Name: Class, dtype: int64
NOR    346
LAV    327
EGY    297
MSA    280
GLF    259
Name: Class, dtype: int64
Loading vocabularies
Words
48244 48244
Phones
45 45
39 39
61 61
51 51
Generating ids
Preprocessing data
Padding character sequences
(13806, 6830)
Padding phone sequences
(13806, 5885) (13806, 7329) (13806, 6436) (13806, 6837)
Turning labels in one-hot vectors
(13806, 5)
Taking ready-made acoustic embeddings
(13806, 600)
Padding character sequences
(1509, 6830)
Padding phone sequences
(1509, 5885) (1509, 7329) (1509, 6436) (1509, 6837)
Turning labels in one-hot vectors
(1509, 5)
Taking ready-made acoustic embeddings
(1509, 600)
MultiInputCharCNN Configurations loaded
Building the model
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
sent_input (InputLayer)         (None, 6830)         0                                            
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 6830, 32)     3232        sent_input[0][0]                 
__________________________________________________________________________________________________
zero_padding1d_1 (ZeroPadding1D (None, 6834, 32)     0           embedding_1[0][0]                
__________________________________________________________________________________________________
zero_padding1d_2 (ZeroPadding1D (None, 6838, 32)     0           embedding_1[0][0]                
__________________________________________________________________________________________________
conv1d_1 (Conv1D)               (None, 6834, 8)      776         zero_padding1d_1[0][0]           
__________________________________________________________________________________________________
conv1d_2 (Conv1D)               (None, 6838, 8)      1288        zero_padding1d_2[0][0]           
__________________________________________________________________________________________________
global_max_pooling1d_1 (GlobalM (None, 8)            0           conv1d_1[0][0]                   
__________________________________________________________________________________________________
global_max_pooling1d_2 (GlobalM (None, 8)            0           conv1d_2[0][0]                   
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 16)           0           global_max_pooling1d_1[0][0]     
                                                                 global_max_pooling1d_2[0][0]     
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 32)           544         concatenate_1[0][0]              
__________________________________________________________________________________________________
l_out (Dense)                   (None, 5)            165         dense_1[0][0]                    
==================================================================================================
Total params: 6,005
Trainable params: 6,005
Non-trainable params: 0
__________________________________________________________________________________________________
Training Configurations loaded
Training the model
no checkpoints available !
Train on 13806 samples, validate on 1509 samples
Epoch 1/15

  128/13806 [..............................] - ETA: 1:58 - loss: 1.8267 - categorical_accuracy: 0.1953
  256/13806 [..............................] - ETA: 1:05 - loss: 1.8299 - categorical_accuracy: 0.1914
  384/13806 [..............................] - ETA: 47s - loss: 1.8318 - categorical_accuracy: 0.2005 
  512/13806 [>.............................] - ETA: 38s - loss: 1.8293 - categorical_accuracy: 0.2051
  640/13806 [>.............................] - ETA: 32s - loss: 1.8281 - categorical_accuracy: 0.1984
  768/13806 [>.............................] - ETA: 29s - loss: 1.8274 - categorical_accuracy: 0.1992
  896/13806 [>.............................] - ETA: 26s - loss: 1.8268 - categorical_accuracy: 0.1942
 1024/13806 [=>............................] - ETA: 24s - loss: 1.8265 - categorical_accuracy: 0.1934
 1152/13806 [=>............................] - ETA: 22s - loss: 1.8246 - categorical_accuracy: 0.1962
 1280/13806 [=>............................] - ETA: 21s - loss: 1.8239 - categorical_accuracy: 0.1906
 1408/13806 [==>...........................] - ETA: 20s - loss: 1.8228 - categorical_accuracy: 0.1939
 1536/13806 [==>...........................] - ETA: 19s - loss: 1.8221 - categorical_accuracy: 0.1979
 1664/13806 [==>...........................] - ETA: 18s - loss: 1.8207 - categorical_accuracy: 0.2025
 1792/13806 [==>...........................] - ETA: 17s - loss: 1.8206 - categorical_accuracy: 0.1987
 1920/13806 [===>..........................] - ETA: 17s - loss: 1.8187 - categorical_accuracy: 0.2052
 2048/13806 [===>..........................] - ETA: 16s - loss: 1.8179 - categorical_accuracy: 0.2041
 2176/13806 [===>..........................] - ETA: 16s - loss: 1.8163 - categorical_accuracy: 0.2091
 2304/13806 [====>.........................] - ETA: 15s - loss: 1.8163 - categorical_accuracy: 0.2075
 2432/13806 [====>.........................] - ETA: 15s - loss: 1.8156 - categorical_accuracy: 0.2048
 2560/13806 [====>.........................] - ETA: 14s - loss: 1.8146 - categorical_accuracy: 0.2066
 2688/13806 [====>.........................] - ETA: 14s - loss: 1.8137 - categorical_accuracy: 0.2072
 2816/13806 [=====>........................] - ETA: 13s - loss: 1.8128 - categorical_accuracy: 0.2088
 2944/13806 [=====>........................] - ETA: 13s - loss: 1.8119 - categorical_accuracy: 0.2092
 3072/13806 [=====>........................] - ETA: 13s - loss: 1.8110 - categorical_accuracy: 0.2113
 3200/13806 [=====>........................] - ETA: 13s - loss: 1.8103 - categorical_accuracy: 0.2103
 3328/13806 [======>.......................] - ETA: 12s - loss: 1.8091 - categorical_accuracy: 0.2133
 3456/13806 [======>.......................] - ETA: 12s - loss: 1.8083 - categorical_accuracy: 0.2133
 3584/13806 [======>.......................] - ETA: 12s - loss: 1.8077 - categorical_accuracy: 0.2126
 3712/13806 [=======>......................] - ETA: 12s - loss: 1.8069 - categorical_accuracy: 0.2139
 3840/13806 [=======>......................] - ETA: 11s - loss: 1.8060 - categorical_accuracy: 0.2146
 3968/13806 [=======>......................] - ETA: 11s - loss: 1.8047 - categorical_accuracy: 0.2172
 4096/13806 [=======>......................] - ETA: 11s - loss: 1.8037 - categorical_accuracy: 0.2168
 4224/13806 [========>.....................] - ETA: 11s - loss: 1.8026 - categorical_accuracy: 0.2178
 4352/13806 [========>.....................] - ETA: 10s - loss: 1.8016 - categorical_accuracy: 0.2201
 4480/13806 [========>.....................] - ETA: 10s - loss: 1.8005 - categorical_accuracy: 0.2205
 4608/13806 [=========>....................] - ETA: 10s - loss: 1.7995 - categorical_accuracy: 0.2207
 4736/13806 [=========>....................] - ETA: 10s - loss: 1.7985 - categorical_accuracy: 0.2211
 4864/13806 [=========>....................] - ETA: 10s - loss: 1.7979 - categorical_accuracy: 0.2212
 4992/13806 [=========>....................] - ETA: 9s - loss: 1.7973 - categorical_accuracy: 0.2218 
 5120/13806 [==========>...................] - ETA: 9s - loss: 1.7962 - categorical_accuracy: 0.2229
 5248/13806 [==========>...................] - ETA: 9s - loss: 1.7953 - categorical_accuracy: 0.2228
 5376/13806 [==========>...................] - ETA: 9s - loss: 1.7942 - categorical_accuracy: 0.2253
 5504/13806 [==========>...................] - ETA: 9s - loss: 1.7934 - categorical_accuracy: 0.2258
 5632/13806 [===========>..................] - ETA: 9s - loss: 1.7927 - categorical_accuracy: 0.2269
 5760/13806 [===========>..................] - ETA: 8s - loss: 1.7916 - categorical_accuracy: 0.2288
 5888/13806 [===========>..................] - ETA: 8s - loss: 1.7909 - categorical_accuracy: 0.2296
 6016/13806 [============>.................] - ETA: 8s - loss: 1.7900 - categorical_accuracy: 0.2302
 6144/13806 [============>.................] - ETA: 8s - loss: 1.7891 - categorical_accuracy: 0.2311
 6272/13806 [============>.................] - ETA: 8s - loss: 1.7880 - categorical_accuracy: 0.2313
 6400/13806 [============>.................] - ETA: 8s - loss: 1.7870 - categorical_accuracy: 0.2308
 6528/13806 [=============>................] - ETA: 7s - loss: 1.7862 - categorical_accuracy: 0.2321
 6656/13806 [=============>................] - ETA: 7s - loss: 1.7852 - categorical_accuracy: 0.2335
 6784/13806 [=============>................] - ETA: 7s - loss: 1.7842 - categorical_accuracy: 0.2347
 6912/13806 [==============>...............] - ETA: 7s - loss: 1.7835 - categorical_accuracy: 0.2344
 7040/13806 [==============>...............] - ETA: 7s - loss: 1.7829 - categorical_accuracy: 0.2344
 7168/13806 [==============>...............] - ETA: 7s - loss: 1.7820 - categorical_accuracy: 0.2348
 7296/13806 [==============>...............] - ETA: 6s - loss: 1.7811 - categorical_accuracy: 0.2356
 7424/13806 [===============>..............] - ETA: 6s - loss: 1.7801 - categorical_accuracy: 0.2359
 7552/13806 [===============>..............] - ETA: 6s - loss: 1.7793 - categorical_accuracy: 0.2361
 7680/13806 [===============>..............] - ETA: 6s - loss: 1.7785 - categorical_accuracy: 0.2358
 7808/13806 [===============>..............] - ETA: 6s - loss: 1.7778 - categorical_accuracy: 0.2351
 7936/13806 [================>.............] - ETA: 6s - loss: 1.7768 - categorical_accuracy: 0.2359
 8064/13806 [================>.............] - ETA: 6s - loss: 1.7760 - categorical_accuracy: 0.2362
 8192/13806 [================>.............] - ETA: 5s - loss: 1.7751 - categorical_accuracy: 0.2362
 8320/13806 [=================>............] - ETA: 5s - loss: 1.7743 - categorical_accuracy: 0.2369
 8448/13806 [=================>............] - ETA: 5s - loss: 1.7735 - categorical_accuracy: 0.2367
 8576/13806 [=================>............] - ETA: 5s - loss: 1.7727 - categorical_accuracy: 0.2366
 8704/13806 [=================>............] - ETA: 5s - loss: 1.7718 - categorical_accuracy: 0.2378
 8832/13806 [==================>...........] - ETA: 5s - loss: 1.7709 - categorical_accuracy: 0.2385
 8960/13806 [==================>...........] - ETA: 5s - loss: 1.7700 - categorical_accuracy: 0.2391
 9088/13806 [==================>...........] - ETA: 4s - loss: 1.7693 - categorical_accuracy: 0.2384
 9216/13806 [===================>..........] - ETA: 4s - loss: 1.7685 - categorical_accuracy: 0.2386
 9344/13806 [===================>..........] - ETA: 4s - loss: 1.7677 - categorical_accuracy: 0.2387
 9472/13806 [===================>..........] - ETA: 4s - loss: 1.7671 - categorical_accuracy: 0.2379
 9600/13806 [===================>..........] - ETA: 4s - loss: 1.7662 - categorical_accuracy: 0.2372
 9728/13806 [====================>.........] - ETA: 4s - loss: 1.7654 - categorical_accuracy: 0.2383
 9856/13806 [====================>.........] - ETA: 4s - loss: 1.7646 - categorical_accuracy: 0.2381
 9984/13806 [====================>.........] - ETA: 3s - loss: 1.7640 - categorical_accuracy: 0.2379
10112/13806 [====================>.........] - ETA: 3s - loss: 1.7633 - categorical_accuracy: 0.2383
10240/13806 [=====================>........] - ETA: 3s - loss: 1.7625 - categorical_accuracy: 0.2386
10368/13806 [=====================>........] - ETA: 3s - loss: 1.7618 - categorical_accuracy: 0.2389
10496/13806 [=====================>........] - ETA: 3s - loss: 1.7608 - categorical_accuracy: 0.2391
10624/13806 [======================>.......] - ETA: 3s - loss: 1.7600 - categorical_accuracy: 0.2393
10752/13806 [======================>.......] - ETA: 3s - loss: 1.7594 - categorical_accuracy: 0.2391
10880/13806 [======================>.......] - ETA: 2s - loss: 1.7586 - categorical_accuracy: 0.2391
11008/13806 [======================>.......] - ETA: 2s - loss: 1.7577 - categorical_accuracy: 0.2394
11136/13806 [=======================>......] - ETA: 2s - loss: 1.7571 - categorical_accuracy: 0.2395
11264/13806 [=======================>......] - ETA: 2s - loss: 1.7564 - categorical_accuracy: 0.2393
11392/13806 [=======================>......] - ETA: 2s - loss: 1.7558 - categorical_accuracy: 0.2393
11520/13806 [========================>.....] - ETA: 2s - loss: 1.7550 - categorical_accuracy: 0.2402
11648/13806 [========================>.....] - ETA: 2s - loss: 1.7542 - categorical_accuracy: 0.2409
11776/13806 [========================>.....] - ETA: 2s - loss: 1.7536 - categorical_accuracy: 0.2411
11904/13806 [========================>.....] - ETA: 1s - loss: 1.7529 - categorical_accuracy: 0.2416
12032/13806 [=========================>....] - ETA: 1s - loss: 1.7521 - categorical_accuracy: 0.2419
12160/13806 [=========================>....] - ETA: 1s - loss: 1.7513 - categorical_accuracy: 0.2425
12288/13806 [=========================>....] - ETA: 1s - loss: 1.7507 - categorical_accuracy: 0.2425
12416/13806 [=========================>....] - ETA: 1s - loss: 1.7500 - categorical_accuracy: 0.2428
12544/13806 [==========================>...] - ETA: 1s - loss: 1.7493 - categorical_accuracy: 0.2427
12672/13806 [==========================>...] - ETA: 1s - loss: 1.7486 - categorical_accuracy: 0.2427
12800/13806 [==========================>...] - ETA: 1s - loss: 1.7478 - categorical_accuracy: 0.2433
12928/13806 [===========================>..] - ETA: 0s - loss: 1.7472 - categorical_accuracy: 0.2436
13056/13806 [===========================>..] - ETA: 0s - loss: 1.7466 - categorical_accuracy: 0.2442
13184/13806 [===========================>..] - ETA: 0s - loss: 1.7459 - categorical_accuracy: 0.2442
13312/13806 [===========================>..] - ETA: 0s - loss: 1.7452 - categorical_accuracy: 0.2447
13440/13806 [============================>.] - ETA: 0s - loss: 1.7445 - categorical_accuracy: 0.2444
13568/13806 [============================>.] - ETA: 0s - loss: 1.7437 - categorical_accuracy: 0.2448
13696/13806 [============================>.] - ETA: 0s - loss: 1.7429 - categorical_accuracy: 0.2457
13806/13806 [==============================] - 15s 1ms/step - loss: 1.7423 - categorical_accuracy: 0.2461 - val_loss: 1.6915 - val_categorical_accuracy: 0.2001

Epoch 00001: val_categorical_accuracy improved from -inf to 0.20013, saving model to results/vardial2018/multi_input_char_only/model_weights.hdf5
Epoch 2/15

  128/13806 [..............................] - ETA: 12s - loss: 1.6690 - categorical_accuracy: 0.2500
  256/13806 [..............................] - ETA: 12s - loss: 1.6580 - categorical_accuracy: 0.2969
  384/13806 [..............................] - ETA: 12s - loss: 1.6567 - categorical_accuracy: 0.3177
  512/13806 [>.............................] - ETA: 12s - loss: 1.6587 - categorical_accuracy: 0.3086
  640/13806 [>.............................] - ETA: 12s - loss: 1.6588 - categorical_accuracy: 0.3078
  768/13806 [>.............................] - ETA: 12s - loss: 1.6552 - categorical_accuracy: 0.3138
  896/13806 [>.............................] - ETA: 12s - loss: 1.6549 - categorical_accuracy: 0.3125
 1024/13806 [=>............................] - ETA: 12s - loss: 1.6568 - categorical_accuracy: 0.3037
 1152/13806 [=>............................] - ETA: 11s - loss: 1.6577 - categorical_accuracy: 0.3012
 1280/13806 [=>............................] - ETA: 11s - loss: 1.6585 - categorical_accuracy: 0.2922
 1408/13806 [==>...........................] - ETA: 11s - loss: 1.6568 - categorical_accuracy: 0.2919
 1536/13806 [==>...........................] - ETA: 11s - loss: 1.6553 - categorical_accuracy: 0.2936
 1664/13806 [==>...........................] - ETA: 11s - loss: 1.6544 - categorical_accuracy: 0.2939
 1792/13806 [==>...........................] - ETA: 11s - loss: 1.6554 - categorical_accuracy: 0.2846
 1920/13806 [===>..........................] - ETA: 11s - loss: 1.6537 - categorical_accuracy: 0.2854
 2048/13806 [===>..........................] - ETA: 11s - loss: 1.6521 - categorical_accuracy: 0.2896
 2176/13806 [===>..........................] - ETA: 10s - loss: 1.6526 - categorical_accuracy: 0.2868
 2304/13806 [====>.........................] - ETA: 10s - loss: 1.6527 - categorical_accuracy: 0.2839
 2432/13806 [====>.........................] - ETA: 10s - loss: 1.6523 - categorical_accuracy: 0.2821
 2560/13806 [====>.........................] - ETA: 10s - loss: 1.6517 - categorical_accuracy: 0.2812
 2688/13806 [====>.........................] - ETA: 10s - loss: 1.6511 - categorical_accuracy: 0.2790
 2816/13806 [=====>........................] - ETA: 10s - loss: 1.6519 - categorical_accuracy: 0.2745
 2944/13806 [=====>........................] - ETA: 10s - loss: 1.6503 - categorical_accuracy: 0.2745
 3072/13806 [=====>........................] - ETA: 10s - loss: 1.6500 - categorical_accuracy: 0.2718
 3200/13806 [=====>........................] - ETA: 10s - loss: 1.6502 - categorical_accuracy: 0.2694
 3328/13806 [======>.......................] - ETA: 9s - loss: 1.6490 - categorical_accuracy: 0.2716 
 3456/13806 [======>.......................] - ETA: 9s - loss: 1.6491 - categorical_accuracy: 0.2723
 3584/13806 [======>.......................] - ETA: 9s - loss: 1.6494 - categorical_accuracy: 0.2709
 3712/13806 [=======>......................] - ETA: 9s - loss: 1.6489 - categorical_accuracy: 0.2724
 3840/13806 [=======>......................] - ETA: 9s - loss: 1.6487 - categorical_accuracy: 0.2724
 3968/13806 [=======>......................] - ETA: 9s - loss: 1.6485 - categorical_accuracy: 0.2742
 4096/13806 [=======>......................] - ETA: 9s - loss: 1.6481 - categorical_accuracy: 0.2747
 4224/13806 [========>.....................] - ETA: 8s - loss: 1.6475 - categorical_accuracy: 0.2727
 4352/13806 [========>.....................] - ETA: 8s - loss: 1.6471 - categorical_accuracy: 0.2746
 4480/13806 [========>.....................] - ETA: 8s - loss: 1.6468 - categorical_accuracy: 0.2757
 4608/13806 [=========>....................] - ETA: 8s - loss: 1.6468 - categorical_accuracy: 0.2754
 4736/13806 [=========>....................] - ETA: 8s - loss: 1.6462 - categorical_accuracy: 0.2753
 4864/13806 [=========>....................] - ETA: 8s - loss: 1.6457 - categorical_accuracy: 0.2759
 4992/13806 [=========>....................] - ETA: 8s - loss: 1.6452 - categorical_accuracy: 0.2768
 5120/13806 [==========>...................] - ETA: 8s - loss: 1.6448 - categorical_accuracy: 0.2770
 5248/13806 [==========>...................] - ETA: 7s - loss: 1.6451 - categorical_accuracy: 0.2763
 5376/13806 [==========>...................] - ETA: 7s - loss: 1.6452 - categorical_accuracy: 0.2744
 5504/13806 [==========>...................] - ETA: 7s - loss: 1.6444 - categorical_accuracy: 0.2762
 5632/13806 [===========>..................] - ETA: 7s - loss: 1.6440 - categorical_accuracy: 0.2768
 5760/13806 [===========>..................] - ETA: 7s - loss: 1.6441 - categorical_accuracy: 0.2773
 5888/13806 [===========>..................] - ETA: 7s - loss: 1.6440 - categorical_accuracy: 0.2780
 6016/13806 [============>.................] - ETA: 7s - loss: 1.6439 - categorical_accuracy: 0.2773
 6144/13806 [============>.................] - ETA: 7s - loss: 1.6442 - categorical_accuracy: 0.2764
 6272/13806 [============>.................] - ETA: 7s - loss: 1.6440 - categorical_accuracy: 0.2768
 6400/13806 [============>.................] - ETA: 6s - loss: 1.6428 - categorical_accuracy: 0.2784
 6528/13806 [=============>................] - ETA: 6s - loss: 1.6427 - categorical_accuracy: 0.2779
 6656/13806 [=============>................] - ETA: 6s - loss: 1.6419 - categorical_accuracy: 0.2787
 6784/13806 [=============>................] - ETA: 6s - loss: 1.6410 - categorical_accuracy: 0.2811
 6912/13806 [==============>...............] - ETA: 6s - loss: 1.6403 - categorical_accuracy: 0.2812
 7040/13806 [==============>...............] - ETA: 6s - loss: 1.6400 - categorical_accuracy: 0.2814
 7168/13806 [==============>...............] - ETA: 6s - loss: 1.6393 - categorical_accuracy: 0.2819
 7296/13806 [==============>...............] - ETA: 6s - loss: 1.6393 - categorical_accuracy: 0.2821
 7424/13806 [===============>..............] - ETA: 5s - loss: 1.6391 - categorical_accuracy: 0.2822
 7552/13806 [===============>..............] - ETA: 5s - loss: 1.6388 - categorical_accuracy: 0.2816
 7680/13806 [===============>..............] - ETA: 5s - loss: 1.6381 - categorical_accuracy: 0.2822
 7808/13806 [===============>..............] - ETA: 5s - loss: 1.6377 - categorical_accuracy: 0.2830
 7936/13806 [================>.............] - ETA: 5s - loss: 1.6372 - categorical_accuracy: 0.2830
 8064/13806 [================>.............] - ETA: 5s - loss: 1.6363 - categorical_accuracy: 0.2842
 8192/13806 [================>.............] - ETA: 5s - loss: 1.6358 - categorical_accuracy: 0.2854
 8320/13806 [=================>............] - ETA: 5s - loss: 1.6355 - categorical_accuracy: 0.2867
 8448/13806 [=================>............] - ETA: 5s - loss: 1.6350 - categorical_accuracy: 0.2866
 8576/13806 [=================>............] - ETA: 4s - loss: 1.6345 - categorical_accuracy: 0.2878
 8704/13806 [=================>............] - ETA: 4s - loss: 1.6339 - categorical_accuracy: 0.2880
 8832/13806 [==================>...........] - ETA: 4s - loss: 1.6333 - categorical_accuracy: 0.2888
 8960/13806 [==================>...........] - ETA: 4s - loss: 1.6330 - categorical_accuracy: 0.2890
 9088/13806 [==================>...........] - ETA: 4s - loss: 1.6322 - categorical_accuracy: 0.2894
 9216/13806 [===================>..........] - ETA: 4s - loss: 1.6322 - categorical_accuracy: 0.2891
 9344/13806 [===================>..........] - ETA: 4s - loss: 1.6317 - categorical_accuracy: 0.2887
 9472/13806 [===================>..........] - ETA: 4s - loss: 1.6314 - categorical_accuracy: 0.2884
 9600/13806 [===================>..........] - ETA: 3s - loss: 1.6306 - categorical_accuracy: 0.2891
 9728/13806 [====================>.........] - ETA: 3s - loss: 1.6301 - categorical_accuracy: 0.2888
 9856/13806 [====================>.........] - ETA: 3s - loss: 1.6295 - categorical_accuracy: 0.2886
 9984/13806 [====================>.........] - ETA: 3s - loss: 1.6286 - categorical_accuracy: 0.2890
10112/13806 [====================>.........] - ETA: 3s - loss: 1.6282 - categorical_accuracy: 0.2891
10240/13806 [=====================>........] - ETA: 3s - loss: 1.6280 - categorical_accuracy: 0.2886
10368/13806 [=====================>........] - ETA: 3s - loss: 1.6276 - categorical_accuracy: 0.2886
10496/13806 [=====================>........] - ETA: 3s - loss: 1.6271 - categorical_accuracy: 0.2883
10624/13806 [======================>.......] - ETA: 2s - loss: 1.6267 - categorical_accuracy: 0.2886
10752/13806 [======================>.......] - ETA: 2s - loss: 1.6261 - categorical_accuracy: 0.2888
10880/13806 [======================>.......] - ETA: 2s - loss: 1.6257 - categorical_accuracy: 0.2887
11008/13806 [======================>.......] - ETA: 2s - loss: 1.6254 - categorical_accuracy: 0.2894
11136/13806 [=======================>......] - ETA: 2s - loss: 1.6254 - categorical_accuracy: 0.2893
11264/13806 [=======================>......] - ETA: 2s - loss: 1.6248 - categorical_accuracy: 0.2902
11392/13806 [=======================>......] - ETA: 2s - loss: 1.6246 - categorical_accuracy: 0.2898
11520/13806 [========================>.....] - ETA: 2s - loss: 1.6242 - categorical_accuracy: 0.2904
11648/13806 [========================>.....] - ETA: 1s - loss: 1.6238 - categorical_accuracy: 0.2911
11776/13806 [========================>.....] - ETA: 1s - loss: 1.6233 - categorical_accuracy: 0.2912
11904/13806 [========================>.....] - ETA: 1s - loss: 1.6229 - categorical_accuracy: 0.2914
12032/13806 [=========================>....] - ETA: 1s - loss: 1.6226 - categorical_accuracy: 0.2916
12160/13806 [=========================>....] - ETA: 1s - loss: 1.6218 - categorical_accuracy: 0.2922
12288/13806 [=========================>....] - ETA: 1s - loss: 1.6213 - categorical_accuracy: 0.2926
12416/13806 [=========================>....] - ETA: 1s - loss: 1.6210 - categorical_accuracy: 0.2924
12544/13806 [==========================>...] - ETA: 1s - loss: 1.6204 - categorical_accuracy: 0.2934
12672/13806 [==========================>...] - ETA: 1s - loss: 1.6199 - categorical_accuracy: 0.2936
12800/13806 [==========================>...] - ETA: 0s - loss: 1.6191 - categorical_accuracy: 0.2941
12928/13806 [===========================>..] - ETA: 0s - loss: 1.6189 - categorical_accuracy: 0.2939
13056/13806 [===========================>..] - ETA: 0s - loss: 1.6188 - categorical_accuracy: 0.2939
13184/13806 [===========================>..] - ETA: 0s - loss: 1.6185 - categorical_accuracy: 0.2936
13312/13806 [===========================>..] - ETA: 0s - loss: 1.6184 - categorical_accuracy: 0.2936
13440/13806 [============================>.] - ETA: 0s - loss: 1.6180 - categorical_accuracy: 0.2936
13568/13806 [============================>.] - ETA: 0s - loss: 1.6176 - categorical_accuracy: 0.2940
13696/13806 [============================>.] - ETA: 0s - loss: 1.6173 - categorical_accuracy: 0.2940
13806/13806 [==============================] - 13s 955us/step - loss: 1.6169 - categorical_accuracy: 0.2947 - val_loss: 1.6437 - val_categorical_accuracy: 0.2525

Epoch 00002: val_categorical_accuracy improved from 0.20013 to 0.25249, saving model to results/vardial2018/multi_input_char_only/model_weights.hdf5
Epoch 3/15

  128/13806 [..............................] - ETA: 11s - loss: 1.5566 - categorical_accuracy: 0.3203
  256/13806 [..............................] - ETA: 11s - loss: 1.5516 - categorical_accuracy: 0.3320
  384/13806 [..............................] - ETA: 12s - loss: 1.5442 - categorical_accuracy: 0.3542
  512/13806 [>.............................] - ETA: 12s - loss: 1.5475 - categorical_accuracy: 0.3301
  640/13806 [>.............................] - ETA: 11s - loss: 1.5518 - categorical_accuracy: 0.3266
  768/13806 [>.............................] - ETA: 11s - loss: 1.5534 - categorical_accuracy: 0.3320
  896/13806 [>.............................] - ETA: 10s - loss: 1.5568 - categorical_accuracy: 0.3270
 1024/13806 [=>............................] - ETA: 10s - loss: 1.5575 - categorical_accuracy: 0.3330
 1152/13806 [=>............................] - ETA: 9s - loss: 1.5594 - categorical_accuracy: 0.3316 
 1280/13806 [=>............................] - ETA: 10s - loss: 1.5596 - categorical_accuracy: 0.3344
 1408/13806 [==>...........................] - ETA: 10s - loss: 1.5564 - categorical_accuracy: 0.3409
 1536/13806 [==>...........................] - ETA: 10s - loss: 1.5571 - categorical_accuracy: 0.3411
 1664/13806 [==>...........................] - ETA: 10s - loss: 1.5575 - categorical_accuracy: 0.3365
 1792/13806 [==>...........................] - ETA: 10s - loss: 1.5610 - categorical_accuracy: 0.3331
 1920/13806 [===>..........................] - ETA: 9s - loss: 1.5622 - categorical_accuracy: 0.3339 
 2048/13806 [===>..........................] - ETA: 9s - loss: 1.5632 - categorical_accuracy: 0.3340
 2176/13806 [===>..........................] - ETA: 9s - loss: 1.5649 - categorical_accuracy: 0.3323
 2304/13806 [====>.........................] - ETA: 9s - loss: 1.5662 - categorical_accuracy: 0.3281
 2432/13806 [====>.........................] - ETA: 9s - loss: 1.5644 - categorical_accuracy: 0.3302
 2560/13806 [====>.........................] - ETA: 9s - loss: 1.5649 - categorical_accuracy: 0.3293
 2688/13806 [====>.........................] - ETA: 9s - loss: 1.5654 - categorical_accuracy: 0.3270
 2816/13806 [=====>........................] - ETA: 9s - loss: 1.5664 - categorical_accuracy: 0.3232
 2944/13806 [=====>........................] - ETA: 9s - loss: 1.5671 - categorical_accuracy: 0.3210
 3072/13806 [=====>........................] - ETA: 8s - loss: 1.5659 - categorical_accuracy: 0.3219
 3200/13806 [=====>........................] - ETA: 8s - loss: 1.5658 - categorical_accuracy: 0.3206
 3328/13806 [======>.......................] - ETA: 8s - loss: 1.5651 - categorical_accuracy: 0.3215
 3456/13806 [======>.......................] - ETA: 8s - loss: 1.5641 - categorical_accuracy: 0.3226
 3584/13806 [======>.......................] - ETA: 8s - loss: 1.5632 - categorical_accuracy: 0.3237
 3712/13806 [=======>......................] - ETA: 8s - loss: 1.5637 - categorical_accuracy: 0.3244
 3840/13806 [=======>......................] - ETA: 8s - loss: 1.5633 - categorical_accuracy: 0.3240
 3968/13806 [=======>......................] - ETA: 8s - loss: 1.5631 - categorical_accuracy: 0.3238
 4096/13806 [=======>......................] - ETA: 8s - loss: 1.5634 - categorical_accuracy: 0.3240
 4224/13806 [========>.....................] - ETA: 8s - loss: 1.5632 - categorical_accuracy: 0.3239
 4352/13806 [========>.....................] - ETA: 8s - loss: 1.5624 - categorical_accuracy: 0.3242
 4480/13806 [========>.....................] - ETA: 8s - loss: 1.5615 - categorical_accuracy: 0.3261
 4608/13806 [=========>....................] - ETA: 8s - loss: 1.5618 - categorical_accuracy: 0.3266
 4736/13806 [=========>....................] - ETA: 7s - loss: 1.5625 - categorical_accuracy: 0.3264
 4864/13806 [=========>....................] - ETA: 7s - loss: 1.5607 - categorical_accuracy: 0.3292
 4992/13806 [=========>....................] - ETA: 7s - loss: 1.5609 - categorical_accuracy: 0.3287
 5120/13806 [==========>...................] - ETA: 7s - loss: 1.5605 - categorical_accuracy: 0.3293
 5248/13806 [==========>...................] - ETA: 7s - loss: 1.5594 - categorical_accuracy: 0.3306
 5376/13806 [==========>...................] - ETA: 7s - loss: 1.5595 - categorical_accuracy: 0.3307
 5504/13806 [==========>...................] - ETA: 7s - loss: 1.5594 - categorical_accuracy: 0.3289
 5632/13806 [===========>..................] - ETA: 7s - loss: 1.5586 - categorical_accuracy: 0.3288
 5760/13806 [===========>..................] - ETA: 7s - loss: 1.5590 - categorical_accuracy: 0.3283
 5888/13806 [===========>..................] - ETA: 6s - loss: 1.5588 - categorical_accuracy: 0.3269
 6016/13806 [============>.................] - ETA: 6s - loss: 1.5592 - categorical_accuracy: 0.3245
 6144/13806 [============>.................] - ETA: 6s - loss: 1.5582 - categorical_accuracy: 0.3250
 6272/13806 [============>.................] - ETA: 6s - loss: 1.5589 - categorical_accuracy: 0.3233
 6400/13806 [============>.................] - ETA: 6s - loss: 1.5590 - categorical_accuracy: 0.3220
 6528/13806 [=============>................] - ETA: 6s - loss: 1.5588 - categorical_accuracy: 0.3220
 6656/13806 [=============>................] - ETA: 6s - loss: 1.5584 - categorical_accuracy: 0.3217
 6784/13806 [=============>................] - ETA: 6s - loss: 1.5582 - categorical_accuracy: 0.3221
 6912/13806 [==============>...............] - ETA: 6s - loss: 1.5588 - categorical_accuracy: 0.3228
 7040/13806 [==============>...............] - ETA: 5s - loss: 1.5585 - categorical_accuracy: 0.3226
 7168/13806 [==============>...............] - ETA: 5s - loss: 1.5586 - categorical_accuracy: 0.3238
 7296/13806 [==============>...............] - ETA: 5s - loss: 1.5579 - categorical_accuracy: 0.3237
 7424/13806 [===============>..............] - ETA: 5s - loss: 1.5579 - categorical_accuracy: 0.3239
 7552/13806 [===============>..............] - ETA: 5s - loss: 1.5578 - categorical_accuracy: 0.3240
 7680/13806 [===============>..............] - ETA: 5s - loss: 1.5570 - categorical_accuracy: 0.3242
 7808/13806 [===============>..............] - ETA: 5s - loss: 1.5571 - categorical_accuracy: 0.3236
 7936/13806 [================>.............] - ETA: 5s - loss: 1.5564 - categorical_accuracy: 0.3241
 8064/13806 [================>.............] - ETA: 5s - loss: 1.5559 - categorical_accuracy: 0.3247
 8192/13806 [================>.............] - ETA: 4s - loss: 1.5558 - categorical_accuracy: 0.3246
 8320/13806 [=================>............] - ETA: 4s - loss: 1.5564 - categorical_accuracy: 0.3243
 8448/13806 [=================>............] - ETA: 4s - loss: 1.5567 - categorical_accuracy: 0.3235
 8576/13806 [=================>............] - ETA: 4s - loss: 1.5568 - categorical_accuracy: 0.3236
 8704/13806 [=================>............] - ETA: 4s - loss: 1.5565 - categorical_accuracy: 0.3236
 8832/13806 [==================>...........] - ETA: 4s - loss: 1.5563 - categorical_accuracy: 0.3228
 8960/13806 [==================>...........] - ETA: 4s - loss: 1.5552 - categorical_accuracy: 0.3243
 9088/13806 [==================>...........] - ETA: 4s - loss: 1.5557 - categorical_accuracy: 0.3238
 9216/13806 [===================>..........] - ETA: 4s - loss: 1.5555 - categorical_accuracy: 0.3244
 9344/13806 [===================>..........] - ETA: 3s - loss: 1.5554 - categorical_accuracy: 0.3245
 9472/13806 [===================>..........] - ETA: 3s - loss: 1.5553 - categorical_accuracy: 0.3247
 9600/13806 [===================>..........] - ETA: 3s - loss: 1.5554 - categorical_accuracy: 0.3241
 9728/13806 [====================>.........] - ETA: 3s - loss: 1.5561 - categorical_accuracy: 0.3233
 9856/13806 [====================>.........] - ETA: 3s - loss: 1.5553 - categorical_accuracy: 0.3239
 9984/13806 [====================>.........] - ETA: 3s - loss: 1.5553 - categorical_accuracy: 0.3236
10112/13806 [====================>.........] - ETA: 3s - loss: 1.5550 - categorical_accuracy: 0.3235
10240/13806 [=====================>........] - ETA: 3s - loss: 1.5553 - categorical_accuracy: 0.3241
10368/13806 [=====================>........] - ETA: 2s - loss: 1.5551 - categorical_accuracy: 0.3249
10496/13806 [=====================>........] - ETA: 2s - loss: 1.5546 - categorical_accuracy: 0.3249
10624/13806 [======================>.......] - ETA: 2s - loss: 1.5544 - categorical_accuracy: 0.3251
10752/13806 [======================>.......] - ETA: 2s - loss: 1.5549 - categorical_accuracy: 0.3251
10880/13806 [======================>.......] - ETA: 2s - loss: 1.5550 - categorical_accuracy: 0.3241
11008/13806 [======================>.......] - ETA: 2s - loss: 1.5546 - categorical_accuracy: 0.3242
11136/13806 [=======================>......] - ETA: 2s - loss: 1.5538 - categorical_accuracy: 0.3246
11264/13806 [=======================>......] - ETA: 2s - loss: 1.5534 - categorical_accuracy: 0.3251
11392/13806 [=======================>......] - ETA: 2s - loss: 1.5529 - categorical_accuracy: 0.3251
11520/13806 [========================>.....] - ETA: 1s - loss: 1.5528 - categorical_accuracy: 0.3247
11648/13806 [========================>.....] - ETA: 1s - loss: 1.5522 - categorical_accuracy: 0.3255
11776/13806 [========================>.....] - ETA: 1s - loss: 1.5523 - categorical_accuracy: 0.3253
11904/13806 [========================>.....] - ETA: 1s - loss: 1.5519 - categorical_accuracy: 0.3263
12032/13806 [=========================>....] - ETA: 1s - loss: 1.5518 - categorical_accuracy: 0.3264
12160/13806 [=========================>....] - ETA: 1s - loss: 1.5518 - categorical_accuracy: 0.3264
12288/13806 [=========================>....] - ETA: 1s - loss: 1.5517 - categorical_accuracy: 0.3264
12416/13806 [=========================>....] - ETA: 1s - loss: 1.5514 - categorical_accuracy: 0.3263
12544/13806 [==========================>...] - ETA: 1s - loss: 1.5513 - categorical_accuracy: 0.3263
12672/13806 [==========================>...] - ETA: 0s - loss: 1.5508 - categorical_accuracy: 0.3266
12800/13806 [==========================>...] - ETA: 0s - loss: 1.5507 - categorical_accuracy: 0.3261
12928/13806 [===========================>..] - ETA: 0s - loss: 1.5505 - categorical_accuracy: 0.3263
13056/13806 [===========================>..] - ETA: 0s - loss: 1.5499 - categorical_accuracy: 0.3269
13184/13806 [===========================>..] - ETA: 0s - loss: 1.5496 - categorical_accuracy: 0.3269
13312/13806 [===========================>..] - ETA: 0s - loss: 1.5496 - categorical_accuracy: 0.3266
13440/13806 [============================>.] - ETA: 0s - loss: 1.5494 - categorical_accuracy: 0.3266
13568/13806 [============================>.] - ETA: 0s - loss: 1.5489 - categorical_accuracy: 0.3269
13696/13806 [============================>.] - ETA: 0s - loss: 1.5491 - categorical_accuracy: 0.3268
13806/13806 [==============================] - 13s 924us/step - loss: 1.5491 - categorical_accuracy: 0.3262 - val_loss: 1.6177 - val_categorical_accuracy: 0.2903

Epoch 00003: val_categorical_accuracy improved from 0.25249 to 0.29026, saving model to results/vardial2018/multi_input_char_only/model_weights.hdf5
Epoch 4/15

  128/13806 [..............................] - ETA: 11s - loss: 1.5317 - categorical_accuracy: 0.3672
  256/13806 [..............................] - ETA: 11s - loss: 1.5301 - categorical_accuracy: 0.3633
  384/13806 [..............................] - ETA: 12s - loss: 1.5204 - categorical_accuracy: 0.3646
  512/13806 [>.............................] - ETA: 11s - loss: 1.5242 - categorical_accuracy: 0.3594
  640/13806 [>.............................] - ETA: 11s - loss: 1.5245 - categorical_accuracy: 0.3516
  768/13806 [>.............................] - ETA: 11s - loss: 1.5213 - categorical_accuracy: 0.3464
  896/13806 [>.............................] - ETA: 11s - loss: 1.5212 - categorical_accuracy: 0.3527
 1024/13806 [=>............................] - ETA: 11s - loss: 1.5191 - categorical_accuracy: 0.3516
 1152/13806 [=>............................] - ETA: 11s - loss: 1.5143 - categorical_accuracy: 0.3585
 1280/13806 [=>............................] - ETA: 11s - loss: 1.5159 - categorical_accuracy: 0.3492
 1408/13806 [==>...........................] - ETA: 11s - loss: 1.5149 - categorical_accuracy: 0.3466
 1536/13806 [==>...........................] - ETA: 11s - loss: 1.5127 - categorical_accuracy: 0.3490
 1664/13806 [==>...........................] - ETA: 11s - loss: 1.5138 - categorical_accuracy: 0.3504
 1792/13806 [==>...........................] - ETA: 11s - loss: 1.5157 - categorical_accuracy: 0.3415
 1920/13806 [===>..........................] - ETA: 11s - loss: 1.5163 - categorical_accuracy: 0.3380
 2048/13806 [===>..........................] - ETA: 10s - loss: 1.5176 - categorical_accuracy: 0.3379
 2176/13806 [===>..........................] - ETA: 10s - loss: 1.5168 - categorical_accuracy: 0.3382
 2304/13806 [====>.........................] - ETA: 10s - loss: 1.5170 - categorical_accuracy: 0.3385
 2432/13806 [====>.........................] - ETA: 10s - loss: 1.5180 - categorical_accuracy: 0.3335
 2560/13806 [====>.........................] - ETA: 10s - loss: 1.5182 - categorical_accuracy: 0.3324
 2688/13806 [====>.........................] - ETA: 10s - loss: 1.5185 - categorical_accuracy: 0.3315
 2816/13806 [=====>........................] - ETA: 10s - loss: 1.5173 - categorical_accuracy: 0.3324
 2944/13806 [=====>........................] - ETA: 10s - loss: 1.5158 - categorical_accuracy: 0.3329
 3072/13806 [=====>........................] - ETA: 10s - loss: 1.5141 - categorical_accuracy: 0.3350
 3200/13806 [=====>........................] - ETA: 9s - loss: 1.5159 - categorical_accuracy: 0.3316 
 3328/13806 [======>.......................] - ETA: 9s - loss: 1.5150 - categorical_accuracy: 0.3311
 3456/13806 [======>.......................] - ETA: 9s - loss: 1.5135 - categorical_accuracy: 0.3325
 3584/13806 [======>.......................] - ETA: 9s - loss: 1.5132 - categorical_accuracy: 0.3348
 3712/13806 [=======>......................] - ETA: 9s - loss: 1.5132 - categorical_accuracy: 0.3359
 3840/13806 [=======>......................] - ETA: 9s - loss: 1.5139 - categorical_accuracy: 0.3346
 3968/13806 [=======>......................] - ETA: 9s - loss: 1.5114 - categorical_accuracy: 0.3359
 4096/13806 [=======>......................] - ETA: 9s - loss: 1.5137 - categorical_accuracy: 0.3335
 4224/13806 [========>.....................] - ETA: 8s - loss: 1.5140 - categorical_accuracy: 0.3343
 4352/13806 [========>.....................] - ETA: 8s - loss: 1.5132 - categorical_accuracy: 0.3350
 4480/13806 [========>.....................] - ETA: 8s - loss: 1.5124 - categorical_accuracy: 0.3346
 4608/13806 [=========>....................] - ETA: 8s - loss: 1.5121 - categorical_accuracy: 0.3359
 4736/13806 [=========>....................] - ETA: 8s - loss: 1.5135 - categorical_accuracy: 0.3342
 4864/13806 [=========>....................] - ETA: 8s - loss: 1.5124 - categorical_accuracy: 0.3361
 4992/13806 [=========>....................] - ETA: 8s - loss: 1.5117 - categorical_accuracy: 0.3373
 5120/13806 [==========>...................] - ETA: 8s - loss: 1.5129 - categorical_accuracy: 0.3381
 5248/13806 [==========>...................] - ETA: 8s - loss: 1.5134 - categorical_accuracy: 0.3382
 5376/13806 [==========>...................] - ETA: 7s - loss: 1.5143 - categorical_accuracy: 0.3382
 5504/13806 [==========>...................] - ETA: 7s - loss: 1.5147 - categorical_accuracy: 0.3378
 5632/13806 [===========>..................] - ETA: 7s - loss: 1.5136 - categorical_accuracy: 0.3390
 5760/13806 [===========>..................] - ETA: 7s - loss: 1.5146 - categorical_accuracy: 0.3378
 5888/13806 [===========>..................] - ETA: 7s - loss: 1.5155 - categorical_accuracy: 0.3373
 6016/13806 [============>.................] - ETA: 7s - loss: 1.5148 - categorical_accuracy: 0.3378
 6144/13806 [============>.................] - ETA: 7s - loss: 1.5150 - categorical_accuracy: 0.3382
 6272/13806 [============>.................] - ETA: 7s - loss: 1.5154 - categorical_accuracy: 0.3380
 6400/13806 [============>.................] - ETA: 6s - loss: 1.5158 - categorical_accuracy: 0.3375
 6528/13806 [=============>................] - ETA: 6s - loss: 1.5154 - categorical_accuracy: 0.3372
 6656/13806 [=============>................] - ETA: 6s - loss: 1.5167 - categorical_accuracy: 0.3352
 6784/13806 [=============>................] - ETA: 6s - loss: 1.5156 - categorical_accuracy: 0.3374
 6912/13806 [==============>...............] - ETA: 6s - loss: 1.5160 - categorical_accuracy: 0.3371
 7040/13806 [==============>...............] - ETA: 6s - loss: 1.5156 - categorical_accuracy: 0.3381
 7168/13806 [==============>...............] - ETA: 6s - loss: 1.5154 - categorical_accuracy: 0.3387
 7296/13806 [==============>...............] - ETA: 6s - loss: 1.5148 - categorical_accuracy: 0.3391
 7424/13806 [===============>..............] - ETA: 5s - loss: 1.5146 - categorical_accuracy: 0.3392
 7552/13806 [===============>..............] - ETA: 5s - loss: 1.5148 - categorical_accuracy: 0.3392
 7680/13806 [===============>..............] - ETA: 5s - loss: 1.5152 - categorical_accuracy: 0.3396
 7808/13806 [===============>..............] - ETA: 5s - loss: 1.5142 - categorical_accuracy: 0.3411
 7936/13806 [================>.............] - ETA: 5s - loss: 1.5137 - categorical_accuracy: 0.3422
 8064/13806 [================>.............] - ETA: 5s - loss: 1.5143 - categorical_accuracy: 0.3410
 8192/13806 [================>.............] - ETA: 5s - loss: 1.5135 - categorical_accuracy: 0.3419
 8320/13806 [=================>............] - ETA: 5s - loss: 1.5132 - categorical_accuracy: 0.3421
 8448/13806 [=================>............] - ETA: 4s - loss: 1.5134 - categorical_accuracy: 0.3426
 8576/13806 [=================>............] - ETA: 4s - loss: 1.5132 - categorical_accuracy: 0.3420
 8704/13806 [=================>............] - ETA: 4s - loss: 1.5134 - categorical_accuracy: 0.3417
 8832/13806 [==================>...........] - ETA: 4s - loss: 1.5133 - categorical_accuracy: 0.3419
 8960/13806 [==================>...........] - ETA: 4s - loss: 1.5133 - categorical_accuracy: 0.3410
 9088/13806 [==================>...........] - ETA: 4s - loss: 1.5135 - categorical_accuracy: 0.3412
 9216/13806 [===================>..........] - ETA: 4s - loss: 1.5128 - categorical_accuracy: 0.3414
 9344/13806 [===================>..........] - ETA: 4s - loss: 1.5122 - categorical_accuracy: 0.3426
 9472/13806 [===================>..........] - ETA: 3s - loss: 1.5120 - categorical_accuracy: 0.3428
 9600/13806 [===================>..........] - ETA: 3s - loss: 1.5122 - categorical_accuracy: 0.3426
 9728/13806 [====================>.........] - ETA: 3s - loss: 1.5121 - categorical_accuracy: 0.3426
 9856/13806 [====================>.........] - ETA: 3s - loss: 1.5124 - categorical_accuracy: 0.3435
 9984/13806 [====================>.........] - ETA: 3s - loss: 1.5125 - categorical_accuracy: 0.3443
10112/13806 [====================>.........] - ETA: 3s - loss: 1.5125 - categorical_accuracy: 0.3441
10240/13806 [=====================>........] - ETA: 3s - loss: 1.5122 - categorical_accuracy: 0.3442
10368/13806 [=====================>........] - ETA: 3s - loss: 1.5120 - categorical_accuracy: 0.3439
10496/13806 [=====================>........] - ETA: 3s - loss: 1.5116 - categorical_accuracy: 0.3444
10624/13806 [======================>.......] - ETA: 2s - loss: 1.5120 - categorical_accuracy: 0.3446
10752/13806 [======================>.......] - ETA: 2s - loss: 1.5119 - categorical_accuracy: 0.3449
10880/13806 [======================>.......] - ETA: 2s - loss: 1.5125 - categorical_accuracy: 0.3446
11008/13806 [======================>.......] - ETA: 2s - loss: 1.5124 - categorical_accuracy: 0.3448
11136/13806 [=======================>......] - ETA: 2s - loss: 1.5125 - categorical_accuracy: 0.3442
11264/13806 [=======================>......] - ETA: 2s - loss: 1.5131 - categorical_accuracy: 0.3438
11392/13806 [=======================>......] - ETA: 2s - loss: 1.5133 - categorical_accuracy: 0.3438
11520/13806 [========================>.....] - ETA: 2s - loss: 1.5139 - categorical_accuracy: 0.3434
11648/13806 [========================>.....] - ETA: 1s - loss: 1.5143 - categorical_accuracy: 0.3428
11776/13806 [========================>.....] - ETA: 1s - loss: 1.5136 - categorical_accuracy: 0.3437
11904/13806 [========================>.....] - ETA: 1s - loss: 1.5134 - categorical_accuracy: 0.3441
12032/13806 [=========================>....] - ETA: 1s - loss: 1.5130 - categorical_accuracy: 0.3443
12160/13806 [=========================>....] - ETA: 1s - loss: 1.5128 - categorical_accuracy: 0.3443
12288/13806 [=========================>....] - ETA: 1s - loss: 1.5128 - categorical_accuracy: 0.3445
12416/13806 [=========================>....] - ETA: 1s - loss: 1.5131 - categorical_accuracy: 0.3442
12544/13806 [==========================>...] - ETA: 1s - loss: 1.5134 - categorical_accuracy: 0.3441
12672/13806 [==========================>...] - ETA: 1s - loss: 1.5132 - categorical_accuracy: 0.3447
12800/13806 [==========================>...] - ETA: 0s - loss: 1.5133 - categorical_accuracy: 0.3441
12928/13806 [===========================>..] - ETA: 0s - loss: 1.5129 - categorical_accuracy: 0.3442
13056/13806 [===========================>..] - ETA: 0s - loss: 1.5126 - categorical_accuracy: 0.3441
13184/13806 [===========================>..] - ETA: 0s - loss: 1.5121 - categorical_accuracy: 0.3447
13312/13806 [===========================>..] - ETA: 0s - loss: 1.5120 - categorical_accuracy: 0.3449
13440/13806 [============================>.] - ETA: 0s - loss: 1.5116 - categorical_accuracy: 0.3452
13568/13806 [============================>.] - ETA: 0s - loss: 1.5115 - categorical_accuracy: 0.3454
13696/13806 [============================>.] - ETA: 0s - loss: 1.5112 - categorical_accuracy: 0.3454
13806/13806 [==============================] - 14s 987us/step - loss: 1.5113 - categorical_accuracy: 0.3451 - val_loss: 1.6270 - val_categorical_accuracy: 0.2783

Epoch 00004: val_categorical_accuracy did not improve
Epoch 5/15

  128/13806 [..............................] - ETA: 9s - loss: 1.4041 - categorical_accuracy: 0.3984
  256/13806 [..............................] - ETA: 11s - loss: 1.4541 - categorical_accuracy: 0.3984
  384/13806 [..............................] - ETA: 11s - loss: 1.4524 - categorical_accuracy: 0.4010
  512/13806 [>.............................] - ETA: 11s - loss: 1.4636 - categorical_accuracy: 0.3867
  640/13806 [>.............................] - ETA: 11s - loss: 1.4716 - categorical_accuracy: 0.3812
  768/13806 [>.............................] - ETA: 11s - loss: 1.4664 - categorical_accuracy: 0.3841
  896/13806 [>.............................] - ETA: 11s - loss: 1.4680 - categorical_accuracy: 0.3862
 1024/13806 [=>............................] - ETA: 11s - loss: 1.4738 - categorical_accuracy: 0.3809
 1152/13806 [=>............................] - ETA: 11s - loss: 1.4748 - categorical_accuracy: 0.3733
 1280/13806 [=>............................] - ETA: 11s - loss: 1.4779 - categorical_accuracy: 0.3742
 1408/13806 [==>...........................] - ETA: 11s - loss: 1.4758 - categorical_accuracy: 0.3793
 1536/13806 [==>...........................] - ETA: 11s - loss: 1.4734 - categorical_accuracy: 0.3789
 1664/13806 [==>...........................] - ETA: 11s - loss: 1.4766 - categorical_accuracy: 0.3774
 1792/13806 [==>...........................] - ETA: 11s - loss: 1.4809 - categorical_accuracy: 0.3728
 1920/13806 [===>..........................] - ETA: 10s - loss: 1.4848 - categorical_accuracy: 0.3677
 2048/13806 [===>..........................] - ETA: 10s - loss: 1.4840 - categorical_accuracy: 0.3716
 2176/13806 [===>..........................] - ETA: 10s - loss: 1.4827 - categorical_accuracy: 0.3709
 2304/13806 [====>.........................] - ETA: 10s - loss: 1.4844 - categorical_accuracy: 0.3659
 2432/13806 [====>.........................] - ETA: 10s - loss: 1.4865 - categorical_accuracy: 0.3651
 2560/13806 [====>.........................] - ETA: 9s - loss: 1.4857 - categorical_accuracy: 0.3621 
 2688/13806 [====>.........................] - ETA: 9s - loss: 1.4868 - categorical_accuracy: 0.3631
 2816/13806 [=====>........................] - ETA: 9s - loss: 1.4871 - categorical_accuracy: 0.3640
 2944/13806 [=====>........................] - ETA: 9s - loss: 1.4890 - categorical_accuracy: 0.3631
 3072/13806 [=====>........................] - ETA: 9s - loss: 1.4888 - categorical_accuracy: 0.3613
 3200/13806 [=====>........................] - ETA: 9s - loss: 1.4895 - categorical_accuracy: 0.3600
 3328/13806 [======>.......................] - ETA: 9s - loss: 1.4888 - categorical_accuracy: 0.3600
 3456/13806 [======>.......................] - ETA: 9s - loss: 1.4889 - categorical_accuracy: 0.3591
 3584/13806 [======>.......................] - ETA: 8s - loss: 1.4870 - categorical_accuracy: 0.3608
 3712/13806 [=======>......................] - ETA: 8s - loss: 1.4874 - categorical_accuracy: 0.3588
 3840/13806 [=======>......................] - ETA: 8s - loss: 1.4875 - categorical_accuracy: 0.3586
 3968/13806 [=======>......................] - ETA: 8s - loss: 1.4882 - categorical_accuracy: 0.3584
 4096/13806 [=======>......................] - ETA: 8s - loss: 1.4875 - categorical_accuracy: 0.3601
 4224/13806 [========>.....................] - ETA: 8s - loss: 1.4887 - categorical_accuracy: 0.3594
 4352/13806 [========>.....................] - ETA: 8s - loss: 1.4883 - categorical_accuracy: 0.3591
 4480/13806 [========>.....................] - ETA: 7s - loss: 1.4885 - categorical_accuracy: 0.3594
 4608/13806 [=========>....................] - ETA: 7s - loss: 1.4899 - categorical_accuracy: 0.3583
 4736/13806 [=========>....................] - ETA: 7s - loss: 1.4903 - categorical_accuracy: 0.3575
 4864/13806 [=========>....................] - ETA: 7s - loss: 1.4883 - categorical_accuracy: 0.3598
 4992/13806 [=========>....................] - ETA: 7s - loss: 1.4874 - categorical_accuracy: 0.3608
 5120/13806 [==========>...................] - ETA: 7s - loss: 1.4891 - categorical_accuracy: 0.3604
 5248/13806 [==========>...................] - ETA: 7s - loss: 1.4891 - categorical_accuracy: 0.3607
 5376/13806 [==========>...................] - ETA: 7s - loss: 1.4897 - categorical_accuracy: 0.3590
 5504/13806 [==========>...................] - ETA: 7s - loss: 1.4909 - categorical_accuracy: 0.3597
 5632/13806 [===========>..................] - ETA: 7s - loss: 1.4907 - categorical_accuracy: 0.3578
 5760/13806 [===========>..................] - ETA: 6s - loss: 1.4911 - categorical_accuracy: 0.3571
 5888/13806 [===========>..................] - ETA: 6s - loss: 1.4899 - categorical_accuracy: 0.3573
 6016/13806 [============>.................] - ETA: 6s - loss: 1.4903 - categorical_accuracy: 0.3559
 6144/13806 [============>.................] - ETA: 6s - loss: 1.4894 - categorical_accuracy: 0.3563
 6272/13806 [============>.................] - ETA: 6s - loss: 1.4902 - categorical_accuracy: 0.3555
 6400/13806 [============>.................] - ETA: 6s - loss: 1.4900 - categorical_accuracy: 0.3558
 6528/13806 [=============>................] - ETA: 6s - loss: 1.4914 - categorical_accuracy: 0.3548
 6656/13806 [=============>................] - ETA: 6s - loss: 1.4903 - categorical_accuracy: 0.3547
 6784/13806 [=============>................] - ETA: 6s - loss: 1.4906 - categorical_accuracy: 0.3545
 6912/13806 [==============>...............] - ETA: 6s - loss: 1.4902 - categorical_accuracy: 0.3552
 7040/13806 [==============>...............] - ETA: 5s - loss: 1.4891 - categorical_accuracy: 0.3561
 7168/13806 [==============>...............] - ETA: 5s - loss: 1.4888 - categorical_accuracy: 0.3564
 7296/13806 [==============>...............] - ETA: 5s - loss: 1.4880 - categorical_accuracy: 0.3581
 7424/13806 [===============>..............] - ETA: 5s - loss: 1.4884 - categorical_accuracy: 0.3584
 7552/13806 [===============>..............] - ETA: 5s - loss: 1.4881 - categorical_accuracy: 0.3584
 7680/13806 [===============>..............] - ETA: 5s - loss: 1.4888 - categorical_accuracy: 0.3587
 7808/13806 [===============>..............] - ETA: 5s - loss: 1.4883 - categorical_accuracy: 0.3584
 7936/13806 [================>.............] - ETA: 5s - loss: 1.4890 - categorical_accuracy: 0.3569
 8064/13806 [================>.............] - ETA: 5s - loss: 1.4892 - categorical_accuracy: 0.3568
 8192/13806 [================>.............] - ETA: 4s - loss: 1.4899 - categorical_accuracy: 0.3563
 8320/13806 [=================>............] - ETA: 4s - loss: 1.4896 - categorical_accuracy: 0.3564
 8448/13806 [=================>............] - ETA: 4s - loss: 1.4899 - categorical_accuracy: 0.3570
 8576/13806 [=================>............] - ETA: 4s - loss: 1.4904 - categorical_accuracy: 0.3561
 8704/13806 [=================>............] - ETA: 4s - loss: 1.4906 - categorical_accuracy: 0.3552
 8832/13806 [==================>...........] - ETA: 4s - loss: 1.4912 - categorical_accuracy: 0.3547
 8960/13806 [==================>...........] - ETA: 4s - loss: 1.4910 - categorical_accuracy: 0.3555
 9088/13806 [==================>...........] - ETA: 4s - loss: 1.4906 - categorical_accuracy: 0.3560
 9216/13806 [===================>..........] - ETA: 4s - loss: 1.4902 - categorical_accuracy: 0.3569
 9344/13806 [===================>..........] - ETA: 3s - loss: 1.4893 - categorical_accuracy: 0.3576
 9472/13806 [===================>..........] - ETA: 3s - loss: 1.4896 - categorical_accuracy: 0.3571
 9600/13806 [===================>..........] - ETA: 3s - loss: 1.4895 - categorical_accuracy: 0.3570
 9728/13806 [====================>.........] - ETA: 3s - loss: 1.4890 - categorical_accuracy: 0.3570
 9856/13806 [====================>.........] - ETA: 3s - loss: 1.4889 - categorical_accuracy: 0.3583
 9984/13806 [====================>.........] - ETA: 3s - loss: 1.4890 - categorical_accuracy: 0.3581
10112/13806 [====================>.........] - ETA: 3s - loss: 1.4894 - categorical_accuracy: 0.3578
10240/13806 [=====================>........] - ETA: 3s - loss: 1.4888 - categorical_accuracy: 0.3585
10368/13806 [=====================>........] - ETA: 3s - loss: 1.4886 - categorical_accuracy: 0.3584
10496/13806 [=====================>........] - ETA: 2s - loss: 1.4889 - categorical_accuracy: 0.3581
10624/13806 [======================>.......] - ETA: 2s - loss: 1.4888 - categorical_accuracy: 0.3582
10752/13806 [======================>.......] - ETA: 2s - loss: 1.4884 - categorical_accuracy: 0.3583
10880/13806 [======================>.......] - ETA: 2s - loss: 1.4883 - categorical_accuracy: 0.3573
11008/13806 [======================>.......] - ETA: 2s - loss: 1.4885 - categorical_accuracy: 0.3565
11136/13806 [=======================>......] - ETA: 2s - loss: 1.4884 - categorical_accuracy: 0.3561
11264/13806 [=======================>......] - ETA: 2s - loss: 1.4885 - categorical_accuracy: 0.3561
11392/13806 [=======================>......] - ETA: 2s - loss: 1.4883 - categorical_accuracy: 0.3561
11520/13806 [========================>.....] - ETA: 2s - loss: 1.4881 - categorical_accuracy: 0.3564
11648/13806 [========================>.....] - ETA: 1s - loss: 1.4876 - categorical_accuracy: 0.3564
11776/13806 [========================>.....] - ETA: 1s - loss: 1.4880 - categorical_accuracy: 0.3567
11904/13806 [========================>.....] - ETA: 1s - loss: 1.4888 - categorical_accuracy: 0.3560
12032/13806 [=========================>....] - ETA: 1s - loss: 1.4882 - categorical_accuracy: 0.3570
12160/13806 [=========================>....] - ETA: 1s - loss: 1.4879 - categorical_accuracy: 0.3572
12288/13806 [=========================>....] - ETA: 1s - loss: 1.4875 - categorical_accuracy: 0.3573
12416/13806 [=========================>....] - ETA: 1s - loss: 1.4865 - categorical_accuracy: 0.3580
12544/13806 [==========================>...] - ETA: 1s - loss: 1.4868 - categorical_accuracy: 0.3580
12672/13806 [==========================>...] - ETA: 1s - loss: 1.4863 - categorical_accuracy: 0.3581
12800/13806 [==========================>...] - ETA: 0s - loss: 1.4859 - categorical_accuracy: 0.3583
12928/13806 [===========================>..] - ETA: 0s - loss: 1.4860 - categorical_accuracy: 0.3584
13056/13806 [===========================>..] - ETA: 0s - loss: 1.4865 - categorical_accuracy: 0.3577
13184/13806 [===========================>..] - ETA: 0s - loss: 1.4866 - categorical_accuracy: 0.3580
13312/13806 [===========================>..] - ETA: 0s - loss: 1.4866 - categorical_accuracy: 0.3581
13440/13806 [============================>.] - ETA: 0s - loss: 1.4863 - categorical_accuracy: 0.3583
13568/13806 [============================>.] - ETA: 0s - loss: 1.4862 - categorical_accuracy: 0.3585
13696/13806 [============================>.] - ETA: 0s - loss: 1.4866 - categorical_accuracy: 0.3575
13806/13806 [==============================] - 13s 946us/step - loss: 1.4863 - categorical_accuracy: 0.3569 - val_loss: 1.5976 - val_categorical_accuracy: 0.2803

Epoch 00005: val_categorical_accuracy did not improve
Epoch 6/15

  128/13806 [..............................] - ETA: 8s - loss: 1.4410 - categorical_accuracy: 0.3828
  256/13806 [..............................] - ETA: 9s - loss: 1.4403 - categorical_accuracy: 0.3711
  384/13806 [..............................] - ETA: 10s - loss: 1.4480 - categorical_accuracy: 0.3828
  512/13806 [>.............................] - ETA: 10s - loss: 1.4475 - categorical_accuracy: 0.3711
  640/13806 [>.............................] - ETA: 11s - loss: 1.4488 - categorical_accuracy: 0.3672
  768/13806 [>.............................] - ETA: 11s - loss: 1.4516 - categorical_accuracy: 0.3685
  896/13806 [>.............................] - ETA: 10s - loss: 1.4599 - categorical_accuracy: 0.3583
 1024/13806 [=>............................] - ETA: 10s - loss: 1.4593 - categorical_accuracy: 0.3555
 1152/13806 [=>............................] - ETA: 10s - loss: 1.4554 - categorical_accuracy: 0.3646
 1280/13806 [=>............................] - ETA: 10s - loss: 1.4565 - categorical_accuracy: 0.3664
 1408/13806 [==>...........................] - ETA: 9s - loss: 1.4579 - categorical_accuracy: 0.3665 
 1536/13806 [==>...........................] - ETA: 9s - loss: 1.4612 - categorical_accuracy: 0.3639
 1664/13806 [==>...........................] - ETA: 9s - loss: 1.4625 - categorical_accuracy: 0.3600
 1792/13806 [==>...........................] - ETA: 9s - loss: 1.4615 - categorical_accuracy: 0.3638
 1920/13806 [===>..........................] - ETA: 9s - loss: 1.4634 - categorical_accuracy: 0.3615
 2048/13806 [===>..........................] - ETA: 9s - loss: 1.4631 - categorical_accuracy: 0.3618
 2176/13806 [===>..........................] - ETA: 9s - loss: 1.4658 - categorical_accuracy: 0.3658
 2304/13806 [====>.........................] - ETA: 9s - loss: 1.4693 - categorical_accuracy: 0.3637
 2432/13806 [====>.........................] - ETA: 9s - loss: 1.4654 - categorical_accuracy: 0.3676
 2560/13806 [====>.........................] - ETA: 9s - loss: 1.4620 - categorical_accuracy: 0.3727
 2688/13806 [====>.........................] - ETA: 9s - loss: 1.4635 - categorical_accuracy: 0.3702
 2816/13806 [=====>........................] - ETA: 9s - loss: 1.4633 - categorical_accuracy: 0.3683
 2944/13806 [=====>........................] - ETA: 8s - loss: 1.4622 - categorical_accuracy: 0.3702
 3072/13806 [=====>........................] - ETA: 8s - loss: 1.4623 - categorical_accuracy: 0.3672
 3200/13806 [=====>........................] - ETA: 8s - loss: 1.4621 - categorical_accuracy: 0.3672
 3328/13806 [======>.......................] - ETA: 8s - loss: 1.4614 - categorical_accuracy: 0.3687
 3456/13806 [======>.......................] - ETA: 8s - loss: 1.4600 - categorical_accuracy: 0.3704
 3584/13806 [======>.......................] - ETA: 8s - loss: 1.4598 - categorical_accuracy: 0.3717
 3712/13806 [=======>......................] - ETA: 8s - loss: 1.4603 - categorical_accuracy: 0.3715
 3840/13806 [=======>......................] - ETA: 7s - loss: 1.4585 - categorical_accuracy: 0.3729
 3968/13806 [=======>......................] - ETA: 7s - loss: 1.4593 - categorical_accuracy: 0.3715
 4096/13806 [=======>......................] - ETA: 7s - loss: 1.4615 - categorical_accuracy: 0.3699
 4224/13806 [========>.....................] - ETA: 7s - loss: 1.4618 - categorical_accuracy: 0.3714
 4352/13806 [========>.....................] - ETA: 7s - loss: 1.4604 - categorical_accuracy: 0.3736
 4480/13806 [========>.....................] - ETA: 7s - loss: 1.4611 - categorical_accuracy: 0.3752
 4608/13806 [=========>....................] - ETA: 7s - loss: 1.4626 - categorical_accuracy: 0.3737
 4736/13806 [=========>....................] - ETA: 7s - loss: 1.4620 - categorical_accuracy: 0.3739
 4864/13806 [=========>....................] - ETA: 7s - loss: 1.4628 - categorical_accuracy: 0.3740
 4992/13806 [=========>....................] - ETA: 7s - loss: 1.4640 - categorical_accuracy: 0.3740
 5120/13806 [==========>...................] - ETA: 7s - loss: 1.4655 - categorical_accuracy: 0.3734
 5248/13806 [==========>...................] - ETA: 7s - loss: 1.4651 - categorical_accuracy: 0.3729
 5376/13806 [==========>...................] - ETA: 6s - loss: 1.4638 - categorical_accuracy: 0.3733
 5504/13806 [==========>...................] - ETA: 6s - loss: 1.4642 - categorical_accuracy: 0.3717
 5632/13806 [===========>..................] - ETA: 6s - loss: 1.4657 - categorical_accuracy: 0.3699
 5760/13806 [===========>..................] - ETA: 6s - loss: 1.4649 - categorical_accuracy: 0.3708
 5888/13806 [===========>..................] - ETA: 6s - loss: 1.4643 - categorical_accuracy: 0.3709
 6016/13806 [============>.................] - ETA: 6s - loss: 1.4637 - categorical_accuracy: 0.3705
 6144/13806 [============>.................] - ETA: 6s - loss: 1.4642 - categorical_accuracy: 0.3700
 6272/13806 [============>.................] - ETA: 6s - loss: 1.4647 - categorical_accuracy: 0.3693
 6400/13806 [============>.................] - ETA: 6s - loss: 1.4658 - categorical_accuracy: 0.3680
 6528/13806 [=============>................] - ETA: 6s - loss: 1.4660 - categorical_accuracy: 0.3693
 6656/13806 [=============>................] - ETA: 5s - loss: 1.4684 - categorical_accuracy: 0.3691
 6784/13806 [=============>................] - ETA: 5s - loss: 1.4677 - categorical_accuracy: 0.3700
 6912/13806 [==============>...............] - ETA: 5s - loss: 1.4683 - categorical_accuracy: 0.3699
 7040/13806 [==============>...............] - ETA: 5s - loss: 1.4682 - categorical_accuracy: 0.3697
 7168/13806 [==============>...............] - ETA: 5s - loss: 1.4688 - categorical_accuracy: 0.3687
 7296/13806 [==============>...............] - ETA: 5s - loss: 1.4685 - categorical_accuracy: 0.3699
 7424/13806 [===============>..............] - ETA: 5s - loss: 1.4690 - categorical_accuracy: 0.3689
 7552/13806 [===============>..............] - ETA: 5s - loss: 1.4684 - categorical_accuracy: 0.3693
 7680/13806 [===============>..............] - ETA: 5s - loss: 1.4689 - categorical_accuracy: 0.3689
 7808/13806 [===============>..............] - ETA: 4s - loss: 1.4692 - categorical_accuracy: 0.3683
 7936/13806 [================>.............] - ETA: 4s - loss: 1.4681 - categorical_accuracy: 0.3686
 8064/13806 [================>.............] - ETA: 4s - loss: 1.4670 - categorical_accuracy: 0.3689
 8192/13806 [================>.............] - ETA: 4s - loss: 1.4680 - categorical_accuracy: 0.3689
 8320/13806 [=================>............] - ETA: 4s - loss: 1.4680 - categorical_accuracy: 0.3684
 8448/13806 [=================>............] - ETA: 4s - loss: 1.4679 - categorical_accuracy: 0.3678
 8576/13806 [=================>............] - ETA: 4s - loss: 1.4689 - categorical_accuracy: 0.3666
 8704/13806 [=================>............] - ETA: 4s - loss: 1.4692 - categorical_accuracy: 0.3665
 8832/13806 [==================>...........] - ETA: 4s - loss: 1.4691 - categorical_accuracy: 0.3667
 8960/13806 [==================>...........] - ETA: 4s - loss: 1.4688 - categorical_accuracy: 0.3674
 9088/13806 [==================>...........] - ETA: 4s - loss: 1.4687 - categorical_accuracy: 0.3676
 9216/13806 [===================>..........] - ETA: 3s - loss: 1.4691 - categorical_accuracy: 0.3679
 9344/13806 [===================>..........] - ETA: 3s - loss: 1.4693 - categorical_accuracy: 0.3673
 9472/13806 [===================>..........] - ETA: 3s - loss: 1.4690 - categorical_accuracy: 0.3674
 9600/13806 [===================>..........] - ETA: 3s - loss: 1.4693 - categorical_accuracy: 0.3671
 9728/13806 [====================>.........] - ETA: 3s - loss: 1.4696 - categorical_accuracy: 0.3674
 9856/13806 [====================>.........] - ETA: 3s - loss: 1.4696 - categorical_accuracy: 0.3670
 9984/13806 [====================>.........] - ETA: 3s - loss: 1.4689 - categorical_accuracy: 0.3672
10112/13806 [====================>.........] - ETA: 3s - loss: 1.4683 - categorical_accuracy: 0.3670
10240/13806 [=====================>........] - ETA: 3s - loss: 1.4678 - categorical_accuracy: 0.3669
10368/13806 [=====================>........] - ETA: 2s - loss: 1.4668 - categorical_accuracy: 0.3673
10496/13806 [=====================>........] - ETA: 2s - loss: 1.4669 - categorical_accuracy: 0.3670
10624/13806 [======================>.......] - ETA: 2s - loss: 1.4669 - categorical_accuracy: 0.3673
10752/13806 [======================>.......] - ETA: 2s - loss: 1.4669 - categorical_accuracy: 0.3667
10880/13806 [======================>.......] - ETA: 2s - loss: 1.4671 - categorical_accuracy: 0.3665
11008/13806 [======================>.......] - ETA: 2s - loss: 1.4677 - categorical_accuracy: 0.3655
11136/13806 [=======================>......] - ETA: 2s - loss: 1.4670 - categorical_accuracy: 0.3662
11264/13806 [=======================>......] - ETA: 2s - loss: 1.4661 - categorical_accuracy: 0.3669
11392/13806 [=======================>......] - ETA: 2s - loss: 1.4657 - categorical_accuracy: 0.3669
11520/13806 [========================>.....] - ETA: 1s - loss: 1.4657 - categorical_accuracy: 0.3668
11648/13806 [========================>.....] - ETA: 1s - loss: 1.4650 - categorical_accuracy: 0.3680
11776/13806 [========================>.....] - ETA: 1s - loss: 1.4656 - categorical_accuracy: 0.3674
11904/13806 [========================>.....] - ETA: 1s - loss: 1.4652 - categorical_accuracy: 0.3673
12032/13806 [=========================>....] - ETA: 1s - loss: 1.4652 - categorical_accuracy: 0.3671
12160/13806 [=========================>....] - ETA: 1s - loss: 1.4658 - categorical_accuracy: 0.3665
12288/13806 [=========================>....] - ETA: 1s - loss: 1.4655 - categorical_accuracy: 0.3665
12416/13806 [=========================>....] - ETA: 1s - loss: 1.4652 - categorical_accuracy: 0.3666
12544/13806 [==========================>...] - ETA: 1s - loss: 1.4650 - categorical_accuracy: 0.3670
12672/13806 [==========================>...] - ETA: 0s - loss: 1.4647 - categorical_accuracy: 0.3675
12800/13806 [==========================>...] - ETA: 0s - loss: 1.4653 - categorical_accuracy: 0.3673
12928/13806 [===========================>..] - ETA: 0s - loss: 1.4655 - categorical_accuracy: 0.3673
13056/13806 [===========================>..] - ETA: 0s - loss: 1.4660 - categorical_accuracy: 0.3663
13184/13806 [===========================>..] - ETA: 0s - loss: 1.4665 - categorical_accuracy: 0.3661
13312/13806 [===========================>..] - ETA: 0s - loss: 1.4660 - categorical_accuracy: 0.3665
13440/13806 [============================>.] - ETA: 0s - loss: 1.4659 - categorical_accuracy: 0.3664
13568/13806 [============================>.] - ETA: 0s - loss: 1.4653 - categorical_accuracy: 0.3667
13696/13806 [============================>.] - ETA: 0s - loss: 1.4651 - categorical_accuracy: 0.3667
13806/13806 [==============================] - 13s 921us/step - loss: 1.4652 - categorical_accuracy: 0.3666 - val_loss: 1.6080 - val_categorical_accuracy: 0.2883

Epoch 00006: val_categorical_accuracy did not improve
Epoch 7/15

  128/13806 [..............................] - ETA: 9s - loss: 1.4101 - categorical_accuracy: 0.4219
  256/13806 [..............................] - ETA: 11s - loss: 1.4425 - categorical_accuracy: 0.4062
  384/13806 [..............................] - ETA: 11s - loss: 1.4481 - categorical_accuracy: 0.3958
  512/13806 [>.............................] - ETA: 11s - loss: 1.4538 - categorical_accuracy: 0.3887
  640/13806 [>.............................] - ETA: 11s - loss: 1.4504 - categorical_accuracy: 0.3953
  768/13806 [>.............................] - ETA: 11s - loss: 1.4436 - categorical_accuracy: 0.4036
  896/13806 [>.............................] - ETA: 11s - loss: 1.4466 - categorical_accuracy: 0.3984
 1024/13806 [=>............................] - ETA: 11s - loss: 1.4537 - categorical_accuracy: 0.3965
 1152/13806 [=>............................] - ETA: 11s - loss: 1.4537 - categorical_accuracy: 0.3950
 1280/13806 [=>............................] - ETA: 11s - loss: 1.4601 - categorical_accuracy: 0.3883
 1408/13806 [==>...........................] - ETA: 11s - loss: 1.4556 - categorical_accuracy: 0.3920
 1536/13806 [==>...........................] - ETA: 11s - loss: 1.4588 - categorical_accuracy: 0.3893
 1664/13806 [==>...........................] - ETA: 10s - loss: 1.4565 - categorical_accuracy: 0.3876
 1792/13806 [==>...........................] - ETA: 10s - loss: 1.4565 - categorical_accuracy: 0.3917
 1920/13806 [===>..........................] - ETA: 10s - loss: 1.4571 - categorical_accuracy: 0.3917
 2048/13806 [===>..........................] - ETA: 10s - loss: 1.4538 - categorical_accuracy: 0.3945
 2176/13806 [===>..........................] - ETA: 10s - loss: 1.4538 - categorical_accuracy: 0.3929
 2304/13806 [====>.........................] - ETA: 10s - loss: 1.4557 - categorical_accuracy: 0.3898
 2432/13806 [====>.........................] - ETA: 10s - loss: 1.4560 - categorical_accuracy: 0.3890
 2560/13806 [====>.........................] - ETA: 10s - loss: 1.4564 - categorical_accuracy: 0.3879
 2688/13806 [====>.........................] - ETA: 9s - loss: 1.4544 - categorical_accuracy: 0.3869 
 2816/13806 [=====>........................] - ETA: 9s - loss: 1.4537 - categorical_accuracy: 0.3892
 2944/13806 [=====>........................] - ETA: 9s - loss: 1.4543 - categorical_accuracy: 0.3862
 3072/13806 [=====>........................] - ETA: 9s - loss: 1.4551 - categorical_accuracy: 0.3854
 3200/13806 [=====>........................] - ETA: 9s - loss: 1.4578 - categorical_accuracy: 0.3816
 3328/13806 [======>.......................] - ETA: 9s - loss: 1.4575 - categorical_accuracy: 0.3804
 3456/13806 [======>.......................] - ETA: 9s - loss: 1.4560 - categorical_accuracy: 0.3811
 3584/13806 [======>.......................] - ETA: 8s - loss: 1.4557 - categorical_accuracy: 0.3809
 3712/13806 [=======>......................] - ETA: 8s - loss: 1.4561 - categorical_accuracy: 0.3785
 3840/13806 [=======>......................] - ETA: 8s - loss: 1.4578 - categorical_accuracy: 0.3760
 3968/13806 [=======>......................] - ETA: 8s - loss: 1.4583 - categorical_accuracy: 0.3740
 4096/13806 [=======>......................] - ETA: 8s - loss: 1.4571 - categorical_accuracy: 0.3743
 4224/13806 [========>.....................] - ETA: 8s - loss: 1.4566 - categorical_accuracy: 0.3738
 4352/13806 [========>.....................] - ETA: 8s - loss: 1.4554 - categorical_accuracy: 0.3745
 4480/13806 [========>.....................] - ETA: 8s - loss: 1.4545 - categorical_accuracy: 0.3761
 4608/13806 [=========>....................] - ETA: 8s - loss: 1.4530 - categorical_accuracy: 0.3776
 4736/13806 [=========>....................] - ETA: 8s - loss: 1.4530 - categorical_accuracy: 0.3763
 4864/13806 [=========>....................] - ETA: 8s - loss: 1.4523 - categorical_accuracy: 0.3769
 4992/13806 [=========>....................] - ETA: 7s - loss: 1.4521 - categorical_accuracy: 0.3776
 5120/13806 [==========>...................] - ETA: 7s - loss: 1.4525 - categorical_accuracy: 0.3758
 5248/13806 [==========>...................] - ETA: 7s - loss: 1.4516 - categorical_accuracy: 0.3769
 5376/13806 [==========>...................] - ETA: 7s - loss: 1.4520 - categorical_accuracy: 0.3763
 5504/13806 [==========>...................] - ETA: 7s - loss: 1.4511 - categorical_accuracy: 0.3777
 5632/13806 [===========>..................] - ETA: 7s - loss: 1.4507 - categorical_accuracy: 0.3786
 5760/13806 [===========>..................] - ETA: 7s - loss: 1.4495 - categorical_accuracy: 0.3797
 5888/13806 [===========>..................] - ETA: 7s - loss: 1.4496 - categorical_accuracy: 0.3808
 6016/13806 [============>.................] - ETA: 7s - loss: 1.4496 - categorical_accuracy: 0.3807
 6144/13806 [============>.................] - ETA: 6s - loss: 1.4489 - categorical_accuracy: 0.3805
 6272/13806 [============>.................] - ETA: 6s - loss: 1.4489 - categorical_accuracy: 0.3809
 6400/13806 [============>.................] - ETA: 6s - loss: 1.4486 - categorical_accuracy: 0.3814
 6528/13806 [=============>................] - ETA: 6s - loss: 1.4491 - categorical_accuracy: 0.3820
 6656/13806 [=============>................] - ETA: 6s - loss: 1.4482 - categorical_accuracy: 0.3821
 6784/13806 [=============>................] - ETA: 6s - loss: 1.4480 - categorical_accuracy: 0.3822
 6912/13806 [==============>...............] - ETA: 6s - loss: 1.4465 - categorical_accuracy: 0.3840
 7040/13806 [==============>...............] - ETA: 6s - loss: 1.4473 - categorical_accuracy: 0.3841
 7168/13806 [==============>...............] - ETA: 6s - loss: 1.4469 - categorical_accuracy: 0.3842
 7296/13806 [==============>...............] - ETA: 5s - loss: 1.4473 - categorical_accuracy: 0.3835
 7424/13806 [===============>..............] - ETA: 5s - loss: 1.4474 - categorical_accuracy: 0.3823
 7552/13806 [===============>..............] - ETA: 5s - loss: 1.4477 - categorical_accuracy: 0.3818
 7680/13806 [===============>..............] - ETA: 5s - loss: 1.4480 - categorical_accuracy: 0.3814
 7808/13806 [===============>..............] - ETA: 5s - loss: 1.4481 - categorical_accuracy: 0.3810
 7936/13806 [================>.............] - ETA: 5s - loss: 1.4493 - categorical_accuracy: 0.3794
 8064/13806 [================>.............] - ETA: 5s - loss: 1.4493 - categorical_accuracy: 0.3785
 8192/13806 [================>.............] - ETA: 5s - loss: 1.4487 - categorical_accuracy: 0.3794
 8320/13806 [=================>............] - ETA: 5s - loss: 1.4490 - categorical_accuracy: 0.3790
 8448/13806 [=================>............] - ETA: 4s - loss: 1.4485 - categorical_accuracy: 0.3799
 8576/13806 [=================>............] - ETA: 4s - loss: 1.4480 - categorical_accuracy: 0.3801
 8704/13806 [=================>............] - ETA: 4s - loss: 1.4475 - categorical_accuracy: 0.3806
 8832/13806 [==================>...........] - ETA: 4s - loss: 1.4468 - categorical_accuracy: 0.3813
 8960/13806 [==================>...........] - ETA: 4s - loss: 1.4461 - categorical_accuracy: 0.3818
 9088/13806 [==================>...........] - ETA: 4s - loss: 1.4459 - categorical_accuracy: 0.3816
 9216/13806 [===================>..........] - ETA: 4s - loss: 1.4458 - categorical_accuracy: 0.3814
 9344/13806 [===================>..........] - ETA: 4s - loss: 1.4457 - categorical_accuracy: 0.3814
 9472/13806 [===================>..........] - ETA: 3s - loss: 1.4455 - categorical_accuracy: 0.3813
 9600/13806 [===================>..........] - ETA: 3s - loss: 1.4454 - categorical_accuracy: 0.3816
 9728/13806 [====================>.........] - ETA: 3s - loss: 1.4453 - categorical_accuracy: 0.3819
 9856/13806 [====================>.........] - ETA: 3s - loss: 1.4453 - categorical_accuracy: 0.3823
 9984/13806 [====================>.........] - ETA: 3s - loss: 1.4460 - categorical_accuracy: 0.3822
10112/13806 [====================>.........] - ETA: 3s - loss: 1.4456 - categorical_accuracy: 0.3828
10240/13806 [=====================>........] - ETA: 3s - loss: 1.4465 - categorical_accuracy: 0.3827
10368/13806 [=====================>........] - ETA: 3s - loss: 1.4464 - categorical_accuracy: 0.3828
10496/13806 [=====================>........] - ETA: 3s - loss: 1.4463 - categorical_accuracy: 0.3826
10624/13806 [======================>.......] - ETA: 2s - loss: 1.4467 - categorical_accuracy: 0.3821
10752/13806 [======================>.......] - ETA: 2s - loss: 1.4458 - categorical_accuracy: 0.3828
10880/13806 [======================>.......] - ETA: 2s - loss: 1.4453 - categorical_accuracy: 0.3835
11008/13806 [======================>.......] - ETA: 2s - loss: 1.4457 - categorical_accuracy: 0.3839
11136/13806 [=======================>......] - ETA: 2s - loss: 1.4462 - categorical_accuracy: 0.3836
11264/13806 [=======================>......] - ETA: 2s - loss: 1.4460 - categorical_accuracy: 0.3837
11392/13806 [=======================>......] - ETA: 2s - loss: 1.4462 - categorical_accuracy: 0.3833
11520/13806 [========================>.....] - ETA: 2s - loss: 1.4465 - categorical_accuracy: 0.3830
11648/13806 [========================>.....] - ETA: 1s - loss: 1.4461 - categorical_accuracy: 0.3831
11776/13806 [========================>.....] - ETA: 1s - loss: 1.4462 - categorical_accuracy: 0.3832
11904/13806 [========================>.....] - ETA: 1s - loss: 1.4468 - categorical_accuracy: 0.3824
12032/13806 [=========================>....] - ETA: 1s - loss: 1.4463 - categorical_accuracy: 0.3831
12160/13806 [=========================>....] - ETA: 1s - loss: 1.4471 - categorical_accuracy: 0.3825
12288/13806 [=========================>....] - ETA: 1s - loss: 1.4467 - categorical_accuracy: 0.3826
12416/13806 [=========================>....] - ETA: 1s - loss: 1.4464 - categorical_accuracy: 0.3827
12544/13806 [==========================>...] - ETA: 1s - loss: 1.4462 - categorical_accuracy: 0.3830
12672/13806 [==========================>...] - ETA: 1s - loss: 1.4465 - categorical_accuracy: 0.3826
12800/13806 [==========================>...] - ETA: 0s - loss: 1.4470 - categorical_accuracy: 0.3821
12928/13806 [===========================>..] - ETA: 0s - loss: 1.4469 - categorical_accuracy: 0.3827
13056/13806 [===========================>..] - ETA: 0s - loss: 1.4465 - categorical_accuracy: 0.3832
13184/13806 [===========================>..] - ETA: 0s - loss: 1.4467 - categorical_accuracy: 0.3833
13312/13806 [===========================>..] - ETA: 0s - loss: 1.4460 - categorical_accuracy: 0.3837
13440/13806 [============================>.] - ETA: 0s - loss: 1.4467 - categorical_accuracy: 0.3830
13568/13806 [============================>.] - ETA: 0s - loss: 1.4471 - categorical_accuracy: 0.3828
13696/13806 [============================>.] - ETA: 0s - loss: 1.4460 - categorical_accuracy: 0.3833
13806/13806 [==============================] - 13s 976us/step - loss: 1.4462 - categorical_accuracy: 0.3833 - val_loss: 1.5926 - val_categorical_accuracy: 0.2982

Epoch 00007: val_categorical_accuracy improved from 0.29026 to 0.29821, saving model to results/vardial2018/multi_input_char_only/model_weights.hdf5
Epoch 8/15

  128/13806 [..............................] - ETA: 12s - loss: 1.4145 - categorical_accuracy: 0.3281
  256/13806 [..............................] - ETA: 12s - loss: 1.4515 - categorical_accuracy: 0.3477
  384/13806 [..............................] - ETA: 12s - loss: 1.4265 - categorical_accuracy: 0.3776
  512/13806 [>.............................] - ETA: 12s - loss: 1.4268 - categorical_accuracy: 0.3828
  640/13806 [>.............................] - ETA: 12s - loss: 1.4130 - categorical_accuracy: 0.4078
  768/13806 [>.............................] - ETA: 12s - loss: 1.4173 - categorical_accuracy: 0.3997
  896/13806 [>.............................] - ETA: 12s - loss: 1.4147 - categorical_accuracy: 0.4096
 1024/13806 [=>............................] - ETA: 12s - loss: 1.4177 - categorical_accuracy: 0.4053
 1152/13806 [=>............................] - ETA: 11s - loss: 1.4187 - categorical_accuracy: 0.4106
 1280/13806 [=>............................] - ETA: 11s - loss: 1.4201 - categorical_accuracy: 0.4062
 1408/13806 [==>...........................] - ETA: 11s - loss: 1.4243 - categorical_accuracy: 0.4041
 1536/13806 [==>...........................] - ETA: 10s - loss: 1.4229 - categorical_accuracy: 0.4049
 1664/13806 [==>...........................] - ETA: 10s - loss: 1.4246 - categorical_accuracy: 0.4050
 1792/13806 [==>...........................] - ETA: 10s - loss: 1.4234 - categorical_accuracy: 0.4051
 1920/13806 [===>..........................] - ETA: 10s - loss: 1.4249 - categorical_accuracy: 0.4026
 2048/13806 [===>..........................] - ETA: 10s - loss: 1.4280 - categorical_accuracy: 0.4028
 2176/13806 [===>..........................] - ETA: 10s - loss: 1.4285 - categorical_accuracy: 0.3998
 2304/13806 [====>.........................] - ETA: 10s - loss: 1.4277 - categorical_accuracy: 0.4002
 2432/13806 [====>.........................] - ETA: 10s - loss: 1.4292 - categorical_accuracy: 0.4001
 2560/13806 [====>.........................] - ETA: 10s - loss: 1.4297 - categorical_accuracy: 0.3980
 2688/13806 [====>.........................] - ETA: 9s - loss: 1.4310 - categorical_accuracy: 0.3977 
 2816/13806 [=====>........................] - ETA: 9s - loss: 1.4293 - categorical_accuracy: 0.3974
 2944/13806 [=====>........................] - ETA: 9s - loss: 1.4298 - categorical_accuracy: 0.3971
 3072/13806 [=====>........................] - ETA: 9s - loss: 1.4303 - categorical_accuracy: 0.3962
 3200/13806 [=====>........................] - ETA: 9s - loss: 1.4311 - categorical_accuracy: 0.3959
 3328/13806 [======>.......................] - ETA: 9s - loss: 1.4317 - categorical_accuracy: 0.3948
 3456/13806 [======>.......................] - ETA: 9s - loss: 1.4308 - categorical_accuracy: 0.3950
 3584/13806 [======>.......................] - ETA: 9s - loss: 1.4301 - categorical_accuracy: 0.3943
 3712/13806 [=======>......................] - ETA: 9s - loss: 1.4312 - categorical_accuracy: 0.3933
 3840/13806 [=======>......................] - ETA: 8s - loss: 1.4339 - categorical_accuracy: 0.3906
 3968/13806 [=======>......................] - ETA: 8s - loss: 1.4339 - categorical_accuracy: 0.3916
 4096/13806 [=======>......................] - ETA: 8s - loss: 1.4315 - categorical_accuracy: 0.3938
 4224/13806 [========>.....................] - ETA: 8s - loss: 1.4301 - categorical_accuracy: 0.3956
 4352/13806 [========>.....................] - ETA: 8s - loss: 1.4275 - categorical_accuracy: 0.3977
 4480/13806 [========>.....................] - ETA: 8s - loss: 1.4283 - categorical_accuracy: 0.3969
 4608/13806 [=========>....................] - ETA: 8s - loss: 1.4272 - categorical_accuracy: 0.3969
 4736/13806 [=========>....................] - ETA: 8s - loss: 1.4268 - categorical_accuracy: 0.3986
 4864/13806 [=========>....................] - ETA: 8s - loss: 1.4260 - categorical_accuracy: 0.3984
 4992/13806 [=========>....................] - ETA: 7s - loss: 1.4273 - categorical_accuracy: 0.3980
 5120/13806 [==========>...................] - ETA: 7s - loss: 1.4283 - categorical_accuracy: 0.3963
 5248/13806 [==========>...................] - ETA: 7s - loss: 1.4290 - categorical_accuracy: 0.3960
 5376/13806 [==========>...................] - ETA: 7s - loss: 1.4289 - categorical_accuracy: 0.3958
 5504/13806 [==========>...................] - ETA: 7s - loss: 1.4295 - categorical_accuracy: 0.3943
 5632/13806 [===========>..................] - ETA: 7s - loss: 1.4304 - categorical_accuracy: 0.3928
 5760/13806 [===========>..................] - ETA: 7s - loss: 1.4317 - categorical_accuracy: 0.3917
 5888/13806 [===========>..................] - ETA: 7s - loss: 1.4314 - categorical_accuracy: 0.3913
 6016/13806 [============>.................] - ETA: 6s - loss: 1.4319 - categorical_accuracy: 0.3905
 6144/13806 [============>.................] - ETA: 6s - loss: 1.4326 - categorical_accuracy: 0.3888
 6272/13806 [============>.................] - ETA: 6s - loss: 1.4309 - categorical_accuracy: 0.3905
 6400/13806 [============>.................] - ETA: 6s - loss: 1.4311 - categorical_accuracy: 0.3916
 6528/13806 [=============>................] - ETA: 6s - loss: 1.4321 - categorical_accuracy: 0.3906
 6656/13806 [=============>................] - ETA: 6s - loss: 1.4317 - categorical_accuracy: 0.3906
 6784/13806 [=============>................] - ETA: 6s - loss: 1.4319 - categorical_accuracy: 0.3911
 6912/13806 [==============>...............] - ETA: 6s - loss: 1.4324 - categorical_accuracy: 0.3913
 7040/13806 [==============>...............] - ETA: 6s - loss: 1.4318 - categorical_accuracy: 0.3913
 7168/13806 [==============>...............] - ETA: 5s - loss: 1.4317 - categorical_accuracy: 0.3919
 7296/13806 [==============>...............] - ETA: 5s - loss: 1.4318 - categorical_accuracy: 0.3920
 7424/13806 [===============>..............] - ETA: 5s - loss: 1.4308 - categorical_accuracy: 0.3917
 7552/13806 [===============>..............] - ETA: 5s - loss: 1.4304 - categorical_accuracy: 0.3914
 7680/13806 [===============>..............] - ETA: 5s - loss: 1.4307 - categorical_accuracy: 0.3915
 7808/13806 [===============>..............] - ETA: 5s - loss: 1.4299 - categorical_accuracy: 0.3918
 7936/13806 [================>.............] - ETA: 5s - loss: 1.4304 - categorical_accuracy: 0.3909
 8064/13806 [================>.............] - ETA: 5s - loss: 1.4304 - categorical_accuracy: 0.3909
 8192/13806 [================>.............] - ETA: 4s - loss: 1.4313 - categorical_accuracy: 0.3900
 8320/13806 [=================>............] - ETA: 4s - loss: 1.4322 - categorical_accuracy: 0.3894
 8448/13806 [=================>............] - ETA: 4s - loss: 1.4331 - categorical_accuracy: 0.3897
 8576/13806 [=================>............] - ETA: 4s - loss: 1.4333 - categorical_accuracy: 0.3892
 8704/13806 [=================>............] - ETA: 4s - loss: 1.4332 - categorical_accuracy: 0.3892
 8832/13806 [==================>...........] - ETA: 4s - loss: 1.4335 - categorical_accuracy: 0.3890
 8960/13806 [==================>...........] - ETA: 4s - loss: 1.4339 - categorical_accuracy: 0.3886
 9088/13806 [==================>...........] - ETA: 4s - loss: 1.4333 - categorical_accuracy: 0.3888
 9216/13806 [===================>..........] - ETA: 4s - loss: 1.4332 - categorical_accuracy: 0.3887
 9344/13806 [===================>..........] - ETA: 3s - loss: 1.4332 - categorical_accuracy: 0.3886
 9472/13806 [===================>..........] - ETA: 3s - loss: 1.4325 - categorical_accuracy: 0.3891
 9600/13806 [===================>..........] - ETA: 3s - loss: 1.4319 - categorical_accuracy: 0.3890
 9728/13806 [====================>.........] - ETA: 3s - loss: 1.4315 - categorical_accuracy: 0.3897
 9856/13806 [====================>.........] - ETA: 3s - loss: 1.4321 - categorical_accuracy: 0.3888
 9984/13806 [====================>.........] - ETA: 3s - loss: 1.4318 - categorical_accuracy: 0.3893
10112/13806 [====================>.........] - ETA: 3s - loss: 1.4320 - categorical_accuracy: 0.3894
10240/13806 [=====================>........] - ETA: 3s - loss: 1.4323 - categorical_accuracy: 0.3891
10368/13806 [=====================>........] - ETA: 3s - loss: 1.4319 - categorical_accuracy: 0.3896
10496/13806 [=====================>........] - ETA: 2s - loss: 1.4318 - categorical_accuracy: 0.3896
10624/13806 [======================>.......] - ETA: 2s - loss: 1.4322 - categorical_accuracy: 0.3898
10752/13806 [======================>.......] - ETA: 2s - loss: 1.4315 - categorical_accuracy: 0.3905
10880/13806 [======================>.......] - ETA: 2s - loss: 1.4310 - categorical_accuracy: 0.3905
11008/13806 [======================>.......] - ETA: 2s - loss: 1.4313 - categorical_accuracy: 0.3899
11136/13806 [=======================>......] - ETA: 2s - loss: 1.4308 - categorical_accuracy: 0.3902
11264/13806 [=======================>......] - ETA: 2s - loss: 1.4304 - categorical_accuracy: 0.3904
11392/13806 [=======================>......] - ETA: 2s - loss: 1.4305 - categorical_accuracy: 0.3899
11520/13806 [========================>.....] - ETA: 2s - loss: 1.4307 - categorical_accuracy: 0.3898
11648/13806 [========================>.....] - ETA: 1s - loss: 1.4305 - categorical_accuracy: 0.3905
11776/13806 [========================>.....] - ETA: 1s - loss: 1.4311 - categorical_accuracy: 0.3905
11904/13806 [========================>.....] - ETA: 1s - loss: 1.4303 - categorical_accuracy: 0.3910
12032/13806 [=========================>....] - ETA: 1s - loss: 1.4312 - categorical_accuracy: 0.3904
12160/13806 [=========================>....] - ETA: 1s - loss: 1.4314 - categorical_accuracy: 0.3907
12288/13806 [=========================>....] - ETA: 1s - loss: 1.4311 - categorical_accuracy: 0.3910
12416/13806 [=========================>....] - ETA: 1s - loss: 1.4316 - categorical_accuracy: 0.3905
12544/13806 [==========================>...] - ETA: 1s - loss: 1.4318 - categorical_accuracy: 0.3905
12672/13806 [==========================>...] - ETA: 1s - loss: 1.4320 - categorical_accuracy: 0.3904
12800/13806 [==========================>...] - ETA: 0s - loss: 1.4317 - categorical_accuracy: 0.3904
12928/13806 [===========================>..] - ETA: 0s - loss: 1.4317 - categorical_accuracy: 0.3902
13056/13806 [===========================>..] - ETA: 0s - loss: 1.4310 - categorical_accuracy: 0.3908
13184/13806 [===========================>..] - ETA: 0s - loss: 1.4309 - categorical_accuracy: 0.3909
13312/13806 [===========================>..] - ETA: 0s - loss: 1.4307 - categorical_accuracy: 0.3909
13440/13806 [============================>.] - ETA: 0s - loss: 1.4307 - categorical_accuracy: 0.3907
13568/13806 [============================>.] - ETA: 0s - loss: 1.4301 - categorical_accuracy: 0.3916
13696/13806 [============================>.] - ETA: 0s - loss: 1.4305 - categorical_accuracy: 0.3911
13806/13806 [==============================] - 13s 957us/step - loss: 1.4310 - categorical_accuracy: 0.3912 - val_loss: 1.5834 - val_categorical_accuracy: 0.3128

Epoch 00008: val_categorical_accuracy improved from 0.29821 to 0.31279, saving model to results/vardial2018/multi_input_char_only/model_weights.hdf5
Epoch 9/15

  128/13806 [..............................] - ETA: 12s - loss: 1.4292 - categorical_accuracy: 0.3906
  256/13806 [..............................] - ETA: 12s - loss: 1.4361 - categorical_accuracy: 0.3867
  384/13806 [..............................] - ETA: 12s - loss: 1.4364 - categorical_accuracy: 0.3750
  512/13806 [>.............................] - ETA: 12s - loss: 1.4322 - categorical_accuracy: 0.3789
  640/13806 [>.............................] - ETA: 12s - loss: 1.4142 - categorical_accuracy: 0.3969
  768/13806 [>.............................] - ETA: 12s - loss: 1.4190 - categorical_accuracy: 0.3984
  896/13806 [>.............................] - ETA: 12s - loss: 1.4147 - categorical_accuracy: 0.4040
 1024/13806 [=>............................] - ETA: 11s - loss: 1.4207 - categorical_accuracy: 0.4004
 1152/13806 [=>............................] - ETA: 11s - loss: 1.4225 - categorical_accuracy: 0.3976
 1280/13806 [=>............................] - ETA: 11s - loss: 1.4290 - categorical_accuracy: 0.3977
 1408/13806 [==>...........................] - ETA: 10s - loss: 1.4212 - categorical_accuracy: 0.4034
 1536/13806 [==>...........................] - ETA: 10s - loss: 1.4209 - categorical_accuracy: 0.4030
 1664/13806 [==>...........................] - ETA: 10s - loss: 1.4229 - categorical_accuracy: 0.3978
 1792/13806 [==>...........................] - ETA: 9s - loss: 1.4236 - categorical_accuracy: 0.3979 
 1920/13806 [===>..........................] - ETA: 9s - loss: 1.4240 - categorical_accuracy: 0.3958
 2048/13806 [===>..........................] - ETA: 9s - loss: 1.4247 - categorical_accuracy: 0.3984
 2176/13806 [===>..........................] - ETA: 9s - loss: 1.4226 - categorical_accuracy: 0.4026
 2304/13806 [====>.........................] - ETA: 9s - loss: 1.4245 - categorical_accuracy: 0.4010
 2432/13806 [====>.........................] - ETA: 9s - loss: 1.4246 - categorical_accuracy: 0.3997
 2560/13806 [====>.........................] - ETA: 8s - loss: 1.4245 - categorical_accuracy: 0.4012
 2688/13806 [====>.........................] - ETA: 8s - loss: 1.4252 - categorical_accuracy: 0.3996
 2816/13806 [=====>........................] - ETA: 8s - loss: 1.4254 - categorical_accuracy: 0.3988
 2944/13806 [=====>........................] - ETA: 8s - loss: 1.4237 - categorical_accuracy: 0.3998
 3072/13806 [=====>........................] - ETA: 8s - loss: 1.4240 - categorical_accuracy: 0.3994
 3200/13806 [=====>........................] - ETA: 8s - loss: 1.4230 - categorical_accuracy: 0.3991
 3328/13806 [======>.......................] - ETA: 8s - loss: 1.4205 - categorical_accuracy: 0.3999
 3456/13806 [======>.......................] - ETA: 8s - loss: 1.4199 - categorical_accuracy: 0.4008
 3584/13806 [======>.......................] - ETA: 8s - loss: 1.4243 - categorical_accuracy: 0.3973
 3712/13806 [=======>......................] - ETA: 8s - loss: 1.4243 - categorical_accuracy: 0.3974
 3840/13806 [=======>......................] - ETA: 8s - loss: 1.4223 - categorical_accuracy: 0.3987
 3968/13806 [=======>......................] - ETA: 8s - loss: 1.4201 - categorical_accuracy: 0.4007
 4096/13806 [=======>......................] - ETA: 8s - loss: 1.4228 - categorical_accuracy: 0.3994
 4224/13806 [========>.....................] - ETA: 8s - loss: 1.4235 - categorical_accuracy: 0.3982
 4352/13806 [========>.....................] - ETA: 8s - loss: 1.4228 - categorical_accuracy: 0.4000
 4480/13806 [========>.....................] - ETA: 8s - loss: 1.4239 - categorical_accuracy: 0.3998
 4608/13806 [=========>....................] - ETA: 7s - loss: 1.4236 - categorical_accuracy: 0.4010
 4736/13806 [=========>....................] - ETA: 7s - loss: 1.4218 - categorical_accuracy: 0.4022
 4864/13806 [=========>....................] - ETA: 7s - loss: 1.4239 - categorical_accuracy: 0.4005
 4992/13806 [=========>....................] - ETA: 7s - loss: 1.4232 - categorical_accuracy: 0.4008
 5120/13806 [==========>...................] - ETA: 7s - loss: 1.4220 - categorical_accuracy: 0.4010
 5248/13806 [==========>...................] - ETA: 7s - loss: 1.4214 - categorical_accuracy: 0.4003
 5376/13806 [==========>...................] - ETA: 7s - loss: 1.4207 - categorical_accuracy: 0.3997
 5504/13806 [==========>...................] - ETA: 7s - loss: 1.4202 - categorical_accuracy: 0.3993
 5632/13806 [===========>..................] - ETA: 7s - loss: 1.4219 - categorical_accuracy: 0.3979
 5760/13806 [===========>..................] - ETA: 7s - loss: 1.4232 - categorical_accuracy: 0.3958
 5888/13806 [===========>..................] - ETA: 6s - loss: 1.4237 - categorical_accuracy: 0.3957
 6016/13806 [============>.................] - ETA: 6s - loss: 1.4236 - categorical_accuracy: 0.3959
 6144/13806 [============>.................] - ETA: 6s - loss: 1.4243 - categorical_accuracy: 0.3960
 6272/13806 [============>.................] - ETA: 6s - loss: 1.4256 - categorical_accuracy: 0.3945
 6400/13806 [============>.................] - ETA: 6s - loss: 1.4235 - categorical_accuracy: 0.3958
 6528/13806 [=============>................] - ETA: 6s - loss: 1.4245 - categorical_accuracy: 0.3949
 6656/13806 [=============>................] - ETA: 6s - loss: 1.4248 - categorical_accuracy: 0.3948
 6784/13806 [=============>................] - ETA: 6s - loss: 1.4241 - categorical_accuracy: 0.3948
 6912/13806 [==============>...............] - ETA: 6s - loss: 1.4253 - categorical_accuracy: 0.3932
 7040/13806 [==============>...............] - ETA: 5s - loss: 1.4244 - categorical_accuracy: 0.3939
 7168/13806 [==============>...............] - ETA: 5s - loss: 1.4237 - categorical_accuracy: 0.3940
 7296/13806 [==============>...............] - ETA: 5s - loss: 1.4232 - categorical_accuracy: 0.3945
 7424/13806 [===============>..............] - ETA: 5s - loss: 1.4224 - categorical_accuracy: 0.3957
 7552/13806 [===============>..............] - ETA: 5s - loss: 1.4212 - categorical_accuracy: 0.3967
 7680/13806 [===============>..............] - ETA: 5s - loss: 1.4203 - categorical_accuracy: 0.3970
 7808/13806 [===============>..............] - ETA: 5s - loss: 1.4206 - categorical_accuracy: 0.3961
 7936/13806 [================>.............] - ETA: 5s - loss: 1.4203 - categorical_accuracy: 0.3965
 8064/13806 [================>.............] - ETA: 5s - loss: 1.4209 - categorical_accuracy: 0.3965
 8192/13806 [================>.............] - ETA: 4s - loss: 1.4201 - categorical_accuracy: 0.3971
 8320/13806 [=================>............] - ETA: 4s - loss: 1.4198 - categorical_accuracy: 0.3977
 8448/13806 [=================>............] - ETA: 4s - loss: 1.4212 - categorical_accuracy: 0.3963
 8576/13806 [=================>............] - ETA: 4s - loss: 1.4206 - categorical_accuracy: 0.3963
 8704/13806 [=================>............] - ETA: 4s - loss: 1.4206 - categorical_accuracy: 0.3957
 8832/13806 [==================>...........] - ETA: 4s - loss: 1.4205 - categorical_accuracy: 0.3962
 8960/13806 [==================>...........] - ETA: 4s - loss: 1.4207 - categorical_accuracy: 0.3962
 9088/13806 [==================>...........] - ETA: 4s - loss: 1.4197 - categorical_accuracy: 0.3970
 9216/13806 [===================>..........] - ETA: 4s - loss: 1.4202 - categorical_accuracy: 0.3968
 9344/13806 [===================>..........] - ETA: 3s - loss: 1.4199 - categorical_accuracy: 0.3968
 9472/13806 [===================>..........] - ETA: 3s - loss: 1.4191 - categorical_accuracy: 0.3971
 9600/13806 [===================>..........] - ETA: 3s - loss: 1.4203 - categorical_accuracy: 0.3964
 9728/13806 [====================>.........] - ETA: 3s - loss: 1.4193 - categorical_accuracy: 0.3964
 9856/13806 [====================>.........] - ETA: 3s - loss: 1.4194 - categorical_accuracy: 0.3956
 9984/13806 [====================>.........] - ETA: 3s - loss: 1.4178 - categorical_accuracy: 0.3975
10112/13806 [====================>.........] - ETA: 3s - loss: 1.4169 - categorical_accuracy: 0.3988
10240/13806 [=====================>........] - ETA: 3s - loss: 1.4174 - categorical_accuracy: 0.3981
10368/13806 [=====================>........] - ETA: 3s - loss: 1.4170 - categorical_accuracy: 0.3988
10496/13806 [=====================>........] - ETA: 2s - loss: 1.4172 - categorical_accuracy: 0.3984
10624/13806 [======================>.......] - ETA: 2s - loss: 1.4174 - categorical_accuracy: 0.3982
10752/13806 [======================>.......] - ETA: 2s - loss: 1.4173 - categorical_accuracy: 0.3987
10880/13806 [======================>.......] - ETA: 2s - loss: 1.4173 - categorical_accuracy: 0.3990
11008/13806 [======================>.......] - ETA: 2s - loss: 1.4179 - categorical_accuracy: 0.3987
11136/13806 [=======================>......] - ETA: 2s - loss: 1.4171 - categorical_accuracy: 0.3985
11264/13806 [=======================>......] - ETA: 2s - loss: 1.4173 - categorical_accuracy: 0.3983
11392/13806 [=======================>......] - ETA: 2s - loss: 1.4166 - categorical_accuracy: 0.3993
11520/13806 [========================>.....] - ETA: 2s - loss: 1.4172 - categorical_accuracy: 0.3990
11648/13806 [========================>.....] - ETA: 1s - loss: 1.4181 - categorical_accuracy: 0.3980
11776/13806 [========================>.....] - ETA: 1s - loss: 1.4175 - categorical_accuracy: 0.3978
11904/13806 [========================>.....] - ETA: 1s - loss: 1.4173 - categorical_accuracy: 0.3979
12032/13806 [=========================>....] - ETA: 1s - loss: 1.4176 - categorical_accuracy: 0.3979
12160/13806 [=========================>....] - ETA: 1s - loss: 1.4174 - categorical_accuracy: 0.3982
12288/13806 [=========================>....] - ETA: 1s - loss: 1.4174 - categorical_accuracy: 0.3980
12416/13806 [=========================>....] - ETA: 1s - loss: 1.4169 - categorical_accuracy: 0.3986
12544/13806 [==========================>...] - ETA: 1s - loss: 1.4177 - categorical_accuracy: 0.3976
12672/13806 [==========================>...] - ETA: 1s - loss: 1.4172 - categorical_accuracy: 0.3983
12800/13806 [==========================>...] - ETA: 0s - loss: 1.4181 - categorical_accuracy: 0.3980
12928/13806 [===========================>..] - ETA: 0s - loss: 1.4182 - categorical_accuracy: 0.3984
13056/13806 [===========================>..] - ETA: 0s - loss: 1.4182 - categorical_accuracy: 0.3986
13184/13806 [===========================>..] - ETA: 0s - loss: 1.4175 - categorical_accuracy: 0.3998
13312/13806 [===========================>..] - ETA: 0s - loss: 1.4170 - categorical_accuracy: 0.3999
13440/13806 [============================>.] - ETA: 0s - loss: 1.4175 - categorical_accuracy: 0.3999
13568/13806 [============================>.] - ETA: 0s - loss: 1.4177 - categorical_accuracy: 0.3997
13696/13806 [============================>.] - ETA: 0s - loss: 1.4176 - categorical_accuracy: 0.3999
13806/13806 [==============================] - 13s 953us/step - loss: 1.4179 - categorical_accuracy: 0.4000 - val_loss: 1.6028 - val_categorical_accuracy: 0.3015

Epoch 00009: val_categorical_accuracy did not improve
Epoch 10/15

  128/13806 [..............................] - ETA: 10s - loss: 1.4890 - categorical_accuracy: 0.3359
  256/13806 [..............................] - ETA: 11s - loss: 1.4105 - categorical_accuracy: 0.3828
  384/13806 [..............................] - ETA: 11s - loss: 1.3970 - categorical_accuracy: 0.3958
  512/13806 [>.............................] - ETA: 11s - loss: 1.3998 - categorical_accuracy: 0.3867
  640/13806 [>.............................] - ETA: 11s - loss: 1.4003 - categorical_accuracy: 0.3953
  768/13806 [>.............................] - ETA: 11s - loss: 1.4134 - categorical_accuracy: 0.3854
  896/13806 [>.............................] - ETA: 11s - loss: 1.4339 - categorical_accuracy: 0.3783
 1024/13806 [=>............................] - ETA: 11s - loss: 1.4379 - categorical_accuracy: 0.3760
 1152/13806 [=>............................] - ETA: 11s - loss: 1.4314 - categorical_accuracy: 0.3785
 1280/13806 [=>............................] - ETA: 11s - loss: 1.4302 - categorical_accuracy: 0.3766
 1408/13806 [==>...........................] - ETA: 11s - loss: 1.4296 - categorical_accuracy: 0.3814
 1536/13806 [==>...........................] - ETA: 11s - loss: 1.4278 - categorical_accuracy: 0.3802
 1664/13806 [==>...........................] - ETA: 11s - loss: 1.4291 - categorical_accuracy: 0.3804
 1792/13806 [==>...........................] - ETA: 11s - loss: 1.4207 - categorical_accuracy: 0.3895
 1920/13806 [===>..........................] - ETA: 10s - loss: 1.4179 - categorical_accuracy: 0.3922
 2048/13806 [===>..........................] - ETA: 10s - loss: 1.4153 - categorical_accuracy: 0.3970
 2176/13806 [===>..........................] - ETA: 10s - loss: 1.4177 - categorical_accuracy: 0.3934
 2304/13806 [====>.........................] - ETA: 10s - loss: 1.4172 - categorical_accuracy: 0.3958
 2432/13806 [====>.........................] - ETA: 10s - loss: 1.4170 - categorical_accuracy: 0.3984
 2560/13806 [====>.........................] - ETA: 10s - loss: 1.4134 - categorical_accuracy: 0.4000
 2688/13806 [====>.........................] - ETA: 10s - loss: 1.4136 - categorical_accuracy: 0.3988
 2816/13806 [=====>........................] - ETA: 10s - loss: 1.4139 - categorical_accuracy: 0.4002
 2944/13806 [=====>........................] - ETA: 9s - loss: 1.4129 - categorical_accuracy: 0.4022 
 3072/13806 [=====>........................] - ETA: 9s - loss: 1.4107 - categorical_accuracy: 0.4030
 3200/13806 [=====>........................] - ETA: 9s - loss: 1.4094 - categorical_accuracy: 0.4028
 3328/13806 [======>.......................] - ETA: 9s - loss: 1.4103 - categorical_accuracy: 0.4026
 3456/13806 [======>.......................] - ETA: 9s - loss: 1.4109 - categorical_accuracy: 0.4031
 3584/13806 [======>.......................] - ETA: 9s - loss: 1.4086 - categorical_accuracy: 0.4037
 3712/13806 [=======>......................] - ETA: 9s - loss: 1.4074 - categorical_accuracy: 0.4041
 3840/13806 [=======>......................] - ETA: 9s - loss: 1.4083 - categorical_accuracy: 0.4029
 3968/13806 [=======>......................] - ETA: 9s - loss: 1.4084 - categorical_accuracy: 0.4025
 4096/13806 [=======>......................] - ETA: 8s - loss: 1.4087 - categorical_accuracy: 0.4023
 4224/13806 [========>.....................] - ETA: 8s - loss: 1.4076 - categorical_accuracy: 0.4032
 4352/13806 [========>.....................] - ETA: 8s - loss: 1.4095 - categorical_accuracy: 0.4019
 4480/13806 [========>.....................] - ETA: 8s - loss: 1.4085 - categorical_accuracy: 0.4033
 4608/13806 [=========>....................] - ETA: 8s - loss: 1.4077 - categorical_accuracy: 0.4039
 4736/13806 [=========>....................] - ETA: 8s - loss: 1.4078 - categorical_accuracy: 0.4037
 4864/13806 [=========>....................] - ETA: 8s - loss: 1.4071 - categorical_accuracy: 0.4060
 4992/13806 [=========>....................] - ETA: 8s - loss: 1.4049 - categorical_accuracy: 0.4085
 5120/13806 [==========>...................] - ETA: 8s - loss: 1.4053 - categorical_accuracy: 0.4082
 5248/13806 [==========>...................] - ETA: 7s - loss: 1.4042 - categorical_accuracy: 0.4085
 5376/13806 [==========>...................] - ETA: 7s - loss: 1.4050 - categorical_accuracy: 0.4072
 5504/13806 [==========>...................] - ETA: 7s - loss: 1.4062 - categorical_accuracy: 0.4053
 5632/13806 [===========>..................] - ETA: 7s - loss: 1.4056 - categorical_accuracy: 0.4052
 5760/13806 [===========>..................] - ETA: 7s - loss: 1.4053 - categorical_accuracy: 0.4054
 5888/13806 [===========>..................] - ETA: 7s - loss: 1.4038 - categorical_accuracy: 0.4051
 6016/13806 [============>.................] - ETA: 7s - loss: 1.4031 - categorical_accuracy: 0.4072
 6144/13806 [============>.................] - ETA: 7s - loss: 1.4038 - categorical_accuracy: 0.4064
 6272/13806 [============>.................] - ETA: 7s - loss: 1.4027 - categorical_accuracy: 0.4070
 6400/13806 [============>.................] - ETA: 6s - loss: 1.4031 - categorical_accuracy: 0.4069
 6528/13806 [=============>................] - ETA: 6s - loss: 1.4020 - categorical_accuracy: 0.4078
 6656/13806 [=============>................] - ETA: 6s - loss: 1.4012 - categorical_accuracy: 0.4087
 6784/13806 [=============>................] - ETA: 6s - loss: 1.4013 - categorical_accuracy: 0.4088
 6912/13806 [==============>...............] - ETA: 6s - loss: 1.4010 - categorical_accuracy: 0.4091
 7040/13806 [==============>...............] - ETA: 6s - loss: 1.4005 - categorical_accuracy: 0.4087
 7168/13806 [==============>...............] - ETA: 6s - loss: 1.4009 - categorical_accuracy: 0.4082
 7296/13806 [==============>...............] - ETA: 6s - loss: 1.4015 - categorical_accuracy: 0.4089
 7424/13806 [===============>..............] - ETA: 5s - loss: 1.4018 - categorical_accuracy: 0.4083
 7552/13806 [===============>..............] - ETA: 5s - loss: 1.4016 - categorical_accuracy: 0.4089
 7680/13806 [===============>..............] - ETA: 5s - loss: 1.4017 - categorical_accuracy: 0.4099
 7808/13806 [===============>..............] - ETA: 5s - loss: 1.4023 - categorical_accuracy: 0.4103
 7936/13806 [================>.............] - ETA: 5s - loss: 1.4015 - categorical_accuracy: 0.4105
 8064/13806 [================>.............] - ETA: 5s - loss: 1.4021 - categorical_accuracy: 0.4089
 8192/13806 [================>.............] - ETA: 5s - loss: 1.4037 - categorical_accuracy: 0.4078
 8320/13806 [=================>............] - ETA: 5s - loss: 1.4039 - categorical_accuracy: 0.4071
 8448/13806 [=================>............] - ETA: 4s - loss: 1.4041 - categorical_accuracy: 0.4079
 8576/13806 [=================>............] - ETA: 4s - loss: 1.4038 - categorical_accuracy: 0.4080
 8704/13806 [=================>............] - ETA: 4s - loss: 1.4030 - categorical_accuracy: 0.4090
 8832/13806 [==================>...........] - ETA: 4s - loss: 1.4031 - categorical_accuracy: 0.4087
 8960/13806 [==================>...........] - ETA: 4s - loss: 1.4043 - categorical_accuracy: 0.4083
 9088/13806 [==================>...........] - ETA: 4s - loss: 1.4047 - categorical_accuracy: 0.4075
 9216/13806 [===================>..........] - ETA: 4s - loss: 1.4048 - categorical_accuracy: 0.4081
 9344/13806 [===================>..........] - ETA: 4s - loss: 1.4054 - categorical_accuracy: 0.4073
 9472/13806 [===================>..........] - ETA: 4s - loss: 1.4058 - categorical_accuracy: 0.4073
 9600/13806 [===================>..........] - ETA: 3s - loss: 1.4050 - categorical_accuracy: 0.4085
 9728/13806 [====================>.........] - ETA: 3s - loss: 1.4053 - categorical_accuracy: 0.4076
 9856/13806 [====================>.........] - ETA: 3s - loss: 1.4048 - categorical_accuracy: 0.4076
 9984/13806 [====================>.........] - ETA: 3s - loss: 1.4043 - categorical_accuracy: 0.4084
10112/13806 [====================>.........] - ETA: 3s - loss: 1.4046 - categorical_accuracy: 0.4079
10240/13806 [=====================>........] - ETA: 3s - loss: 1.4042 - categorical_accuracy: 0.4086
10368/13806 [=====================>........] - ETA: 3s - loss: 1.4038 - categorical_accuracy: 0.4086
10496/13806 [=====================>........] - ETA: 3s - loss: 1.4037 - categorical_accuracy: 0.4085
10624/13806 [======================>.......] - ETA: 2s - loss: 1.4040 - categorical_accuracy: 0.4082
10752/13806 [======================>.......] - ETA: 2s - loss: 1.4045 - categorical_accuracy: 0.4077
10880/13806 [======================>.......] - ETA: 2s - loss: 1.4049 - categorical_accuracy: 0.4073
11008/13806 [======================>.......] - ETA: 2s - loss: 1.4060 - categorical_accuracy: 0.4066
11136/13806 [=======================>......] - ETA: 2s - loss: 1.4060 - categorical_accuracy: 0.4062
11264/13806 [=======================>......] - ETA: 2s - loss: 1.4063 - categorical_accuracy: 0.4055
11392/13806 [=======================>......] - ETA: 2s - loss: 1.4060 - categorical_accuracy: 0.4054
11520/13806 [========================>.....] - ETA: 2s - loss: 1.4057 - categorical_accuracy: 0.4058
11648/13806 [========================>.....] - ETA: 1s - loss: 1.4058 - categorical_accuracy: 0.4053
11776/13806 [========================>.....] - ETA: 1s - loss: 1.4056 - categorical_accuracy: 0.4059
11904/13806 [========================>.....] - ETA: 1s - loss: 1.4057 - categorical_accuracy: 0.4062
12032/13806 [=========================>....] - ETA: 1s - loss: 1.4059 - categorical_accuracy: 0.4062
12160/13806 [=========================>....] - ETA: 1s - loss: 1.4054 - categorical_accuracy: 0.4066
12288/13806 [=========================>....] - ETA: 1s - loss: 1.4059 - categorical_accuracy: 0.4061
12416/13806 [=========================>....] - ETA: 1s - loss: 1.4065 - categorical_accuracy: 0.4053
12544/13806 [==========================>...] - ETA: 1s - loss: 1.4065 - categorical_accuracy: 0.4059
12672/13806 [==========================>...] - ETA: 1s - loss: 1.4071 - categorical_accuracy: 0.4054
12800/13806 [==========================>...] - ETA: 0s - loss: 1.4069 - categorical_accuracy: 0.4055
12928/13806 [===========================>..] - ETA: 0s - loss: 1.4065 - categorical_accuracy: 0.4055
13056/13806 [===========================>..] - ETA: 0s - loss: 1.4071 - categorical_accuracy: 0.4051
13184/13806 [===========================>..] - ETA: 0s - loss: 1.4071 - categorical_accuracy: 0.4044
13312/13806 [===========================>..] - ETA: 0s - loss: 1.4069 - categorical_accuracy: 0.4047
13440/13806 [============================>.] - ETA: 0s - loss: 1.4067 - categorical_accuracy: 0.4047
13568/13806 [============================>.] - ETA: 0s - loss: 1.4065 - categorical_accuracy: 0.4052
13696/13806 [============================>.] - ETA: 0s - loss: 1.4067 - categorical_accuracy: 0.4054
13806/13806 [==============================] - 13s 971us/step - loss: 1.4066 - categorical_accuracy: 0.4052 - val_loss: 1.5760 - val_categorical_accuracy: 0.3068

Epoch 00010: val_categorical_accuracy did not improve
Epoch 11/15

  128/13806 [..............................] - ETA: 11s - loss: 1.3045 - categorical_accuracy: 0.4453
  256/13806 [..............................] - ETA: 12s - loss: 1.3124 - categorical_accuracy: 0.4922
  384/13806 [..............................] - ETA: 11s - loss: 1.3358 - categorical_accuracy: 0.4714
  512/13806 [>.............................] - ETA: 11s - loss: 1.3499 - categorical_accuracy: 0.4629
  640/13806 [>.............................] - ETA: 12s - loss: 1.3740 - categorical_accuracy: 0.4437
  768/13806 [>.............................] - ETA: 12s - loss: 1.3825 - categorical_accuracy: 0.4349
  896/13806 [>.............................] - ETA: 11s - loss: 1.3904 - categorical_accuracy: 0.4219
 1024/13806 [=>............................] - ETA: 11s - loss: 1.3964 - categorical_accuracy: 0.4170
 1152/13806 [=>............................] - ETA: 11s - loss: 1.3945 - categorical_accuracy: 0.4149
 1280/13806 [=>............................] - ETA: 11s - loss: 1.3865 - categorical_accuracy: 0.4234
 1408/13806 [==>...........................] - ETA: 11s - loss: 1.3904 - categorical_accuracy: 0.4183
 1536/13806 [==>...........................] - ETA: 11s - loss: 1.3946 - categorical_accuracy: 0.4128
 1664/13806 [==>...........................] - ETA: 11s - loss: 1.3998 - categorical_accuracy: 0.4093
 1792/13806 [==>...........................] - ETA: 11s - loss: 1.3979 - categorical_accuracy: 0.4096
 1920/13806 [===>..........................] - ETA: 11s - loss: 1.3976 - categorical_accuracy: 0.4115
 2048/13806 [===>..........................] - ETA: 11s - loss: 1.3978 - categorical_accuracy: 0.4087
 2176/13806 [===>..........................] - ETA: 10s - loss: 1.3959 - categorical_accuracy: 0.4081
 2304/13806 [====>.........................] - ETA: 10s - loss: 1.3953 - categorical_accuracy: 0.4084
 2432/13806 [====>.........................] - ETA: 10s - loss: 1.3979 - categorical_accuracy: 0.4091
 2560/13806 [====>.........................] - ETA: 10s - loss: 1.3992 - categorical_accuracy: 0.4082
 2688/13806 [====>.........................] - ETA: 10s - loss: 1.3977 - categorical_accuracy: 0.4103
 2816/13806 [=====>........................] - ETA: 10s - loss: 1.3976 - categorical_accuracy: 0.4084
 2944/13806 [=====>........................] - ETA: 10s - loss: 1.3955 - categorical_accuracy: 0.4093
 3072/13806 [=====>........................] - ETA: 10s - loss: 1.3950 - categorical_accuracy: 0.4095
 3200/13806 [=====>........................] - ETA: 9s - loss: 1.3931 - categorical_accuracy: 0.4113 
 3328/13806 [======>.......................] - ETA: 9s - loss: 1.3926 - categorical_accuracy: 0.4117
 3456/13806 [======>.......................] - ETA: 9s - loss: 1.3955 - categorical_accuracy: 0.4100
 3584/13806 [======>.......................] - ETA: 9s - loss: 1.3932 - categorical_accuracy: 0.4107
 3712/13806 [=======>......................] - ETA: 9s - loss: 1.3924 - categorical_accuracy: 0.4119
 3840/13806 [=======>......................] - ETA: 9s - loss: 1.3916 - categorical_accuracy: 0.4148
 3968/13806 [=======>......................] - ETA: 8s - loss: 1.3919 - categorical_accuracy: 0.4151
 4096/13806 [=======>......................] - ETA: 8s - loss: 1.3932 - categorical_accuracy: 0.4126
 4224/13806 [========>.....................] - ETA: 8s - loss: 1.3939 - categorical_accuracy: 0.4119
 4352/13806 [========>.....................] - ETA: 8s - loss: 1.3973 - categorical_accuracy: 0.4088
 4480/13806 [========>.....................] - ETA: 8s - loss: 1.3943 - categorical_accuracy: 0.4123
 4608/13806 [=========>....................] - ETA: 8s - loss: 1.3938 - categorical_accuracy: 0.4141
 4736/13806 [=========>....................] - ETA: 8s - loss: 1.3928 - categorical_accuracy: 0.4141
 4864/13806 [=========>....................] - ETA: 8s - loss: 1.3930 - categorical_accuracy: 0.4139
 4992/13806 [=========>....................] - ETA: 8s - loss: 1.3951 - categorical_accuracy: 0.4127
 5120/13806 [==========>...................] - ETA: 7s - loss: 1.3955 - categorical_accuracy: 0.4109
 5248/13806 [==========>...................] - ETA: 7s - loss: 1.3957 - categorical_accuracy: 0.4093
 5376/13806 [==========>...................] - ETA: 7s - loss: 1.3964 - categorical_accuracy: 0.4094
 5504/13806 [==========>...................] - ETA: 7s - loss: 1.3964 - categorical_accuracy: 0.4092
 5632/13806 [===========>..................] - ETA: 7s - loss: 1.3959 - categorical_accuracy: 0.4103
 5760/13806 [===========>..................] - ETA: 7s - loss: 1.3972 - categorical_accuracy: 0.4078
 5888/13806 [===========>..................] - ETA: 7s - loss: 1.3966 - categorical_accuracy: 0.4083
 6016/13806 [============>.................] - ETA: 7s - loss: 1.3956 - categorical_accuracy: 0.4097
 6144/13806 [============>.................] - ETA: 6s - loss: 1.3971 - categorical_accuracy: 0.4087
 6272/13806 [============>.................] - ETA: 6s - loss: 1.3962 - categorical_accuracy: 0.4083
 6400/13806 [============>.................] - ETA: 6s - loss: 1.3957 - categorical_accuracy: 0.4083
 6528/13806 [=============>................] - ETA: 6s - loss: 1.3968 - categorical_accuracy: 0.4081
 6656/13806 [=============>................] - ETA: 6s - loss: 1.3961 - categorical_accuracy: 0.4081
 6784/13806 [=============>................] - ETA: 6s - loss: 1.3959 - categorical_accuracy: 0.4080
 6912/13806 [==============>...............] - ETA: 6s - loss: 1.3952 - categorical_accuracy: 0.4083
 7040/13806 [==============>...............] - ETA: 6s - loss: 1.3947 - categorical_accuracy: 0.4085
 7168/13806 [==============>...............] - ETA: 6s - loss: 1.3939 - categorical_accuracy: 0.4086
 7296/13806 [==============>...............] - ETA: 5s - loss: 1.3950 - categorical_accuracy: 0.4086
 7424/13806 [===============>..............] - ETA: 5s - loss: 1.3940 - categorical_accuracy: 0.4096
 7552/13806 [===============>..............] - ETA: 5s - loss: 1.3940 - categorical_accuracy: 0.4100
 7680/13806 [===============>..............] - ETA: 5s - loss: 1.3934 - categorical_accuracy: 0.4107
 7808/13806 [===============>..............] - ETA: 5s - loss: 1.3935 - categorical_accuracy: 0.4105
 7936/13806 [================>.............] - ETA: 5s - loss: 1.3932 - categorical_accuracy: 0.4113
 8064/13806 [================>.............] - ETA: 5s - loss: 1.3930 - categorical_accuracy: 0.4117
 8192/13806 [================>.............] - ETA: 5s - loss: 1.3927 - categorical_accuracy: 0.4110
 8320/13806 [=================>............] - ETA: 5s - loss: 1.3922 - categorical_accuracy: 0.4107
 8448/13806 [=================>............] - ETA: 4s - loss: 1.3928 - categorical_accuracy: 0.4111
 8576/13806 [=================>............] - ETA: 4s - loss: 1.3927 - categorical_accuracy: 0.4124
 8704/13806 [=================>............] - ETA: 4s - loss: 1.3917 - categorical_accuracy: 0.4131
 8832/13806 [==================>...........] - ETA: 4s - loss: 1.3913 - categorical_accuracy: 0.4136
 8960/13806 [==================>...........] - ETA: 4s - loss: 1.3914 - categorical_accuracy: 0.4137
 9088/13806 [==================>...........] - ETA: 4s - loss: 1.3916 - categorical_accuracy: 0.4130
 9216/13806 [===================>..........] - ETA: 4s - loss: 1.3926 - categorical_accuracy: 0.4125
 9344/13806 [===================>..........] - ETA: 4s - loss: 1.3930 - categorical_accuracy: 0.4120
 9472/13806 [===================>..........] - ETA: 3s - loss: 1.3928 - categorical_accuracy: 0.4123
 9600/13806 [===================>..........] - ETA: 3s - loss: 1.3931 - categorical_accuracy: 0.4123
 9728/13806 [====================>.........] - ETA: 3s - loss: 1.3933 - categorical_accuracy: 0.4125
 9856/13806 [====================>.........] - ETA: 3s - loss: 1.3940 - categorical_accuracy: 0.4115
 9984/13806 [====================>.........] - ETA: 3s - loss: 1.3945 - categorical_accuracy: 0.4114
10112/13806 [====================>.........] - ETA: 3s - loss: 1.3943 - categorical_accuracy: 0.4115
10240/13806 [=====================>........] - ETA: 3s - loss: 1.3951 - categorical_accuracy: 0.4109
10368/13806 [=====================>........] - ETA: 3s - loss: 1.3955 - categorical_accuracy: 0.4103
10496/13806 [=====================>........] - ETA: 3s - loss: 1.3956 - categorical_accuracy: 0.4103
10624/13806 [======================>.......] - ETA: 2s - loss: 1.3955 - categorical_accuracy: 0.4101
10752/13806 [======================>.......] - ETA: 2s - loss: 1.3952 - categorical_accuracy: 0.4109
10880/13806 [======================>.......] - ETA: 2s - loss: 1.3944 - categorical_accuracy: 0.4116
11008/13806 [======================>.......] - ETA: 2s - loss: 1.3945 - categorical_accuracy: 0.4106
11136/13806 [=======================>......] - ETA: 2s - loss: 1.3939 - categorical_accuracy: 0.4104
11264/13806 [=======================>......] - ETA: 2s - loss: 1.3935 - categorical_accuracy: 0.4104
11392/13806 [=======================>......] - ETA: 2s - loss: 1.3939 - categorical_accuracy: 0.4103
11520/13806 [========================>.....] - ETA: 2s - loss: 1.3945 - categorical_accuracy: 0.4100
11648/13806 [========================>.....] - ETA: 1s - loss: 1.3958 - categorical_accuracy: 0.4090
11776/13806 [========================>.....] - ETA: 1s - loss: 1.3960 - categorical_accuracy: 0.4089
11904/13806 [========================>.....] - ETA: 1s - loss: 1.3959 - categorical_accuracy: 0.4092
12032/13806 [=========================>....] - ETA: 1s - loss: 1.3956 - categorical_accuracy: 0.4097
12160/13806 [=========================>....] - ETA: 1s - loss: 1.3954 - categorical_accuracy: 0.4101
12288/13806 [=========================>....] - ETA: 1s - loss: 1.3952 - categorical_accuracy: 0.4103
12416/13806 [=========================>....] - ETA: 1s - loss: 1.3951 - categorical_accuracy: 0.4104
12544/13806 [==========================>...] - ETA: 1s - loss: 1.3954 - categorical_accuracy: 0.4099
12672/13806 [==========================>...] - ETA: 1s - loss: 1.3957 - categorical_accuracy: 0.4100
12800/13806 [==========================>...] - ETA: 0s - loss: 1.3955 - categorical_accuracy: 0.4098
12928/13806 [===========================>..] - ETA: 0s - loss: 1.3954 - categorical_accuracy: 0.4101
13056/13806 [===========================>..] - ETA: 0s - loss: 1.3953 - categorical_accuracy: 0.4103
13184/13806 [===========================>..] - ETA: 0s - loss: 1.3950 - categorical_accuracy: 0.4103
13312/13806 [===========================>..] - ETA: 0s - loss: 1.3953 - categorical_accuracy: 0.4103
13440/13806 [============================>.] - ETA: 0s - loss: 1.3953 - categorical_accuracy: 0.4108
13568/13806 [============================>.] - ETA: 0s - loss: 1.3955 - categorical_accuracy: 0.4108
13696/13806 [============================>.] - ETA: 0s - loss: 1.3950 - categorical_accuracy: 0.4114
13806/13806 [==============================] - 13s 963us/step - loss: 1.3948 - categorical_accuracy: 0.4114 - val_loss: 1.6034 - val_categorical_accuracy: 0.3247

Epoch 00011: val_categorical_accuracy improved from 0.31279 to 0.32472, saving model to results/vardial2018/multi_input_char_only/model_weights.hdf5
Epoch 12/15

  128/13806 [..............................] - ETA: 11s - loss: 1.4312 - categorical_accuracy: 0.3984
  256/13806 [..............................] - ETA: 12s - loss: 1.3920 - categorical_accuracy: 0.4180
  384/13806 [..............................] - ETA: 12s - loss: 1.3538 - categorical_accuracy: 0.4609
  512/13806 [>.............................] - ETA: 12s - loss: 1.3545 - categorical_accuracy: 0.4590
  640/13806 [>.............................] - ETA: 12s - loss: 1.3679 - categorical_accuracy: 0.4484
  768/13806 [>.............................] - ETA: 12s - loss: 1.3767 - categorical_accuracy: 0.4401
  896/13806 [>.............................] - ETA: 12s - loss: 1.3778 - categorical_accuracy: 0.4453
 1024/13806 [=>............................] - ETA: 11s - loss: 1.3843 - categorical_accuracy: 0.4395
 1152/13806 [=>............................] - ETA: 11s - loss: 1.3825 - categorical_accuracy: 0.4358
 1280/13806 [=>............................] - ETA: 11s - loss: 1.3862 - categorical_accuracy: 0.4313
 1408/13806 [==>...........................] - ETA: 11s - loss: 1.3861 - categorical_accuracy: 0.4297
 1536/13806 [==>...........................] - ETA: 11s - loss: 1.3843 - categorical_accuracy: 0.4342
 1664/13806 [==>...........................] - ETA: 11s - loss: 1.3812 - categorical_accuracy: 0.4333
 1792/13806 [==>...........................] - ETA: 11s - loss: 1.3824 - categorical_accuracy: 0.4353
 1920/13806 [===>..........................] - ETA: 10s - loss: 1.3819 - categorical_accuracy: 0.4354
 2048/13806 [===>..........................] - ETA: 10s - loss: 1.3800 - categorical_accuracy: 0.4360
 2176/13806 [===>..........................] - ETA: 10s - loss: 1.3847 - categorical_accuracy: 0.4324
 2304/13806 [====>.........................] - ETA: 10s - loss: 1.3842 - categorical_accuracy: 0.4332
 2432/13806 [====>.........................] - ETA: 10s - loss: 1.3811 - categorical_accuracy: 0.4379
 2560/13806 [====>.........................] - ETA: 10s - loss: 1.3802 - categorical_accuracy: 0.4395
 2688/13806 [====>.........................] - ETA: 9s - loss: 1.3808 - categorical_accuracy: 0.4408 
 2816/13806 [=====>........................] - ETA: 9s - loss: 1.3809 - categorical_accuracy: 0.4396
 2944/13806 [=====>........................] - ETA: 9s - loss: 1.3814 - categorical_accuracy: 0.4378
 3072/13806 [=====>........................] - ETA: 9s - loss: 1.3831 - categorical_accuracy: 0.4349
 3200/13806 [=====>........................] - ETA: 9s - loss: 1.3821 - categorical_accuracy: 0.4350
 3328/13806 [======>.......................] - ETA: 9s - loss: 1.3796 - categorical_accuracy: 0.4387
 3456/13806 [======>.......................] - ETA: 9s - loss: 1.3799 - categorical_accuracy: 0.4387
 3584/13806 [======>.......................] - ETA: 9s - loss: 1.3784 - categorical_accuracy: 0.4392
 3712/13806 [=======>......................] - ETA: 9s - loss: 1.3791 - categorical_accuracy: 0.4375
 3840/13806 [=======>......................] - ETA: 8s - loss: 1.3766 - categorical_accuracy: 0.4375
 3968/13806 [=======>......................] - ETA: 8s - loss: 1.3771 - categorical_accuracy: 0.4360
 4096/13806 [=======>......................] - ETA: 8s - loss: 1.3773 - categorical_accuracy: 0.4353
 4224/13806 [========>.....................] - ETA: 8s - loss: 1.3785 - categorical_accuracy: 0.4342
 4352/13806 [========>.....................] - ETA: 8s - loss: 1.3782 - categorical_accuracy: 0.4324
 4480/13806 [========>.....................] - ETA: 8s - loss: 1.3777 - categorical_accuracy: 0.4337
 4608/13806 [=========>....................] - ETA: 8s - loss: 1.3805 - categorical_accuracy: 0.4325
 4736/13806 [=========>....................] - ETA: 8s - loss: 1.3806 - categorical_accuracy: 0.4324
 4864/13806 [=========>....................] - ETA: 8s - loss: 1.3820 - categorical_accuracy: 0.4301
 4992/13806 [=========>....................] - ETA: 8s - loss: 1.3820 - categorical_accuracy: 0.4293
 5120/13806 [==========>...................] - ETA: 7s - loss: 1.3820 - categorical_accuracy: 0.4279
 5248/13806 [==========>...................] - ETA: 7s - loss: 1.3815 - categorical_accuracy: 0.4276
 5376/13806 [==========>...................] - ETA: 7s - loss: 1.3825 - categorical_accuracy: 0.4271
 5504/13806 [==========>...................] - ETA: 7s - loss: 1.3824 - categorical_accuracy: 0.4266
 5632/13806 [===========>..................] - ETA: 7s - loss: 1.3834 - categorical_accuracy: 0.4263
 5760/13806 [===========>..................] - ETA: 7s - loss: 1.3828 - categorical_accuracy: 0.4255
 5888/13806 [===========>..................] - ETA: 7s - loss: 1.3823 - categorical_accuracy: 0.4246
 6016/13806 [============>.................] - ETA: 7s - loss: 1.3832 - categorical_accuracy: 0.4235
 6144/13806 [============>.................] - ETA: 7s - loss: 1.3837 - categorical_accuracy: 0.4224
 6272/13806 [============>.................] - ETA: 6s - loss: 1.3840 - categorical_accuracy: 0.4219
 6400/13806 [============>.................] - ETA: 6s - loss: 1.3843 - categorical_accuracy: 0.4222
 6528/13806 [=============>................] - ETA: 6s - loss: 1.3840 - categorical_accuracy: 0.4219
 6656/13806 [=============>................] - ETA: 6s - loss: 1.3857 - categorical_accuracy: 0.4211
 6784/13806 [=============>................] - ETA: 6s - loss: 1.3862 - categorical_accuracy: 0.4207
 6912/13806 [==============>...............] - ETA: 6s - loss: 1.3863 - categorical_accuracy: 0.4209
 7040/13806 [==============>...............] - ETA: 6s - loss: 1.3858 - categorical_accuracy: 0.4210
 7168/13806 [==============>...............] - ETA: 6s - loss: 1.3858 - categorical_accuracy: 0.4210
 7296/13806 [==============>...............] - ETA: 6s - loss: 1.3868 - categorical_accuracy: 0.4204
 7424/13806 [===============>..............] - ETA: 5s - loss: 1.3874 - categorical_accuracy: 0.4199
 7552/13806 [===============>..............] - ETA: 5s - loss: 1.3884 - categorical_accuracy: 0.4199
 7680/13806 [===============>..............] - ETA: 5s - loss: 1.3888 - categorical_accuracy: 0.4201
 7808/13806 [===============>..............] - ETA: 5s - loss: 1.3880 - categorical_accuracy: 0.4207
 7936/13806 [================>.............] - ETA: 5s - loss: 1.3878 - categorical_accuracy: 0.4207
 8064/13806 [================>.............] - ETA: 5s - loss: 1.3864 - categorical_accuracy: 0.4218
 8192/13806 [================>.............] - ETA: 5s - loss: 1.3868 - categorical_accuracy: 0.4208
 8320/13806 [=================>............] - ETA: 5s - loss: 1.3878 - categorical_accuracy: 0.4201
 8448/13806 [=================>............] - ETA: 4s - loss: 1.3877 - categorical_accuracy: 0.4201
 8576/13806 [=================>............] - ETA: 4s - loss: 1.3872 - categorical_accuracy: 0.4205
 8704/13806 [=================>............] - ETA: 4s - loss: 1.3865 - categorical_accuracy: 0.4216
 8832/13806 [==================>...........] - ETA: 4s - loss: 1.3865 - categorical_accuracy: 0.4218
 8960/13806 [==================>...........] - ETA: 4s - loss: 1.3853 - categorical_accuracy: 0.4224
 9088/13806 [==================>...........] - ETA: 4s - loss: 1.3855 - categorical_accuracy: 0.4217
 9216/13806 [===================>..........] - ETA: 4s - loss: 1.3860 - categorical_accuracy: 0.4204
 9344/13806 [===================>..........] - ETA: 4s - loss: 1.3850 - categorical_accuracy: 0.4214
 9472/13806 [===================>..........] - ETA: 4s - loss: 1.3846 - categorical_accuracy: 0.4221
 9600/13806 [===================>..........] - ETA: 3s - loss: 1.3842 - categorical_accuracy: 0.4228
 9728/13806 [====================>.........] - ETA: 3s - loss: 1.3838 - categorical_accuracy: 0.4224
 9856/13806 [====================>.........] - ETA: 3s - loss: 1.3834 - categorical_accuracy: 0.4225
 9984/13806 [====================>.........] - ETA: 3s - loss: 1.3826 - categorical_accuracy: 0.4232
10112/13806 [====================>.........] - ETA: 3s - loss: 1.3828 - categorical_accuracy: 0.4226
10240/13806 [=====================>........] - ETA: 3s - loss: 1.3822 - categorical_accuracy: 0.4227
10368/13806 [=====================>........] - ETA: 3s - loss: 1.3824 - categorical_accuracy: 0.4226
10496/13806 [=====================>........] - ETA: 3s - loss: 1.3821 - categorical_accuracy: 0.4237
10624/13806 [======================>.......] - ETA: 2s - loss: 1.3816 - categorical_accuracy: 0.4242
10752/13806 [======================>.......] - ETA: 2s - loss: 1.3811 - categorical_accuracy: 0.4239
10880/13806 [======================>.......] - ETA: 2s - loss: 1.3809 - categorical_accuracy: 0.4243
11008/13806 [======================>.......] - ETA: 2s - loss: 1.3816 - categorical_accuracy: 0.4237
11136/13806 [=======================>......] - ETA: 2s - loss: 1.3824 - categorical_accuracy: 0.4230
11264/13806 [=======================>......] - ETA: 2s - loss: 1.3822 - categorical_accuracy: 0.4235
11392/13806 [=======================>......] - ETA: 2s - loss: 1.3822 - categorical_accuracy: 0.4233
11520/13806 [========================>.....] - ETA: 2s - loss: 1.3820 - categorical_accuracy: 0.4227
11648/13806 [========================>.....] - ETA: 2s - loss: 1.3816 - categorical_accuracy: 0.4227
11776/13806 [========================>.....] - ETA: 1s - loss: 1.3816 - categorical_accuracy: 0.4226
11904/13806 [========================>.....] - ETA: 1s - loss: 1.3824 - categorical_accuracy: 0.4219
12032/13806 [=========================>....] - ETA: 1s - loss: 1.3820 - categorical_accuracy: 0.4220
12160/13806 [=========================>....] - ETA: 1s - loss: 1.3825 - categorical_accuracy: 0.4215
12288/13806 [=========================>....] - ETA: 1s - loss: 1.3824 - categorical_accuracy: 0.4218
12416/13806 [=========================>....] - ETA: 1s - loss: 1.3825 - categorical_accuracy: 0.4212
12544/13806 [==========================>...] - ETA: 1s - loss: 1.3819 - categorical_accuracy: 0.4218
12672/13806 [==========================>...] - ETA: 1s - loss: 1.3819 - categorical_accuracy: 0.4216
12800/13806 [==========================>...] - ETA: 0s - loss: 1.3822 - categorical_accuracy: 0.4207
12928/13806 [===========================>..] - ETA: 0s - loss: 1.3830 - categorical_accuracy: 0.4200
13056/13806 [===========================>..] - ETA: 0s - loss: 1.3832 - categorical_accuracy: 0.4200
13184/13806 [===========================>..] - ETA: 0s - loss: 1.3833 - categorical_accuracy: 0.4198
13312/13806 [===========================>..] - ETA: 0s - loss: 1.3840 - categorical_accuracy: 0.4191
13440/13806 [============================>.] - ETA: 0s - loss: 1.3832 - categorical_accuracy: 0.4196
13568/13806 [============================>.] - ETA: 0s - loss: 1.3839 - categorical_accuracy: 0.4189
13696/13806 [============================>.] - ETA: 0s - loss: 1.3839 - categorical_accuracy: 0.4184
13806/13806 [==============================] - 14s 987us/step - loss: 1.3840 - categorical_accuracy: 0.4184 - val_loss: 1.5857 - val_categorical_accuracy: 0.3135

Epoch 00012: val_categorical_accuracy did not improve
Epoch 13/15

  128/13806 [..............................] - ETA: 13s - loss: 1.3770 - categorical_accuracy: 0.4453
  256/13806 [..............................] - ETA: 12s - loss: 1.3424 - categorical_accuracy: 0.4766
  384/13806 [..............................] - ETA: 12s - loss: 1.3610 - categorical_accuracy: 0.4427
  512/13806 [>.............................] - ETA: 12s - loss: 1.3849 - categorical_accuracy: 0.4355
  640/13806 [>.............................] - ETA: 12s - loss: 1.3831 - categorical_accuracy: 0.4281
  768/13806 [>.............................] - ETA: 12s - loss: 1.3790 - categorical_accuracy: 0.4284
  896/13806 [>.............................] - ETA: 12s - loss: 1.3806 - categorical_accuracy: 0.4230
 1024/13806 [=>............................] - ETA: 12s - loss: 1.3739 - categorical_accuracy: 0.4268
 1152/13806 [=>............................] - ETA: 12s - loss: 1.3730 - categorical_accuracy: 0.4236
 1280/13806 [=>............................] - ETA: 11s - loss: 1.3757 - categorical_accuracy: 0.4250
 1408/13806 [==>...........................] - ETA: 11s - loss: 1.3750 - categorical_accuracy: 0.4268
 1536/13806 [==>...........................] - ETA: 11s - loss: 1.3738 - categorical_accuracy: 0.4225
 1664/13806 [==>...........................] - ETA: 11s - loss: 1.3776 - categorical_accuracy: 0.4189
 1792/13806 [==>...........................] - ETA: 11s - loss: 1.3798 - categorical_accuracy: 0.4180
 1920/13806 [===>..........................] - ETA: 10s - loss: 1.3829 - categorical_accuracy: 0.4172
 2048/13806 [===>..........................] - ETA: 10s - loss: 1.3810 - categorical_accuracy: 0.4219
 2176/13806 [===>..........................] - ETA: 10s - loss: 1.3819 - categorical_accuracy: 0.4219
 2304/13806 [====>.........................] - ETA: 10s - loss: 1.3859 - categorical_accuracy: 0.4175
 2432/13806 [====>.........................] - ETA: 9s - loss: 1.3815 - categorical_accuracy: 0.4186 
 2560/13806 [====>.........................] - ETA: 9s - loss: 1.3798 - categorical_accuracy: 0.4191
 2688/13806 [====>.........................] - ETA: 9s - loss: 1.3825 - categorical_accuracy: 0.4170
 2816/13806 [=====>........................] - ETA: 9s - loss: 1.3840 - categorical_accuracy: 0.4141
 2944/13806 [=====>........................] - ETA: 9s - loss: 1.3829 - categorical_accuracy: 0.4147
 3072/13806 [=====>........................] - ETA: 9s - loss: 1.3817 - categorical_accuracy: 0.4131
 3200/13806 [=====>........................] - ETA: 9s - loss: 1.3784 - categorical_accuracy: 0.4166
 3328/13806 [======>.......................] - ETA: 9s - loss: 1.3790 - categorical_accuracy: 0.4156
 3456/13806 [======>.......................] - ETA: 8s - loss: 1.3773 - categorical_accuracy: 0.4172
 3584/13806 [======>.......................] - ETA: 8s - loss: 1.3776 - categorical_accuracy: 0.4174
 3712/13806 [=======>......................] - ETA: 8s - loss: 1.3776 - categorical_accuracy: 0.4162
 3840/13806 [=======>......................] - ETA: 8s - loss: 1.3763 - categorical_accuracy: 0.4159
 3968/13806 [=======>......................] - ETA: 8s - loss: 1.3753 - categorical_accuracy: 0.4178
 4096/13806 [=======>......................] - ETA: 8s - loss: 1.3759 - categorical_accuracy: 0.4160
 4224/13806 [========>.....................] - ETA: 8s - loss: 1.3788 - categorical_accuracy: 0.4143
 4352/13806 [========>.....................] - ETA: 8s - loss: 1.3784 - categorical_accuracy: 0.4159
 4480/13806 [========>.....................] - ETA: 8s - loss: 1.3771 - categorical_accuracy: 0.4172
 4608/13806 [=========>....................] - ETA: 8s - loss: 1.3779 - categorical_accuracy: 0.4175
 4736/13806 [=========>....................] - ETA: 7s - loss: 1.3777 - categorical_accuracy: 0.4166
 4864/13806 [=========>....................] - ETA: 7s - loss: 1.3773 - categorical_accuracy: 0.4182
 4992/13806 [=========>....................] - ETA: 7s - loss: 1.3773 - categorical_accuracy: 0.4167
 5120/13806 [==========>...................] - ETA: 7s - loss: 1.3749 - categorical_accuracy: 0.4176
 5248/13806 [==========>...................] - ETA: 7s - loss: 1.3753 - categorical_accuracy: 0.4163
 5376/13806 [==========>...................] - ETA: 7s - loss: 1.3758 - categorical_accuracy: 0.4172
 5504/13806 [==========>...................] - ETA: 7s - loss: 1.3752 - categorical_accuracy: 0.4172
 5632/13806 [===========>..................] - ETA: 7s - loss: 1.3751 - categorical_accuracy: 0.4174
 5760/13806 [===========>..................] - ETA: 7s - loss: 1.3756 - categorical_accuracy: 0.4179
 5888/13806 [===========>..................] - ETA: 7s - loss: 1.3758 - categorical_accuracy: 0.4168
 6016/13806 [============>.................] - ETA: 6s - loss: 1.3768 - categorical_accuracy: 0.4162
 6144/13806 [============>.................] - ETA: 6s - loss: 1.3767 - categorical_accuracy: 0.4170
 6272/13806 [============>.................] - ETA: 6s - loss: 1.3755 - categorical_accuracy: 0.4188
 6400/13806 [============>.................] - ETA: 6s - loss: 1.3757 - categorical_accuracy: 0.4192
 6528/13806 [=============>................] - ETA: 6s - loss: 1.3771 - categorical_accuracy: 0.4179
 6656/13806 [=============>................] - ETA: 6s - loss: 1.3777 - categorical_accuracy: 0.4177
 6784/13806 [=============>................] - ETA: 6s - loss: 1.3784 - categorical_accuracy: 0.4176
 6912/13806 [==============>...............] - ETA: 6s - loss: 1.3779 - categorical_accuracy: 0.4178
 7040/13806 [==============>...............] - ETA: 6s - loss: 1.3778 - categorical_accuracy: 0.4178
 7168/13806 [==============>...............] - ETA: 5s - loss: 1.3769 - categorical_accuracy: 0.4187
 7296/13806 [==============>...............] - ETA: 5s - loss: 1.3768 - categorical_accuracy: 0.4180
 7424/13806 [===============>..............] - ETA: 5s - loss: 1.3772 - categorical_accuracy: 0.4185
 7552/13806 [===============>..............] - ETA: 5s - loss: 1.3768 - categorical_accuracy: 0.4182
 7680/13806 [===============>..............] - ETA: 5s - loss: 1.3774 - categorical_accuracy: 0.4181
 7808/13806 [===============>..............] - ETA: 5s - loss: 1.3765 - categorical_accuracy: 0.4188
 7936/13806 [================>.............] - ETA: 5s - loss: 1.3764 - categorical_accuracy: 0.4190
 8064/13806 [================>.............] - ETA: 5s - loss: 1.3765 - categorical_accuracy: 0.4198
 8192/13806 [================>.............] - ETA: 5s - loss: 1.3756 - categorical_accuracy: 0.4204
 8320/13806 [=================>............] - ETA: 4s - loss: 1.3761 - categorical_accuracy: 0.4196
 8448/13806 [=================>............] - ETA: 4s - loss: 1.3756 - categorical_accuracy: 0.4196
 8576/13806 [=================>............] - ETA: 4s - loss: 1.3758 - categorical_accuracy: 0.4191
 8704/13806 [=================>............] - ETA: 4s - loss: 1.3755 - categorical_accuracy: 0.4195
 8832/13806 [==================>...........] - ETA: 4s - loss: 1.3754 - categorical_accuracy: 0.4194
 8960/13806 [==================>...........] - ETA: 4s - loss: 1.3751 - categorical_accuracy: 0.4200
 9088/13806 [==================>...........] - ETA: 4s - loss: 1.3754 - categorical_accuracy: 0.4202
 9216/13806 [===================>..........] - ETA: 4s - loss: 1.3755 - categorical_accuracy: 0.4201
 9344/13806 [===================>..........] - ETA: 4s - loss: 1.3736 - categorical_accuracy: 0.4214
 9472/13806 [===================>..........] - ETA: 3s - loss: 1.3730 - categorical_accuracy: 0.4223
 9600/13806 [===================>..........] - ETA: 3s - loss: 1.3746 - categorical_accuracy: 0.4216
 9728/13806 [====================>.........] - ETA: 3s - loss: 1.3742 - categorical_accuracy: 0.4219
 9856/13806 [====================>.........] - ETA: 3s - loss: 1.3743 - categorical_accuracy: 0.4219
 9984/13806 [====================>.........] - ETA: 3s - loss: 1.3750 - categorical_accuracy: 0.4218
10112/13806 [====================>.........] - ETA: 3s - loss: 1.3744 - categorical_accuracy: 0.4219
10240/13806 [=====================>........] - ETA: 3s - loss: 1.3742 - categorical_accuracy: 0.4217
10368/13806 [=====================>........] - ETA: 3s - loss: 1.3747 - categorical_accuracy: 0.4218
10496/13806 [=====================>........] - ETA: 2s - loss: 1.3746 - categorical_accuracy: 0.4222
10624/13806 [======================>.......] - ETA: 2s - loss: 1.3737 - categorical_accuracy: 0.4230
10752/13806 [======================>.......] - ETA: 2s - loss: 1.3748 - categorical_accuracy: 0.4228
10880/13806 [======================>.......] - ETA: 2s - loss: 1.3737 - categorical_accuracy: 0.4240
11008/13806 [======================>.......] - ETA: 2s - loss: 1.3741 - categorical_accuracy: 0.4238
11136/13806 [=======================>......] - ETA: 2s - loss: 1.3749 - categorical_accuracy: 0.4230
11264/13806 [=======================>......] - ETA: 2s - loss: 1.3750 - categorical_accuracy: 0.4225
11392/13806 [=======================>......] - ETA: 2s - loss: 1.3754 - categorical_accuracy: 0.4221
11520/13806 [========================>.....] - ETA: 2s - loss: 1.3745 - categorical_accuracy: 0.4231
11648/13806 [========================>.....] - ETA: 1s - loss: 1.3747 - categorical_accuracy: 0.4228
11776/13806 [========================>.....] - ETA: 1s - loss: 1.3754 - categorical_accuracy: 0.4226
11904/13806 [========================>.....] - ETA: 1s - loss: 1.3753 - categorical_accuracy: 0.4229
12032/13806 [=========================>....] - ETA: 1s - loss: 1.3754 - categorical_accuracy: 0.4235
12160/13806 [=========================>....] - ETA: 1s - loss: 1.3747 - categorical_accuracy: 0.4234
12288/13806 [=========================>....] - ETA: 1s - loss: 1.3754 - categorical_accuracy: 0.4225
12416/13806 [=========================>....] - ETA: 1s - loss: 1.3750 - categorical_accuracy: 0.4226
12544/13806 [==========================>...] - ETA: 1s - loss: 1.3750 - categorical_accuracy: 0.4227
12672/13806 [==========================>...] - ETA: 1s - loss: 1.3753 - categorical_accuracy: 0.4224
12800/13806 [==========================>...] - ETA: 0s - loss: 1.3756 - categorical_accuracy: 0.4221
12928/13806 [===========================>..] - ETA: 0s - loss: 1.3760 - categorical_accuracy: 0.4212
13056/13806 [===========================>..] - ETA: 0s - loss: 1.3761 - categorical_accuracy: 0.4210
13184/13806 [===========================>..] - ETA: 0s - loss: 1.3754 - categorical_accuracy: 0.4216
13312/13806 [===========================>..] - ETA: 0s - loss: 1.3745 - categorical_accuracy: 0.4224
13440/13806 [============================>.] - ETA: 0s - loss: 1.3746 - categorical_accuracy: 0.4225
13568/13806 [============================>.] - ETA: 0s - loss: 1.3749 - categorical_accuracy: 0.4225
13696/13806 [============================>.] - ETA: 0s - loss: 1.3744 - categorical_accuracy: 0.4224
13806/13806 [==============================] - 13s 969us/step - loss: 1.3744 - categorical_accuracy: 0.4226 - val_loss: 1.5691 - val_categorical_accuracy: 0.3280

Epoch 00013: val_categorical_accuracy improved from 0.32472 to 0.32803, saving model to results/vardial2018/multi_input_char_only/model_weights.hdf5
Epoch 14/15

  128/13806 [..............................] - ETA: 11s - loss: 1.3887 - categorical_accuracy: 0.4297
  256/13806 [..............................] - ETA: 12s - loss: 1.3677 - categorical_accuracy: 0.4258
  384/13806 [..............................] - ETA: 12s - loss: 1.4019 - categorical_accuracy: 0.4089
  512/13806 [>.............................] - ETA: 12s - loss: 1.4078 - categorical_accuracy: 0.3945
  640/13806 [>.............................] - ETA: 12s - loss: 1.3944 - categorical_accuracy: 0.4078
  768/13806 [>.............................] - ETA: 12s - loss: 1.3905 - categorical_accuracy: 0.4102
  896/13806 [>.............................] - ETA: 12s - loss: 1.3850 - categorical_accuracy: 0.4118
 1024/13806 [=>............................] - ETA: 11s - loss: 1.3739 - categorical_accuracy: 0.4180
 1152/13806 [=>............................] - ETA: 11s - loss: 1.3714 - categorical_accuracy: 0.4167
 1280/13806 [=>............................] - ETA: 11s - loss: 1.3745 - categorical_accuracy: 0.4188
 1408/13806 [==>...........................] - ETA: 11s - loss: 1.3737 - categorical_accuracy: 0.4183
 1536/13806 [==>...........................] - ETA: 11s - loss: 1.3758 - categorical_accuracy: 0.4173
 1664/13806 [==>...........................] - ETA: 10s - loss: 1.3719 - categorical_accuracy: 0.4177
 1792/13806 [==>...........................] - ETA: 10s - loss: 1.3719 - categorical_accuracy: 0.4163
 1920/13806 [===>..........................] - ETA: 10s - loss: 1.3755 - categorical_accuracy: 0.4177
 2048/13806 [===>..........................] - ETA: 10s - loss: 1.3773 - categorical_accuracy: 0.4150
 2176/13806 [===>..........................] - ETA: 10s - loss: 1.3760 - categorical_accuracy: 0.4154
 2304/13806 [====>.........................] - ETA: 10s - loss: 1.3713 - categorical_accuracy: 0.4180
 2432/13806 [====>.........................] - ETA: 10s - loss: 1.3694 - categorical_accuracy: 0.4215
 2560/13806 [====>.........................] - ETA: 10s - loss: 1.3680 - categorical_accuracy: 0.4246
 2688/13806 [====>.........................] - ETA: 10s - loss: 1.3695 - categorical_accuracy: 0.4234
 2816/13806 [=====>........................] - ETA: 10s - loss: 1.3702 - categorical_accuracy: 0.4215
 2944/13806 [=====>........................] - ETA: 10s - loss: 1.3719 - categorical_accuracy: 0.4212
 3072/13806 [=====>........................] - ETA: 9s - loss: 1.3707 - categorical_accuracy: 0.4225 
 3200/13806 [=====>........................] - ETA: 9s - loss: 1.3716 - categorical_accuracy: 0.4219
 3328/13806 [======>.......................] - ETA: 9s - loss: 1.3683 - categorical_accuracy: 0.4240
 3456/13806 [======>.......................] - ETA: 9s - loss: 1.3666 - categorical_accuracy: 0.4256
 3584/13806 [======>.......................] - ETA: 9s - loss: 1.3666 - categorical_accuracy: 0.4249
 3712/13806 [=======>......................] - ETA: 9s - loss: 1.3664 - categorical_accuracy: 0.4232
 3840/13806 [=======>......................] - ETA: 9s - loss: 1.3637 - categorical_accuracy: 0.4253
 3968/13806 [=======>......................] - ETA: 9s - loss: 1.3628 - categorical_accuracy: 0.4264
 4096/13806 [=======>......................] - ETA: 9s - loss: 1.3636 - categorical_accuracy: 0.4263
 4224/13806 [========>.....................] - ETA: 8s - loss: 1.3607 - categorical_accuracy: 0.4278
 4352/13806 [========>.....................] - ETA: 8s - loss: 1.3602 - categorical_accuracy: 0.4292
 4480/13806 [========>.....................] - ETA: 8s - loss: 1.3596 - categorical_accuracy: 0.4290
 4608/13806 [=========>....................] - ETA: 8s - loss: 1.3568 - categorical_accuracy: 0.4306
 4736/13806 [=========>....................] - ETA: 8s - loss: 1.3563 - categorical_accuracy: 0.4310
 4864/13806 [=========>....................] - ETA: 8s - loss: 1.3572 - categorical_accuracy: 0.4309
 4992/13806 [=========>....................] - ETA: 8s - loss: 1.3556 - categorical_accuracy: 0.4331
 5120/13806 [==========>...................] - ETA: 8s - loss: 1.3565 - categorical_accuracy: 0.4322
 5248/13806 [==========>...................] - ETA: 7s - loss: 1.3571 - categorical_accuracy: 0.4322
 5376/13806 [==========>...................] - ETA: 7s - loss: 1.3579 - categorical_accuracy: 0.4314
 5504/13806 [==========>...................] - ETA: 7s - loss: 1.3568 - categorical_accuracy: 0.4317
 5632/13806 [===========>..................] - ETA: 7s - loss: 1.3555 - categorical_accuracy: 0.4325
 5760/13806 [===========>..................] - ETA: 7s - loss: 1.3547 - categorical_accuracy: 0.4330
 5888/13806 [===========>..................] - ETA: 7s - loss: 1.3550 - categorical_accuracy: 0.4322
 6016/13806 [============>.................] - ETA: 7s - loss: 1.3567 - categorical_accuracy: 0.4320
 6144/13806 [============>.................] - ETA: 7s - loss: 1.3553 - categorical_accuracy: 0.4329
 6272/13806 [============>.................] - ETA: 6s - loss: 1.3557 - categorical_accuracy: 0.4316
 6400/13806 [============>.................] - ETA: 6s - loss: 1.3551 - categorical_accuracy: 0.4314
 6528/13806 [=============>................] - ETA: 6s - loss: 1.3543 - categorical_accuracy: 0.4328
 6656/13806 [=============>................] - ETA: 6s - loss: 1.3538 - categorical_accuracy: 0.4322
 6784/13806 [=============>................] - ETA: 6s - loss: 1.3545 - categorical_accuracy: 0.4332
 6912/13806 [==============>...............] - ETA: 6s - loss: 1.3561 - categorical_accuracy: 0.4321
 7040/13806 [==============>...............] - ETA: 6s - loss: 1.3560 - categorical_accuracy: 0.4324
 7168/13806 [==============>...............] - ETA: 6s - loss: 1.3585 - categorical_accuracy: 0.4309
 7296/13806 [==============>...............] - ETA: 6s - loss: 1.3579 - categorical_accuracy: 0.4317
 7424/13806 [===============>..............] - ETA: 5s - loss: 1.3575 - categorical_accuracy: 0.4302
 7552/13806 [===============>..............] - ETA: 5s - loss: 1.3566 - categorical_accuracy: 0.4313
 7680/13806 [===============>..............] - ETA: 5s - loss: 1.3578 - categorical_accuracy: 0.4296
 7808/13806 [===============>..............] - ETA: 5s - loss: 1.3576 - categorical_accuracy: 0.4298
 7936/13806 [================>.............] - ETA: 5s - loss: 1.3573 - categorical_accuracy: 0.4307
 8064/13806 [================>.............] - ETA: 5s - loss: 1.3575 - categorical_accuracy: 0.4303
 8192/13806 [================>.............] - ETA: 5s - loss: 1.3572 - categorical_accuracy: 0.4309
 8320/13806 [=================>............] - ETA: 5s - loss: 1.3581 - categorical_accuracy: 0.4300
 8448/13806 [=================>............] - ETA: 4s - loss: 1.3585 - categorical_accuracy: 0.4304
 8576/13806 [=================>............] - ETA: 4s - loss: 1.3576 - categorical_accuracy: 0.4310
 8704/13806 [=================>............] - ETA: 4s - loss: 1.3588 - categorical_accuracy: 0.4313
 8832/13806 [==================>...........] - ETA: 4s - loss: 1.3585 - categorical_accuracy: 0.4317
 8960/13806 [==================>...........] - ETA: 4s - loss: 1.3583 - categorical_accuracy: 0.4319
 9088/13806 [==================>...........] - ETA: 4s - loss: 1.3573 - categorical_accuracy: 0.4331
 9216/13806 [===================>..........] - ETA: 4s - loss: 1.3588 - categorical_accuracy: 0.4325
 9344/13806 [===================>..........] - ETA: 4s - loss: 1.3575 - categorical_accuracy: 0.4334
 9472/13806 [===================>..........] - ETA: 3s - loss: 1.3585 - categorical_accuracy: 0.4320
 9600/13806 [===================>..........] - ETA: 3s - loss: 1.3595 - categorical_accuracy: 0.4311
 9728/13806 [====================>.........] - ETA: 3s - loss: 1.3600 - categorical_accuracy: 0.4305
 9856/13806 [====================>.........] - ETA: 3s - loss: 1.3608 - categorical_accuracy: 0.4307
 9984/13806 [====================>.........] - ETA: 3s - loss: 1.3610 - categorical_accuracy: 0.4300
10112/13806 [====================>.........] - ETA: 3s - loss: 1.3604 - categorical_accuracy: 0.4304
10240/13806 [=====================>........] - ETA: 3s - loss: 1.3615 - categorical_accuracy: 0.4295
10368/13806 [=====================>........] - ETA: 3s - loss: 1.3619 - categorical_accuracy: 0.4288
10496/13806 [=====================>........] - ETA: 3s - loss: 1.3627 - categorical_accuracy: 0.4283
10624/13806 [======================>.......] - ETA: 2s - loss: 1.3641 - categorical_accuracy: 0.4268
10752/13806 [======================>.......] - ETA: 2s - loss: 1.3642 - categorical_accuracy: 0.4273
10880/13806 [======================>.......] - ETA: 2s - loss: 1.3650 - categorical_accuracy: 0.4269
11008/13806 [======================>.......] - ETA: 2s - loss: 1.3654 - categorical_accuracy: 0.4264
11136/13806 [=======================>......] - ETA: 2s - loss: 1.3661 - categorical_accuracy: 0.4262
11264/13806 [=======================>......] - ETA: 2s - loss: 1.3669 - categorical_accuracy: 0.4259
11392/13806 [=======================>......] - ETA: 2s - loss: 1.3670 - categorical_accuracy: 0.4260
11520/13806 [========================>.....] - ETA: 2s - loss: 1.3678 - categorical_accuracy: 0.4248
11648/13806 [========================>.....] - ETA: 1s - loss: 1.3687 - categorical_accuracy: 0.4245
11776/13806 [========================>.....] - ETA: 1s - loss: 1.3696 - categorical_accuracy: 0.4239
11904/13806 [========================>.....] - ETA: 1s - loss: 1.3697 - categorical_accuracy: 0.4241
12032/13806 [=========================>....] - ETA: 1s - loss: 1.3696 - categorical_accuracy: 0.4242
12160/13806 [=========================>....] - ETA: 1s - loss: 1.3695 - categorical_accuracy: 0.4245
12288/13806 [=========================>....] - ETA: 1s - loss: 1.3687 - categorical_accuracy: 0.4253
12416/13806 [=========================>....] - ETA: 1s - loss: 1.3689 - categorical_accuracy: 0.4257
12544/13806 [==========================>...] - ETA: 1s - loss: 1.3688 - categorical_accuracy: 0.4262
12672/13806 [==========================>...] - ETA: 1s - loss: 1.3695 - categorical_accuracy: 0.4257
12800/13806 [==========================>...] - ETA: 0s - loss: 1.3696 - categorical_accuracy: 0.4254
12928/13806 [===========================>..] - ETA: 0s - loss: 1.3697 - categorical_accuracy: 0.4254
13056/13806 [===========================>..] - ETA: 0s - loss: 1.3698 - categorical_accuracy: 0.4252
13184/13806 [===========================>..] - ETA: 0s - loss: 1.3691 - categorical_accuracy: 0.4259
13312/13806 [===========================>..] - ETA: 0s - loss: 1.3687 - categorical_accuracy: 0.4263
13440/13806 [============================>.] - ETA: 0s - loss: 1.3688 - categorical_accuracy: 0.4265
13568/13806 [============================>.] - ETA: 0s - loss: 1.3687 - categorical_accuracy: 0.4270
13696/13806 [============================>.] - ETA: 0s - loss: 1.3686 - categorical_accuracy: 0.4271
13806/13806 [==============================] - 14s 984us/step - loss: 1.3675 - categorical_accuracy: 0.4278 - val_loss: 1.5642 - val_categorical_accuracy: 0.3247

Epoch 00014: val_categorical_accuracy did not improve
Epoch 15/15

  128/13806 [..............................] - ETA: 11s - loss: 1.3882 - categorical_accuracy: 0.3906
  256/13806 [..............................] - ETA: 12s - loss: 1.3886 - categorical_accuracy: 0.3984
  384/13806 [..............................] - ETA: 12s - loss: 1.3765 - categorical_accuracy: 0.3984
  512/13806 [>.............................] - ETA: 12s - loss: 1.3777 - categorical_accuracy: 0.3945
  640/13806 [>.............................] - ETA: 12s - loss: 1.3688 - categorical_accuracy: 0.4078
  768/13806 [>.............................] - ETA: 12s - loss: 1.3813 - categorical_accuracy: 0.3984
  896/13806 [>.............................] - ETA: 12s - loss: 1.3768 - categorical_accuracy: 0.4040
 1024/13806 [=>............................] - ETA: 11s - loss: 1.3798 - categorical_accuracy: 0.4023
 1152/13806 [=>............................] - ETA: 11s - loss: 1.3716 - categorical_accuracy: 0.4062
 1280/13806 [=>............................] - ETA: 11s - loss: 1.3737 - categorical_accuracy: 0.4031
 1408/13806 [==>...........................] - ETA: 11s - loss: 1.3748 - categorical_accuracy: 0.3999
 1536/13806 [==>...........................] - ETA: 11s - loss: 1.3764 - categorical_accuracy: 0.4010
 1664/13806 [==>...........................] - ETA: 11s - loss: 1.3751 - categorical_accuracy: 0.4062
 1792/13806 [==>...........................] - ETA: 11s - loss: 1.3741 - categorical_accuracy: 0.4057
 1920/13806 [===>..........................] - ETA: 11s - loss: 1.3706 - categorical_accuracy: 0.4062
 2048/13806 [===>..........................] - ETA: 10s - loss: 1.3695 - categorical_accuracy: 0.4067
 2176/13806 [===>..........................] - ETA: 10s - loss: 1.3676 - categorical_accuracy: 0.4090
 2304/13806 [====>.........................] - ETA: 10s - loss: 1.3681 - categorical_accuracy: 0.4089
 2432/13806 [====>.........................] - ETA: 10s - loss: 1.3633 - categorical_accuracy: 0.4116
 2560/13806 [====>.........................] - ETA: 10s - loss: 1.3598 - categorical_accuracy: 0.4156
 2688/13806 [====>.........................] - ETA: 10s - loss: 1.3568 - categorical_accuracy: 0.4193
 2816/13806 [=====>........................] - ETA: 10s - loss: 1.3545 - categorical_accuracy: 0.4219
 2944/13806 [=====>........................] - ETA: 10s - loss: 1.3565 - categorical_accuracy: 0.4202
 3072/13806 [=====>........................] - ETA: 10s - loss: 1.3577 - categorical_accuracy: 0.4196
 3200/13806 [=====>........................] - ETA: 9s - loss: 1.3586 - categorical_accuracy: 0.4188 
 3328/13806 [======>.......................] - ETA: 9s - loss: 1.3551 - categorical_accuracy: 0.4228
 3456/13806 [======>.......................] - ETA: 9s - loss: 1.3535 - categorical_accuracy: 0.4233
 3584/13806 [======>.......................] - ETA: 9s - loss: 1.3546 - categorical_accuracy: 0.4247
 3712/13806 [=======>......................] - ETA: 9s - loss: 1.3533 - categorical_accuracy: 0.4251
 3840/13806 [=======>......................] - ETA: 9s - loss: 1.3553 - categorical_accuracy: 0.4250
 3968/13806 [=======>......................] - ETA: 9s - loss: 1.3543 - categorical_accuracy: 0.4254
 4096/13806 [=======>......................] - ETA: 8s - loss: 1.3523 - categorical_accuracy: 0.4263
 4224/13806 [========>.....................] - ETA: 8s - loss: 1.3520 - categorical_accuracy: 0.4264
 4352/13806 [========>.....................] - ETA: 8s - loss: 1.3521 - categorical_accuracy: 0.4258
 4480/13806 [========>.....................] - ETA: 8s - loss: 1.3526 - categorical_accuracy: 0.4268
 4608/13806 [=========>....................] - ETA: 8s - loss: 1.3521 - categorical_accuracy: 0.4275
 4736/13806 [=========>....................] - ETA: 8s - loss: 1.3525 - categorical_accuracy: 0.4276
 4864/13806 [=========>....................] - ETA: 8s - loss: 1.3524 - categorical_accuracy: 0.4287
 4992/13806 [=========>....................] - ETA: 8s - loss: 1.3506 - categorical_accuracy: 0.4299
 5120/13806 [==========>...................] - ETA: 7s - loss: 1.3502 - categorical_accuracy: 0.4303
 5248/13806 [==========>...................] - ETA: 7s - loss: 1.3506 - categorical_accuracy: 0.4299
 5376/13806 [==========>...................] - ETA: 7s - loss: 1.3496 - categorical_accuracy: 0.4304
 5504/13806 [==========>...................] - ETA: 7s - loss: 1.3504 - categorical_accuracy: 0.4306
 5632/13806 [===========>..................] - ETA: 7s - loss: 1.3526 - categorical_accuracy: 0.4293
 5760/13806 [===========>..................] - ETA: 7s - loss: 1.3525 - categorical_accuracy: 0.4300
 5888/13806 [===========>..................] - ETA: 7s - loss: 1.3552 - categorical_accuracy: 0.4290
 6016/13806 [============>.................] - ETA: 7s - loss: 1.3545 - categorical_accuracy: 0.4299
 6144/13806 [============>.................] - ETA: 7s - loss: 1.3551 - categorical_accuracy: 0.4303
 6272/13806 [============>.................] - ETA: 6s - loss: 1.3557 - categorical_accuracy: 0.4306
 6400/13806 [============>.................] - ETA: 6s - loss: 1.3557 - categorical_accuracy: 0.4305
 6528/13806 [=============>................] - ETA: 6s - loss: 1.3548 - categorical_accuracy: 0.4317
 6656/13806 [=============>................] - ETA: 6s - loss: 1.3538 - categorical_accuracy: 0.4322
 6784/13806 [=============>................] - ETA: 6s - loss: 1.3544 - categorical_accuracy: 0.4315
 6912/13806 [==============>...............] - ETA: 6s - loss: 1.3534 - categorical_accuracy: 0.4324
 7040/13806 [==============>...............] - ETA: 6s - loss: 1.3523 - categorical_accuracy: 0.4332
 7168/13806 [==============>...............] - ETA: 6s - loss: 1.3522 - categorical_accuracy: 0.4343
 7296/13806 [==============>...............] - ETA: 5s - loss: 1.3518 - categorical_accuracy: 0.4342
 7424/13806 [===============>..............] - ETA: 5s - loss: 1.3529 - categorical_accuracy: 0.4332
 7552/13806 [===============>..............] - ETA: 5s - loss: 1.3529 - categorical_accuracy: 0.4339
 7680/13806 [===============>..............] - ETA: 5s - loss: 1.3531 - categorical_accuracy: 0.4340
 7808/13806 [===============>..............] - ETA: 5s - loss: 1.3526 - categorical_accuracy: 0.4343
 7936/13806 [================>.............] - ETA: 5s - loss: 1.3520 - categorical_accuracy: 0.4349
 8064/13806 [================>.............] - ETA: 5s - loss: 1.3519 - categorical_accuracy: 0.4361
 8192/13806 [================>.............] - ETA: 5s - loss: 1.3508 - categorical_accuracy: 0.4370
 8320/13806 [=================>............] - ETA: 4s - loss: 1.3519 - categorical_accuracy: 0.4363
 8448/13806 [=================>............] - ETA: 4s - loss: 1.3522 - categorical_accuracy: 0.4354
 8576/13806 [=================>............] - ETA: 4s - loss: 1.3523 - categorical_accuracy: 0.4351
 8704/13806 [=================>............] - ETA: 4s - loss: 1.3524 - categorical_accuracy: 0.4342
 8832/13806 [==================>...........] - ETA: 4s - loss: 1.3523 - categorical_accuracy: 0.4346
 8960/13806 [==================>...........] - ETA: 4s - loss: 1.3524 - categorical_accuracy: 0.4343
 9088/13806 [==================>...........] - ETA: 4s - loss: 1.3539 - categorical_accuracy: 0.4332
 9216/13806 [===================>..........] - ETA: 4s - loss: 1.3529 - categorical_accuracy: 0.4333
 9344/13806 [===================>..........] - ETA: 4s - loss: 1.3536 - categorical_accuracy: 0.4325
 9472/13806 [===================>..........] - ETA: 3s - loss: 1.3542 - categorical_accuracy: 0.4323
 9600/13806 [===================>..........] - ETA: 3s - loss: 1.3542 - categorical_accuracy: 0.4321
 9728/13806 [====================>.........] - ETA: 3s - loss: 1.3544 - categorical_accuracy: 0.4318
 9856/13806 [====================>.........] - ETA: 3s - loss: 1.3548 - categorical_accuracy: 0.4315
 9984/13806 [====================>.........] - ETA: 3s - loss: 1.3556 - categorical_accuracy: 0.4311
10112/13806 [====================>.........] - ETA: 3s - loss: 1.3557 - categorical_accuracy: 0.4310
10240/13806 [=====================>........] - ETA: 3s - loss: 1.3553 - categorical_accuracy: 0.4314
10368/13806 [=====================>........] - ETA: 3s - loss: 1.3550 - categorical_accuracy: 0.4314
10496/13806 [=====================>........] - ETA: 2s - loss: 1.3555 - categorical_accuracy: 0.4314
10624/13806 [======================>.......] - ETA: 2s - loss: 1.3565 - categorical_accuracy: 0.4311
10752/13806 [======================>.......] - ETA: 2s - loss: 1.3566 - categorical_accuracy: 0.4302
10880/13806 [======================>.......] - ETA: 2s - loss: 1.3578 - categorical_accuracy: 0.4299
11008/13806 [======================>.......] - ETA: 2s - loss: 1.3579 - categorical_accuracy: 0.4297
11136/13806 [=======================>......] - ETA: 2s - loss: 1.3586 - categorical_accuracy: 0.4291
11264/13806 [=======================>......] - ETA: 2s - loss: 1.3586 - categorical_accuracy: 0.4294
11392/13806 [=======================>......] - ETA: 2s - loss: 1.3579 - categorical_accuracy: 0.4300
11520/13806 [========================>.....] - ETA: 2s - loss: 1.3582 - categorical_accuracy: 0.4296
11648/13806 [========================>.....] - ETA: 1s - loss: 1.3586 - categorical_accuracy: 0.4292
11776/13806 [========================>.....] - ETA: 1s - loss: 1.3588 - categorical_accuracy: 0.4293
11904/13806 [========================>.....] - ETA: 1s - loss: 1.3579 - categorical_accuracy: 0.4302
12032/13806 [=========================>....] - ETA: 1s - loss: 1.3577 - categorical_accuracy: 0.4305
12160/13806 [=========================>....] - ETA: 1s - loss: 1.3583 - categorical_accuracy: 0.4304
12288/13806 [=========================>....] - ETA: 1s - loss: 1.3573 - categorical_accuracy: 0.4310
12416/13806 [=========================>....] - ETA: 1s - loss: 1.3576 - categorical_accuracy: 0.4311
12544/13806 [==========================>...] - ETA: 1s - loss: 1.3579 - categorical_accuracy: 0.4310
12672/13806 [==========================>...] - ETA: 1s - loss: 1.3589 - categorical_accuracy: 0.4307
12800/13806 [==========================>...] - ETA: 0s - loss: 1.3591 - categorical_accuracy: 0.4302
12928/13806 [===========================>..] - ETA: 0s - loss: 1.3585 - categorical_accuracy: 0.4306
13056/13806 [===========================>..] - ETA: 0s - loss: 1.3583 - categorical_accuracy: 0.4308
13184/13806 [===========================>..] - ETA: 0s - loss: 1.3578 - categorical_accuracy: 0.4311
13312/13806 [===========================>..] - ETA: 0s - loss: 1.3579 - categorical_accuracy: 0.4310
13440/13806 [============================>.] - ETA: 0s - loss: 1.3583 - categorical_accuracy: 0.4304
13568/13806 [============================>.] - ETA: 0s - loss: 1.3589 - categorical_accuracy: 0.4301
13696/13806 [============================>.] - ETA: 0s - loss: 1.3596 - categorical_accuracy: 0.4295
13806/13806 [==============================] - 13s 962us/step - loss: 1.3599 - categorical_accuracy: 0.4296 - val_loss: 1.5793 - val_categorical_accuracy: 0.3426
2018-03-27 14:22:33.054905: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1120] Creating TensorFlow device (/device:GPU:0) -> (device: 0, name: GeForce GTX 1080, pci bus id: 0000:01:00.0, compute capability: 6.1)
2018-03-27 14:22:33.054951: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1120] Creating TensorFlow device (/device:GPU:1) -> (device: 1, name: GeForce GTX 1080, pci bus id: 0000:02:00.0, compute capability: 6.1)
2018-03-27 14:22:33.054959: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1120] Creating TensorFlow device (/device:GPU:2) -> (device: 2, name: GeForce GTX 1080, pci bus id: 0000:03:00.0, compute capability: 6.1)
2018-03-27 14:22:33.054973: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1120] Creating TensorFlow device (/device:GPU:3) -> (device: 3, name: GeForce GTX 1080, pci bus id: 0000:04:00.0, compute capability: 6.1)
/home/michon/anaconda2/envs/py35/lib/python3.5/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  from ._conv import register_converters as _register_converters
Using TensorFlow backend.

Epoch 00015: val_categorical_accuracy improved from 0.32803 to 0.34261, saving model to results/vardial2018/multi_input_char_only/model_weights.hdf5

Final evaluation

f1_score
 0.3212295117092233
accuracy_score
 0.3426110006626905

classification_report
              precision    recall  f1-score   support

        EGY       0.33      0.43      0.37       297
        GLF       0.23      0.17      0.19       259
        LAV       0.37      0.20      0.26       327
        MSA       0.36      0.69      0.48       280
        NOR       0.38      0.25      0.30       346

avg / total       0.34      0.34      0.32      1509


confusion_matrix
 [[128  20  31  71  47]
 [ 67  43  33  88  28]
 [ 93  33  64  76  61]
 [ 39  32   7 194   8]
 [ 60  57  36 105  88]]

Evaluation on best model

f1_score
 0.3212295117092233
accuracy_score
 0.3426110006626905

classification_report
              precision    recall  f1-score   support

        EGY       0.33      0.43      0.37       297
        GLF       0.23      0.17      0.19       259
        LAV       0.37      0.20      0.26       327
        MSA       0.36      0.69      0.48       280
        NOR       0.38      0.25      0.30       346

avg / total       0.34      0.34      0.32      1509


confusion_matrix
 [[128  20  31  71  47]
 [ 67  43  33  88  28]
 [ 93  33  64  76  61]
 [ 39  32   7 194   8]
 [ 60  57  36 105  88]]
Closing remaining open files:data/vardial2018/dataset.h5...done
############# train: DONE @ Tue Mar 27 14:22:35 CEST 2018
