############# train @ Fri Mar 23 14:36:46 CET 2018 GPUS=3  HOST=ssaling11 PWD=/home/michon/projects/VarDial2018/to_export/multi_input_modular
Loading data
Data Configurations loaded
Loading data
(13806, 8)
(1509, 8)
EGY    3085
LAV    2940
NOR    2866
GLF    2707
MSA    2208
Name: Class, dtype: int64
NOR    346
LAV    327
EGY    297
MSA    280
GLF    259
Name: Class, dtype: int64
Loading vocabularies
Words
48244 48244
Phones
45 45
39 39
61 61
51 51
Generating ids
Preprocessing data
Padding character sequences
(13806, 6830)
Padding phone sequences
(13806, 5885) (13806, 7329) (13806, 6436) (13806, 6837)
Turning labels in one-hot vectors
(13806, 5)
Taking ready-made acoustic embeddings
(13806, 600)
Padding character sequences
(1509, 6830)
Padding phone sequences
(1509, 5885) (1509, 7329) (1509, 6436) (1509, 6837)
Turning labels in one-hot vectors
(1509, 5)
Taking ready-made acoustic embeddings
(1509, 600)
MultiInputCharCNN Configurations loaded
Building the model
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
sent_input (InputLayer)         (None, 6830)         0                                            
__________________________________________________________________________________________________
phone_CZ_input (InputLayer)     (None, 5885)         0                                            
__________________________________________________________________________________________________
phone_EN_input (InputLayer)     (None, 7329)         0                                            
__________________________________________________________________________________________________
phone_HU_input (InputLayer)     (None, 6436)         0                                            
__________________________________________________________________________________________________
phone_RU_input (InputLayer)     (None, 6837)         0                                            
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 6830, 32)     3232        sent_input[0][0]                 
__________________________________________________________________________________________________
embedding_2 (Embedding)         (None, 5885, 32)     1472        phone_CZ_input[0][0]             
__________________________________________________________________________________________________
embedding_3 (Embedding)         (None, 7329, 32)     1280        phone_EN_input[0][0]             
__________________________________________________________________________________________________
embedding_4 (Embedding)         (None, 6436, 32)     1984        phone_HU_input[0][0]             
__________________________________________________________________________________________________
embedding_5 (Embedding)         (None, 6837, 32)     1664        phone_RU_input[0][0]             
__________________________________________________________________________________________________
zero_padding1d_1 (ZeroPadding1D (None, 6834, 32)     0           embedding_1[0][0]                
__________________________________________________________________________________________________
zero_padding1d_2 (ZeroPadding1D (None, 6838, 32)     0           embedding_1[0][0]                
__________________________________________________________________________________________________
zero_padding1d_3 (ZeroPadding1D (None, 5889, 32)     0           embedding_2[0][0]                
__________________________________________________________________________________________________
zero_padding1d_4 (ZeroPadding1D (None, 5893, 32)     0           embedding_2[0][0]                
__________________________________________________________________________________________________
zero_padding1d_5 (ZeroPadding1D (None, 7333, 32)     0           embedding_3[0][0]                
__________________________________________________________________________________________________
zero_padding1d_6 (ZeroPadding1D (None, 7337, 32)     0           embedding_3[0][0]                
__________________________________________________________________________________________________
zero_padding1d_7 (ZeroPadding1D (None, 6440, 32)     0           embedding_4[0][0]                
__________________________________________________________________________________________________
zero_padding1d_8 (ZeroPadding1D (None, 6444, 32)     0           embedding_4[0][0]                
__________________________________________________________________________________________________
zero_padding1d_9 (ZeroPadding1D (None, 6841, 32)     0           embedding_5[0][0]                
__________________________________________________________________________________________________
zero_padding1d_10 (ZeroPadding1 (None, 6845, 32)     0           embedding_5[0][0]                
__________________________________________________________________________________________________
conv1d_1 (Conv1D)               (None, 6834, 8)      776         zero_padding1d_1[0][0]           
__________________________________________________________________________________________________
conv1d_2 (Conv1D)               (None, 6838, 8)      1288        zero_padding1d_2[0][0]           
__________________________________________________________________________________________________
conv1d_3 (Conv1D)               (None, 5889, 8)      776         zero_padding1d_3[0][0]           
__________________________________________________________________________________________________
conv1d_4 (Conv1D)               (None, 5893, 8)      1288        zero_padding1d_4[0][0]           
__________________________________________________________________________________________________
conv1d_5 (Conv1D)               (None, 7333, 8)      776         zero_padding1d_5[0][0]           
__________________________________________________________________________________________________
conv1d_6 (Conv1D)               (None, 7337, 8)      1288        zero_padding1d_6[0][0]           
__________________________________________________________________________________________________
conv1d_7 (Conv1D)               (None, 6440, 8)      776         zero_padding1d_7[0][0]           
__________________________________________________________________________________________________
conv1d_8 (Conv1D)               (None, 6444, 8)      1288        zero_padding1d_8[0][0]           
__________________________________________________________________________________________________
conv1d_9 (Conv1D)               (None, 6841, 8)      776         zero_padding1d_9[0][0]           
__________________________________________________________________________________________________
conv1d_10 (Conv1D)              (None, 6845, 8)      1288        zero_padding1d_10[0][0]          
__________________________________________________________________________________________________
global_max_pooling1d_1 (GlobalM (None, 8)            0           conv1d_1[0][0]                   
__________________________________________________________________________________________________
global_max_pooling1d_2 (GlobalM (None, 8)            0           conv1d_2[0][0]                   
__________________________________________________________________________________________________
global_max_pooling1d_3 (GlobalM (None, 8)            0           conv1d_3[0][0]                   
__________________________________________________________________________________________________
global_max_pooling1d_4 (GlobalM (None, 8)            0           conv1d_4[0][0]                   
__________________________________________________________________________________________________
global_max_pooling1d_5 (GlobalM (None, 8)            0           conv1d_5[0][0]                   
__________________________________________________________________________________________________
global_max_pooling1d_6 (GlobalM (None, 8)            0           conv1d_6[0][0]                   
__________________________________________________________________________________________________2018-03-23 14:36:57.133103: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
2018-03-23 14:36:57.387205: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1030] Found device 0 with properties: 
name: GeForce GTX 1080 major: 6 minor: 1 memoryClockRate(GHz): 1.7335
pciBusID: 0000:04:00.0
totalMemory: 7.92GiB freeMemory: 7.81GiB
2018-03-23 14:36:57.387234: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1120] Creating TensorFlow device (/device:GPU:0) -> (device: 0, name: GeForce GTX 1080, pci bus id: 0000:04:00.0, compute capability: 6.1)

global_max_pooling1d_7 (GlobalM (None, 8)            0           conv1d_7[0][0]                   
__________________________________________________________________________________________________
global_max_pooling1d_8 (GlobalM (None, 8)            0           conv1d_8[0][0]                   
__________________________________________________________________________________________________
global_max_pooling1d_9 (GlobalM (None, 8)            0           conv1d_9[0][0]                   
__________________________________________________________________________________________________
global_max_pooling1d_10 (Global (None, 8)            0           conv1d_10[0][0]                  
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 8)            0           global_max_pooling1d_1[0][0]     
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 8)            0           global_max_pooling1d_2[0][0]     
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 8)            0           global_max_pooling1d_3[0][0]     
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 8)            0           global_max_pooling1d_4[0][0]     
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 8)            0           global_max_pooling1d_5[0][0]     
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 8)            0           global_max_pooling1d_6[0][0]     
__________________________________________________________________________________________________
dropout_7 (Dropout)             (None, 8)            0           global_max_pooling1d_7[0][0]     
__________________________________________________________________________________________________
dropout_8 (Dropout)             (None, 8)            0           global_max_pooling1d_8[0][0]     
__________________________________________________________________________________________________
dropout_9 (Dropout)             (None, 8)            0           global_max_pooling1d_9[0][0]     
__________________________________________________________________________________________________
dropout_10 (Dropout)            (None, 8)            0           global_max_pooling1d_10[0][0]    
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 80)           0           dropout_1[0][0]                  
                                                                 dropout_2[0][0]                  
                                                                 dropout_3[0][0]                  
                                                                 dropout_4[0][0]                  
                                                                 dropout_5[0][0]                  
                                                                 dropout_6[0][0]                  
                                                                 dropout_7[0][0]                  
                                                                 dropout_8[0][0]                  
                                                                 dropout_9[0][0]                  
                                                                 dropout_10[0][0]                 
__________________________________________________________________________________________________
embed_input (InputLayer)        (None, 600)          0                                            
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 680)          0           concatenate_1[0][0]              
                                                                 embed_input[0][0]                
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 32)           21792       concatenate_2[0][0]              
__________________________________________________________________________________________________
dropout_11 (Dropout)            (None, 32)           0           dense_1[0][0]                    
__________________________________________________________________________________________________
l_out (Dense)                   (None, 5)            165         dropout_11[0][0]                 
==================================================================================================
Total params: 41,909
Trainable params: 41,909
Non-trainable params: 0
__________________________________________________________________________________________________
Training Configurations loaded
Training the model
no checkpoints available !
Train on 13806 samples, validate on 1509 samples
Epoch 1/15

  128/13806 [..............................] - ETA: 2:32 - loss: 2.3853 - categorical_accuracy: 0.2188
  256/13806 [..............................] - ETA: 1:30 - loss: 2.3390 - categorical_accuracy: 0.2188
  384/13806 [..............................] - ETA: 1:09 - loss: 2.2686 - categorical_accuracy: 0.2370
  512/13806 [>.............................] - ETA: 59s - loss: 2.2096 - categorical_accuracy: 0.2812 
  640/13806 [>.............................] - ETA: 53s - loss: 2.1366 - categorical_accuracy: 0.3281
  768/13806 [>.............................] - ETA: 48s - loss: 2.0798 - categorical_accuracy: 0.3685
  896/13806 [>.............................] - ETA: 45s - loss: 2.0278 - categorical_accuracy: 0.4062
 1024/13806 [=>............................] - ETA: 42s - loss: 1.9848 - categorical_accuracy: 0.4434
 1152/13806 [=>............................] - ETA: 40s - loss: 1.9521 - categorical_accuracy: 0.4583
 1280/13806 [=>............................] - ETA: 38s - loss: 1.9144 - categorical_accuracy: 0.4828
 1408/13806 [==>...........................] - ETA: 37s - loss: 1.8790 - categorical_accuracy: 0.5099
 1536/13806 [==>...........................] - ETA: 36s - loss: 1.8469 - categorical_accuracy: 0.5312
 1664/13806 [==>...........................] - ETA: 35s - loss: 1.8195 - categorical_accuracy: 0.5463
 1792/13806 [==>...........................] - ETA: 34s - loss: 1.7904 - categorical_accuracy: 0.5658
 1920/13806 [===>..........................] - ETA: 33s - loss: 1.7643 - categorical_accuracy: 0.5818
 2048/13806 [===>..........................] - ETA: 32s - loss: 1.7361 - categorical_accuracy: 0.5962
 2176/13806 [===>..........................] - ETA: 31s - loss: 1.7077 - categorical_accuracy: 0.6103
 2304/13806 [====>.........................] - ETA: 31s - loss: 1.6887 - categorical_accuracy: 0.6202
 2432/13806 [====>.........................] - ETA: 30s - loss: 1.6665 - categorical_accuracy: 0.6291
 2560/13806 [====>.........................] - ETA: 29s - loss: 1.6382 - categorical_accuracy: 0.6414
 2688/13806 [====>.........................] - ETA: 29s - loss: 1.6183 - categorical_accuracy: 0.6507
 2816/13806 [=====>........................] - ETA: 28s - loss: 1.5961 - categorical_accuracy: 0.6598
 2944/13806 [=====>........................] - ETA: 28s - loss: 1.5740 - categorical_accuracy: 0.6688
 3072/13806 [=====>........................] - ETA: 27s - loss: 1.5539 - categorical_accuracy: 0.6748
 3200/13806 [=====>........................] - ETA: 27s - loss: 1.5341 - categorical_accuracy: 0.6834
 3328/13806 [======>.......................] - ETA: 26s - loss: 1.5160 - categorical_accuracy: 0.6914
 3456/13806 [======>.......................] - ETA: 26s - loss: 1.4978 - categorical_accuracy: 0.6965
 3584/13806 [======>.......................] - ETA: 25s - loss: 1.4800 - categorical_accuracy: 0.7042
 3712/13806 [=======>......................] - ETA: 25s - loss: 1.4635 - categorical_accuracy: 0.7107
 3840/13806 [=======>......................] - ETA: 24s - loss: 1.4489 - categorical_accuracy: 0.7143
 3968/13806 [=======>......................] - ETA: 24s - loss: 1.4319 - categorical_accuracy: 0.7203
 4096/13806 [=======>......................] - ETA: 24s - loss: 1.4166 - categorical_accuracy: 0.7251
 4224/13806 [========>.....................] - ETA: 23s - loss: 1.4030 - categorical_accuracy: 0.7308
 4352/13806 [========>.....................] - ETA: 23s - loss: 1.3873 - categorical_accuracy: 0.7362
 4480/13806 [========>.....................] - ETA: 22s - loss: 1.3727 - categorical_accuracy: 0.7413
 4608/13806 [=========>....................] - ETA: 22s - loss: 1.3573 - categorical_accuracy: 0.7465
 4736/13806 [=========>....................] - ETA: 22s - loss: 1.3431 - categorical_accuracy: 0.7523
 4864/13806 [=========>....................] - ETA: 21s - loss: 1.3292 - categorical_accuracy: 0.7568
 4992/13806 [=========>....................] - ETA: 21s - loss: 1.3189 - categorical_accuracy: 0.7596
 5120/13806 [==========>...................] - ETA: 20s - loss: 1.3079 - categorical_accuracy: 0.7629
 5248/13806 [==========>...................] - ETA: 20s - loss: 1.2957 - categorical_accuracy: 0.7660
 5376/13806 [==========>...................] - ETA: 20s - loss: 1.2833 - categorical_accuracy: 0.7699
 5504/13806 [==========>...................] - ETA: 19s - loss: 1.2737 - categorical_accuracy: 0.7731
 5632/13806 [===========>..................] - ETA: 19s - loss: 1.2616 - categorical_accuracy: 0.7772
 5760/13806 [===========>..................] - ETA: 19s - loss: 1.2512 - categorical_accuracy: 0.7802
 5888/13806 [===========>..................] - ETA: 18s - loss: 1.2415 - categorical_accuracy: 0.7824
 6016/13806 [============>.................] - ETA: 18s - loss: 1.2311 - categorical_accuracy: 0.7854
 6144/13806 [============>.................] - ETA: 18s - loss: 1.2218 - categorical_accuracy: 0.7882
 6272/13806 [============>.................] - ETA: 17s - loss: 1.2117 - categorical_accuracy: 0.7911
 6400/13806 [============>.................] - ETA: 17s - loss: 1.2008 - categorical_accuracy: 0.7942
 6528/13806 [=============>................] - ETA: 17s - loss: 1.1918 - categorical_accuracy: 0.7972
 6656/13806 [=============>................] - ETA: 16s - loss: 1.1817 - categorical_accuracy: 0.7999
 6784/13806 [=============>................] - ETA: 16s - loss: 1.1726 - categorical_accuracy: 0.8025
 6912/13806 [==============>...............] - ETA: 16s - loss: 1.1641 - categorical_accuracy: 0.8051
 7040/13806 [==============>...............] - ETA: 15s - loss: 1.1556 - categorical_accuracy: 0.8075
 7168/13806 [==============>...............] - ETA: 15s - loss: 1.1465 - categorical_accuracy: 0.8104
 7296/13806 [==============>...............] - ETA: 15s - loss: 1.1384 - categorical_accuracy: 0.8125
 7424/13806 [===============>..............] - ETA: 14s - loss: 1.1314 - categorical_accuracy: 0.8140
 7552/13806 [===============>..............] - ETA: 14s - loss: 1.1234 - categorical_accuracy: 0.8158
 7680/13806 [===============>..............] - ETA: 14s - loss: 1.1160 - categorical_accuracy: 0.8174
 7808/13806 [===============>..............] - ETA: 13s - loss: 1.1086 - categorical_accuracy: 0.8194
 7936/13806 [================>.............] - ETA: 13s - loss: 1.1007 - categorical_accuracy: 0.8214
 8064/13806 [================>.............] - ETA: 13s - loss: 1.0936 - categorical_accuracy: 0.8235
 8192/13806 [================>.............] - ETA: 13s - loss: 1.0870 - categorical_accuracy: 0.8251
 8320/13806 [=================>............] - ETA: 12s - loss: 1.0793 - categorical_accuracy: 0.8269
 8448/13806 [=================>............] - ETA: 12s - loss: 1.0725 - categorical_accuracy: 0.8286
 8576/13806 [=================>............] - ETA: 12s - loss: 1.0658 - categorical_accuracy: 0.8305
 8704/13806 [=================>............] - ETA: 11s - loss: 1.0594 - categorical_accuracy: 0.8319
 8832/13806 [==================>...........] - ETA: 11s - loss: 1.0524 - categorical_accuracy: 0.8336
 8960/13806 [==================>...........] - ETA: 11s - loss: 1.0468 - categorical_accuracy: 0.8345
 9088/13806 [==================>...........] - ETA: 10s - loss: 1.0411 - categorical_accuracy: 0.8355
 9216/13806 [===================>..........] - ETA: 10s - loss: 1.0356 - categorical_accuracy: 0.8369
 9344/13806 [===================>..........] - ETA: 10s - loss: 1.0289 - categorical_accuracy: 0.8386
 9472/13806 [===================>..........] - ETA: 10s - loss: 1.0235 - categorical_accuracy: 0.8401
 9600/13806 [===================>..........] - ETA: 9s - loss: 1.0191 - categorical_accuracy: 0.8408 
 9728/13806 [====================>.........] - ETA: 9s - loss: 1.0128 - categorical_accuracy: 0.8423
 9856/13806 [====================>.........] - ETA: 9s - loss: 1.0071 - categorical_accuracy: 0.8435
 9984/13806 [====================>.........] - ETA: 8s - loss: 1.0021 - categorical_accuracy: 0.8449
10112/13806 [====================>.........] - ETA: 8s - loss: 0.9979 - categorical_accuracy: 0.8456
10240/13806 [=====================>........] - ETA: 8s - loss: 0.9929 - categorical_accuracy: 0.8465
10368/13806 [=====================>........] - ETA: 7s - loss: 0.9870 - categorical_accuracy: 0.8479
10496/13806 [=====================>........] - ETA: 7s - loss: 0.9814 - categorical_accuracy: 0.8493
10624/13806 [======================>.......] - ETA: 7s - loss: 0.9767 - categorical_accuracy: 0.8500
10752/13806 [======================>.......] - ETA: 7s - loss: 0.9720 - categorical_accuracy: 0.8508
10880/13806 [======================>.......] - ETA: 6s - loss: 0.9673 - categorical_accuracy: 0.8517
11008/13806 [======================>.......] - ETA: 6s - loss: 0.9619 - categorical_accuracy: 0.8529
11136/13806 [=======================>......] - ETA: 6s - loss: 0.9572 - categorical_accuracy: 0.8536
11264/13806 [=======================>......] - ETA: 5s - loss: 0.9524 - categorical_accuracy: 0.8548
11392/13806 [=======================>......] - ETA: 5s - loss: 0.9478 - categorical_accuracy: 0.8560
11520/13806 [========================>.....] - ETA: 5s - loss: 0.9431 - categorical_accuracy: 0.8572
11648/13806 [========================>.....] - ETA: 4s - loss: 0.9390 - categorical_accuracy: 0.8578
11776/13806 [========================>.....] - ETA: 4s - loss: 0.9346 - categorical_accuracy: 0.8587
11904/13806 [========================>.....] - ETA: 4s - loss: 0.9303 - categorical_accuracy: 0.8593
12032/13806 [=========================>....] - ETA: 4s - loss: 0.9258 - categorical_accuracy: 0.8603
12160/13806 [=========================>....] - ETA: 3s - loss: 0.9229 - categorical_accuracy: 0.8607
12288/13806 [=========================>....] - ETA: 3s - loss: 0.9195 - categorical_accuracy: 0.8613
12416/13806 [=========================>....] - ETA: 3s - loss: 0.9151 - categorical_accuracy: 0.8624
12544/13806 [==========================>...] - ETA: 2s - loss: 0.9110 - categorical_accuracy: 0.8631
12672/13806 [==========================>...] - ETA: 2s - loss: 0.9081 - categorical_accuracy: 0.8636
12800/13806 [==========================>...] - ETA: 2s - loss: 0.9046 - categorical_accuracy: 0.8642
12928/13806 [===========================>..] - ETA: 2s - loss: 0.9006 - categorical_accuracy: 0.8652
13056/13806 [===========================>..] - ETA: 1s - loss: 0.8965 - categorical_accuracy: 0.8658
13184/13806 [===========================>..] - ETA: 1s - loss: 0.8934 - categorical_accuracy: 0.8663
13312/13806 [===========================>..] - ETA: 1s - loss: 0.8893 - categorical_accuracy: 0.8671
13440/13806 [============================>.] - ETA: 0s - loss: 0.8860 - categorical_accuracy: 0.8677
13568/13806 [============================>.] - ETA: 0s - loss: 0.8826 - categorical_accuracy: 0.8684
13696/13806 [============================>.] - ETA: 0s - loss: 0.8790 - categorical_accuracy: 0.8691
13806/13806 [==============================] - 33s 2ms/step - loss: 0.8768 - categorical_accuracy: 0.8695 - val_loss: 1.5602 - val_categorical_accuracy: 0.5321

Epoch 00001: val_categorical_accuracy improved from -inf to 0.53214, saving model to results/vardial2018/multi_input_half_with_dropout/model_weights.hdf5
Epoch 2/15

  128/13806 [..............................] - ETA: 30s - loss: 0.4987 - categorical_accuracy: 0.9375
  256/13806 [..............................] - ETA: 29s - loss: 0.5098 - categorical_accuracy: 0.9180
  384/13806 [..............................] - ETA: 29s - loss: 0.4955 - categorical_accuracy: 0.9245
  512/13806 [>.............................] - ETA: 29s - loss: 0.4847 - categorical_accuracy: 0.9355
  640/13806 [>.............................] - ETA: 29s - loss: 0.4841 - categorical_accuracy: 0.9406
  768/13806 [>.............................] - ETA: 29s - loss: 0.4955 - categorical_accuracy: 0.9336
  896/13806 [>.............................] - ETA: 28s - loss: 0.4915 - categorical_accuracy: 0.9330
 1024/13806 [=>............................] - ETA: 28s - loss: 0.4863 - categorical_accuracy: 0.9346
 1152/13806 [=>............................] - ETA: 27s - loss: 0.4849 - categorical_accuracy: 0.9340
 1280/13806 [=>............................] - ETA: 27s - loss: 0.4827 - categorical_accuracy: 0.9344
 1408/13806 [==>...........................] - ETA: 27s - loss: 0.4794 - categorical_accuracy: 0.9361
 1536/13806 [==>...........................] - ETA: 26s - loss: 0.4779 - categorical_accuracy: 0.9355
 1664/13806 [==>...........................] - ETA: 26s - loss: 0.4808 - categorical_accuracy: 0.9363
 1792/13806 [==>...........................] - ETA: 26s - loss: 0.4857 - categorical_accuracy: 0.9369
 1920/13806 [===>..........................] - ETA: 25s - loss: 0.4831 - categorical_accuracy: 0.9380
 2048/13806 [===>..........................] - ETA: 25s - loss: 0.4762 - categorical_accuracy: 0.9404
 2176/13806 [===>..........................] - ETA: 25s - loss: 0.4719 - categorical_accuracy: 0.9426
 2304/13806 [====>.........................] - ETA: 25s - loss: 0.4744 - categorical_accuracy: 0.9397
 2432/13806 [====>.........................] - ETA: 24s - loss: 0.4718 - categorical_accuracy: 0.9404
 2560/13806 [====>.........................] - ETA: 24s - loss: 0.4696 - categorical_accuracy: 0.9422
 2688/13806 [====>.........................] - ETA: 24s - loss: 0.4684 - categorical_accuracy: 0.9431
 2816/13806 [=====>........................] - ETA: 24s - loss: 0.4673 - categorical_accuracy: 0.9428
 2944/13806 [=====>........................] - ETA: 23s - loss: 0.4649 - categorical_accuracy: 0.9436
 3072/13806 [=====>........................] - ETA: 23s - loss: 0.4634 - categorical_accuracy: 0.9440
 3200/13806 [=====>........................] - ETA: 23s - loss: 0.4646 - categorical_accuracy: 0.9434
 3328/13806 [======>.......................] - ETA: 22s - loss: 0.4651 - categorical_accuracy: 0.9435
 3456/13806 [======>.......................] - ETA: 22s - loss: 0.4663 - categorical_accuracy: 0.9424
 3584/13806 [======>.......................] - ETA: 22s - loss: 0.4677 - categorical_accuracy: 0.9411
 3712/13806 [=======>......................] - ETA: 22s - loss: 0.4651 - categorical_accuracy: 0.9421
 3840/13806 [=======>......................] - ETA: 21s - loss: 0.4623 - categorical_accuracy: 0.9422
 3968/13806 [=======>......................] - ETA: 21s - loss: 0.4581 - categorical_accuracy: 0.9433
 4096/13806 [=======>......................] - ETA: 21s - loss: 0.4569 - categorical_accuracy: 0.9434
 4224/13806 [========>.....................] - ETA: 20s - loss: 0.4548 - categorical_accuracy: 0.9444
 4352/13806 [========>.....................] - ETA: 20s - loss: 0.4534 - categorical_accuracy: 0.9451
 4480/13806 [========>.....................] - ETA: 20s - loss: 0.4513 - categorical_accuracy: 0.9453
 4608/13806 [=========>....................] - ETA: 20s - loss: 0.4500 - categorical_accuracy: 0.9453
 4736/13806 [=========>....................] - ETA: 19s - loss: 0.4469 - categorical_accuracy: 0.9464
 4864/13806 [=========>....................] - ETA: 19s - loss: 0.4459 - categorical_accuracy: 0.9470
 4992/13806 [=========>....................] - ETA: 19s - loss: 0.4443 - categorical_accuracy: 0.9471
 5120/13806 [==========>...................] - ETA: 19s - loss: 0.4412 - categorical_accuracy: 0.9479
 5248/13806 [==========>...................] - ETA: 18s - loss: 0.4406 - categorical_accuracy: 0.9482
 5376/13806 [==========>...................] - ETA: 18s - loss: 0.4394 - categorical_accuracy: 0.9481
 5504/13806 [==========>...................] - ETA: 18s - loss: 0.4388 - categorical_accuracy: 0.9484
 5632/13806 [===========>..................] - ETA: 18s - loss: 0.4376 - categorical_accuracy: 0.9482
 5760/13806 [===========>..................] - ETA: 17s - loss: 0.4386 - categorical_accuracy: 0.9477
 5888/13806 [===========>..................] - ETA: 17s - loss: 0.4391 - categorical_accuracy: 0.9468
 6016/13806 [============>.................] - ETA: 17s - loss: 0.4371 - categorical_accuracy: 0.9471
 6144/13806 [============>.................] - ETA: 16s - loss: 0.4364 - categorical_accuracy: 0.9471
 6272/13806 [============>.................] - ETA: 16s - loss: 0.4378 - categorical_accuracy: 0.9466
 6400/13806 [============>.................] - ETA: 16s - loss: 0.4373 - categorical_accuracy: 0.9469
 6528/13806 [=============>................] - ETA: 16s - loss: 0.4376 - categorical_accuracy: 0.9465
 6656/13806 [=============>................] - ETA: 15s - loss: 0.4383 - categorical_accuracy: 0.9462
 6784/13806 [=============>................] - ETA: 15s - loss: 0.4367 - categorical_accuracy: 0.9463
 6912/13806 [==============>...............] - ETA: 15s - loss: 0.4366 - categorical_accuracy: 0.9460
 7040/13806 [==============>...............] - ETA: 14s - loss: 0.4355 - categorical_accuracy: 0.9456
 7168/13806 [==============>...............] - ETA: 14s - loss: 0.4351 - categorical_accuracy: 0.9453
 7296/13806 [==============>...............] - ETA: 14s - loss: 0.4343 - categorical_accuracy: 0.9454
 7424/13806 [===============>..............] - ETA: 14s - loss: 0.4334 - categorical_accuracy: 0.9456
 7552/13806 [===============>..............] - ETA: 13s - loss: 0.4322 - categorical_accuracy: 0.9460
 7680/13806 [===============>..............] - ETA: 13s - loss: 0.4315 - categorical_accuracy: 0.9460
 7808/13806 [===============>..............] - ETA: 13s - loss: 0.4310 - categorical_accuracy: 0.9460
 7936/13806 [================>.............] - ETA: 12s - loss: 0.4295 - categorical_accuracy: 0.9462
 8064/13806 [================>.............] - ETA: 12s - loss: 0.4308 - categorical_accuracy: 0.9458
 8192/13806 [================>.............] - ETA: 12s - loss: 0.4301 - categorical_accuracy: 0.9459
 8320/13806 [=================>............] - ETA: 12s - loss: 0.4291 - categorical_accuracy: 0.9463
 8448/13806 [=================>............] - ETA: 11s - loss: 0.4281 - categorical_accuracy: 0.9460
 8576/13806 [=================>............] - ETA: 11s - loss: 0.4269 - categorical_accuracy: 0.9460
 8704/13806 [=================>............] - ETA: 11s - loss: 0.4259 - categorical_accuracy: 0.9462
 8832/13806 [==================>...........] - ETA: 11s - loss: 0.4250 - categorical_accuracy: 0.9463
 8960/13806 [==================>...........] - ETA: 10s - loss: 0.4234 - categorical_accuracy: 0.9467
 9088/13806 [==================>...........] - ETA: 10s - loss: 0.4230 - categorical_accuracy: 0.9463
 9216/13806 [===================>..........] - ETA: 10s - loss: 0.4219 - categorical_accuracy: 0.9466
 9344/13806 [===================>..........] - ETA: 9s - loss: 0.4221 - categorical_accuracy: 0.9466 
 9472/13806 [===================>..........] - ETA: 9s - loss: 0.4206 - categorical_accuracy: 0.9469
 9600/13806 [===================>..........] - ETA: 9s - loss: 0.4197 - categorical_accuracy: 0.9470
 9728/13806 [====================>.........] - ETA: 9s - loss: 0.4184 - categorical_accuracy: 0.9472
 9856/13806 [====================>.........] - ETA: 8s - loss: 0.4179 - categorical_accuracy: 0.9473
 9984/13806 [====================>.........] - ETA: 8s - loss: 0.4180 - categorical_accuracy: 0.9470
10112/13806 [====================>.........] - ETA: 8s - loss: 0.4181 - categorical_accuracy: 0.9468
10240/13806 [=====================>........] - ETA: 7s - loss: 0.4168 - categorical_accuracy: 0.9471
10368/13806 [=====================>........] - ETA: 7s - loss: 0.4166 - categorical_accuracy: 0.9470
10496/13806 [=====================>........] - ETA: 7s - loss: 0.4159 - categorical_accuracy: 0.9466
10624/13806 [======================>.......] - ETA: 7s - loss: 0.4150 - categorical_accuracy: 0.9467
10752/13806 [======================>.......] - ETA: 6s - loss: 0.4136 - categorical_accuracy: 0.9470
10880/13806 [======================>.......] - ETA: 6s - loss: 0.4126 - categorical_accuracy: 0.9472
11008/13806 [======================>.......] - ETA: 6s - loss: 0.4119 - categorical_accuracy: 0.9471
11136/13806 [=======================>......] - ETA: 5s - loss: 0.4112 - categorical_accuracy: 0.9472
11264/13806 [=======================>......] - ETA: 5s - loss: 0.4104 - categorical_accuracy: 0.9474
11392/13806 [=======================>......] - ETA: 5s - loss: 0.4092 - categorical_accuracy: 0.9474
11520/13806 [========================>.....] - ETA: 5s - loss: 0.4079 - categorical_accuracy: 0.9477
11648/13806 [========================>.....] - ETA: 4s - loss: 0.4071 - categorical_accuracy: 0.9480
11776/13806 [========================>.....] - ETA: 4s - loss: 0.4064 - categorical_accuracy: 0.9482
11904/13806 [========================>.....] - ETA: 4s - loss: 0.4063 - categorical_accuracy: 0.9481
12032/13806 [=========================>....] - ETA: 3s - loss: 0.4056 - categorical_accuracy: 0.9480
12160/13806 [=========================>....] - ETA: 3s - loss: 0.4042 - categorical_accuracy: 0.9484
12288/13806 [=========================>....] - ETA: 3s - loss: 0.4036 - categorical_accuracy: 0.9485
12416/13806 [=========================>....] - ETA: 3s - loss: 0.4030 - categorical_accuracy: 0.9486
12544/13806 [==========================>...] - ETA: 2s - loss: 0.4021 - categorical_accuracy: 0.9485
12672/13806 [==========================>...] - ETA: 2s - loss: 0.4015 - categorical_accuracy: 0.9485
12800/13806 [==========================>...] - ETA: 2s - loss: 0.4003 - categorical_accuracy: 0.9489
12928/13806 [===========================>..] - ETA: 1s - loss: 0.3995 - categorical_accuracy: 0.9486
13056/13806 [===========================>..] - ETA: 1s - loss: 0.3988 - categorical_accuracy: 0.9490
13184/13806 [===========================>..] - ETA: 1s - loss: 0.3988 - categorical_accuracy: 0.9487
13312/13806 [===========================>..] - ETA: 1s - loss: 0.3986 - categorical_accuracy: 0.9486
13440/13806 [============================>.] - ETA: 0s - loss: 0.3980 - categorical_accuracy: 0.9487
13568/13806 [============================>.] - ETA: 0s - loss: 0.3974 - categorical_accuracy: 0.9485
13696/13806 [============================>.] - ETA: 0s - loss: 0.3968 - categorical_accuracy: 0.9486
13806/13806 [==============================] - 32s 2ms/step - loss: 0.3958 - categorical_accuracy: 0.9488 - val_loss: 1.4962 - val_categorical_accuracy: 0.5328

Epoch 00002: val_categorical_accuracy improved from 0.53214 to 0.53280, saving model to results/vardial2018/multi_input_half_with_dropout/model_weights.hdf5
Epoch 3/15

  128/13806 [..............................] - ETA: 31s - loss: 0.3580 - categorical_accuracy: 0.9688
  256/13806 [..............................] - ETA: 30s - loss: 0.3655 - categorical_accuracy: 0.9492
  384/13806 [..............................] - ETA: 29s - loss: 0.3428 - categorical_accuracy: 0.9505
  512/13806 [>.............................] - ETA: 29s - loss: 0.3415 - categorical_accuracy: 0.9551
  640/13806 [>.............................] - ETA: 28s - loss: 0.3402 - categorical_accuracy: 0.9594
  768/13806 [>.............................] - ETA: 29s - loss: 0.3309 - categorical_accuracy: 0.9596
  896/13806 [>.............................] - ETA: 29s - loss: 0.3307 - categorical_accuracy: 0.9609
 1024/13806 [=>............................] - ETA: 28s - loss: 0.3243 - categorical_accuracy: 0.9639
 1152/13806 [=>............................] - ETA: 28s - loss: 0.3247 - categorical_accuracy: 0.9635
 1280/13806 [=>............................] - ETA: 28s - loss: 0.3227 - categorical_accuracy: 0.9609
 1408/13806 [==>...........................] - ETA: 27s - loss: 0.3207 - categorical_accuracy: 0.9609
 1536/13806 [==>...........................] - ETA: 27s - loss: 0.3190 - categorical_accuracy: 0.9603
 1664/13806 [==>...........................] - ETA: 26s - loss: 0.3135 - categorical_accuracy: 0.9603
 1792/13806 [==>...........................] - ETA: 26s - loss: 0.3148 - categorical_accuracy: 0.9593
 1920/13806 [===>..........................] - ETA: 26s - loss: 0.3168 - categorical_accuracy: 0.9594
 2048/13806 [===>..........................] - ETA: 26s - loss: 0.3137 - categorical_accuracy: 0.9609
 2176/13806 [===>..........................] - ETA: 25s - loss: 0.3174 - categorical_accuracy: 0.9573
 2304/13806 [====>.........................] - ETA: 25s - loss: 0.3168 - categorical_accuracy: 0.9570
 2432/13806 [====>.........................] - ETA: 25s - loss: 0.3202 - categorical_accuracy: 0.9556
 2560/13806 [====>.........................] - ETA: 25s - loss: 0.3181 - categorical_accuracy: 0.9555
 2688/13806 [====>.........................] - ETA: 24s - loss: 0.3181 - categorical_accuracy: 0.9557
 2816/13806 [=====>........................] - ETA: 24s - loss: 0.3183 - categorical_accuracy: 0.9545
 2944/13806 [=====>........................] - ETA: 24s - loss: 0.3174 - categorical_accuracy: 0.9552
 3072/13806 [=====>........................] - ETA: 23s - loss: 0.3152 - categorical_accuracy: 0.9557
 3200/13806 [=====>........................] - ETA: 23s - loss: 0.3128 - categorical_accuracy: 0.9559
 3328/13806 [======>.......................] - ETA: 23s - loss: 0.3117 - categorical_accuracy: 0.9558
 3456/13806 [======>.......................] - ETA: 23s - loss: 0.3110 - categorical_accuracy: 0.9563
 3584/13806 [======>.......................] - ETA: 22s - loss: 0.3125 - categorical_accuracy: 0.9556
 3712/13806 [=======>......................] - ETA: 22s - loss: 0.3156 - categorical_accuracy: 0.9550
 3840/13806 [=======>......................] - ETA: 22s - loss: 0.3155 - categorical_accuracy: 0.9547
 3968/13806 [=======>......................] - ETA: 21s - loss: 0.3143 - categorical_accuracy: 0.9549
 4096/13806 [=======>......................] - ETA: 21s - loss: 0.3150 - categorical_accuracy: 0.9546
 4224/13806 [========>.....................] - ETA: 21s - loss: 0.3125 - categorical_accuracy: 0.9550
 4352/13806 [========>.....................] - ETA: 21s - loss: 0.3106 - categorical_accuracy: 0.9554
 4480/13806 [========>.....................] - ETA: 20s - loss: 0.3093 - categorical_accuracy: 0.9563
 4608/13806 [=========>....................] - ETA: 20s - loss: 0.3112 - categorical_accuracy: 0.9559
 4736/13806 [=========>....................] - ETA: 20s - loss: 0.3108 - categorical_accuracy: 0.9563
 4864/13806 [=========>....................] - ETA: 19s - loss: 0.3111 - categorical_accuracy: 0.9564
 4992/13806 [=========>....................] - ETA: 19s - loss: 0.3110 - categorical_accuracy: 0.9561
 5120/13806 [==========>...................] - ETA: 19s - loss: 0.3090 - categorical_accuracy: 0.9568
 5248/13806 [==========>...................] - ETA: 19s - loss: 0.3083 - categorical_accuracy: 0.9573
 5376/13806 [==========>...................] - ETA: 18s - loss: 0.3099 - categorical_accuracy: 0.9568
 5504/13806 [==========>...................] - ETA: 18s - loss: 0.3107 - categorical_accuracy: 0.9566
 5632/13806 [===========>..................] - ETA: 18s - loss: 0.3090 - categorical_accuracy: 0.9569
 5760/13806 [===========>..................] - ETA: 17s - loss: 0.3078 - categorical_accuracy: 0.9569
 5888/13806 [===========>..................] - ETA: 17s - loss: 0.3078 - categorical_accuracy: 0.9574
 6016/13806 [============>.................] - ETA: 17s - loss: 0.3069 - categorical_accuracy: 0.9578
 6144/13806 [============>.................] - ETA: 17s - loss: 0.3063 - categorical_accuracy: 0.9578
 6272/13806 [============>.................] - ETA: 16s - loss: 0.3052 - categorical_accuracy: 0.9584
 6400/13806 [============>.................] - ETA: 16s - loss: 0.3047 - categorical_accuracy: 0.9581
 6528/13806 [=============>................] - ETA: 16s - loss: 0.3040 - categorical_accuracy: 0.9583
 6656/13806 [=============>................] - ETA: 16s - loss: 0.3042 - categorical_accuracy: 0.9585
 6784/13806 [=============>................] - ETA: 15s - loss: 0.3040 - categorical_accuracy: 0.9583
 6912/13806 [==============>...............] - ETA: 15s - loss: 0.3036 - categorical_accuracy: 0.9582
 7040/13806 [==============>...............] - ETA: 15s - loss: 0.3023 - categorical_accuracy: 0.9584
 7168/13806 [==============>...............] - ETA: 14s - loss: 0.3026 - categorical_accuracy: 0.9583
 7296/13806 [==============>...............] - ETA: 14s - loss: 0.3018 - categorical_accuracy: 0.9583
 7424/13806 [===============>..............] - ETA: 14s - loss: 0.3024 - categorical_accuracy: 0.9588
 7552/13806 [===============>..............] - ETA: 14s - loss: 0.3018 - categorical_accuracy: 0.9586
 7680/13806 [===============>..............] - ETA: 13s - loss: 0.3015 - categorical_accuracy: 0.9587
 7808/13806 [===============>..............] - ETA: 13s - loss: 0.3007 - categorical_accuracy: 0.9590
 7936/13806 [================>.............] - ETA: 13s - loss: 0.2995 - categorical_accuracy: 0.9594
 8064/13806 [================>.............] - ETA: 12s - loss: 0.2989 - categorical_accuracy: 0.9596
 8192/13806 [================>.............] - ETA: 12s - loss: 0.2974 - categorical_accuracy: 0.9600
 8320/13806 [=================>............] - ETA: 12s - loss: 0.2979 - categorical_accuracy: 0.9597
 8448/13806 [=================>............] - ETA: 12s - loss: 0.2984 - categorical_accuracy: 0.9594
 8576/13806 [=================>............] - ETA: 11s - loss: 0.2995 - categorical_accuracy: 0.9591
 8704/13806 [=================>............] - ETA: 11s - loss: 0.2993 - categorical_accuracy: 0.9586
 8832/13806 [==================>...........] - ETA: 11s - loss: 0.3001 - categorical_accuracy: 0.9581
 8960/13806 [==================>...........] - ETA: 10s - loss: 0.2988 - categorical_accuracy: 0.9586
 9088/13806 [==================>...........] - ETA: 10s - loss: 0.2987 - categorical_accuracy: 0.9583
 9216/13806 [===================>..........] - ETA: 10s - loss: 0.2980 - categorical_accuracy: 0.9587
 9344/13806 [===================>..........] - ETA: 10s - loss: 0.2978 - categorical_accuracy: 0.9583
 9472/13806 [===================>..........] - ETA: 9s - loss: 0.2974 - categorical_accuracy: 0.9585 
 9600/13806 [===================>..........] - ETA: 9s - loss: 0.2973 - categorical_accuracy: 0.9584
 9728/13806 [====================>.........] - ETA: 9s - loss: 0.2991 - categorical_accuracy: 0.9584
 9856/13806 [====================>.........] - ETA: 8s - loss: 0.2997 - categorical_accuracy: 0.9579
 9984/13806 [====================>.........] - ETA: 8s - loss: 0.3004 - categorical_accuracy: 0.9574
10112/13806 [====================>.........] - ETA: 8s - loss: 0.2999 - categorical_accuracy: 0.9574
10240/13806 [=====================>........] - ETA: 8s - loss: 0.3001 - categorical_accuracy: 0.9573
10368/13806 [=====================>........] - ETA: 7s - loss: 0.3007 - categorical_accuracy: 0.9569
10496/13806 [=====================>........] - ETA: 7s - loss: 0.3016 - categorical_accuracy: 0.9561
10624/13806 [======================>.......] - ETA: 7s - loss: 0.3009 - categorical_accuracy: 0.9562
10752/13806 [======================>.......] - ETA: 6s - loss: 0.2999 - categorical_accuracy: 0.9567
10880/13806 [======================>.......] - ETA: 6s - loss: 0.2996 - categorical_accuracy: 0.9564
11008/13806 [======================>.......] - ETA: 6s - loss: 0.2991 - categorical_accuracy: 0.9564
11136/13806 [=======================>......] - ETA: 5s - loss: 0.2981 - categorical_accuracy: 0.9565
11264/13806 [=======================>......] - ETA: 5s - loss: 0.2977 - categorical_accuracy: 0.9566
11392/13806 [=======================>......] - ETA: 5s - loss: 0.2983 - categorical_accuracy: 0.9565
11520/13806 [========================>.....] - ETA: 5s - loss: 0.2991 - categorical_accuracy: 0.9563
11648/13806 [========================>.....] - ETA: 4s - loss: 0.2980 - categorical_accuracy: 0.9566
11776/13806 [========================>.....] - ETA: 4s - loss: 0.2977 - categorical_accuracy: 0.9566
11904/13806 [========================>.....] - ETA: 4s - loss: 0.2976 - categorical_accuracy: 0.9567
12032/13806 [=========================>....] - ETA: 3s - loss: 0.2978 - categorical_accuracy: 0.9564
12160/13806 [=========================>....] - ETA: 3s - loss: 0.2974 - categorical_accuracy: 0.9563
12288/13806 [=========================>....] - ETA: 3s - loss: 0.2972 - categorical_accuracy: 0.9561
12416/13806 [=========================>....] - ETA: 3s - loss: 0.2964 - categorical_accuracy: 0.9563
12544/13806 [==========================>...] - ETA: 2s - loss: 0.2955 - categorical_accuracy: 0.9566
12672/13806 [==========================>...] - ETA: 2s - loss: 0.2952 - categorical_accuracy: 0.9566
12800/13806 [==========================>...] - ETA: 2s - loss: 0.2952 - categorical_accuracy: 0.9567
12928/13806 [===========================>..] - ETA: 1s - loss: 0.2949 - categorical_accuracy: 0.9565
13056/13806 [===========================>..] - ETA: 1s - loss: 0.2947 - categorical_accuracy: 0.9567
13184/13806 [===========================>..] - ETA: 1s - loss: 0.2948 - categorical_accuracy: 0.9567
13312/13806 [===========================>..] - ETA: 1s - loss: 0.2944 - categorical_accuracy: 0.9568
13440/13806 [============================>.] - ETA: 0s - loss: 0.2934 - categorical_accuracy: 0.9570
13568/13806 [============================>.] - ETA: 0s - loss: 0.2931 - categorical_accuracy: 0.9571
13696/13806 [============================>.] - ETA: 0s - loss: 0.2943 - categorical_accuracy: 0.9569
13806/13806 [==============================] - 32s 2ms/step - loss: 0.2944 - categorical_accuracy: 0.9570 - val_loss: 1.4916 - val_categorical_accuracy: 0.5255

Epoch 00003: val_categorical_accuracy did not improve
Epoch 4/15

  128/13806 [..............................] - ETA: 31s - loss: 0.2746 - categorical_accuracy: 0.9609
  256/13806 [..............................] - ETA: 31s - loss: 0.2606 - categorical_accuracy: 0.9492
  384/13806 [..............................] - ETA: 31s - loss: 0.2488 - categorical_accuracy: 0.9583
  512/13806 [>.............................] - ETA: 31s - loss: 0.2631 - categorical_accuracy: 0.9570
  640/13806 [>.............................] - ETA: 30s - loss: 0.2616 - categorical_accuracy: 0.9578
  768/13806 [>.............................] - ETA: 30s - loss: 0.2602 - categorical_accuracy: 0.9596
  896/13806 [>.............................] - ETA: 29s - loss: 0.2548 - categorical_accuracy: 0.9621
 1024/13806 [=>............................] - ETA: 28s - loss: 0.2649 - categorical_accuracy: 0.9600
 1152/13806 [=>............................] - ETA: 28s - loss: 0.2637 - categorical_accuracy: 0.9609
 1280/13806 [=>............................] - ETA: 28s - loss: 0.2685 - categorical_accuracy: 0.9586
 1408/13806 [==>...........................] - ETA: 27s - loss: 0.2602 - categorical_accuracy: 0.9624
 1536/13806 [==>...........................] - ETA: 27s - loss: 0.2672 - categorical_accuracy: 0.9609
 1664/13806 [==>...........................] - ETA: 26s - loss: 0.2775 - categorical_accuracy: 0.9573
 1792/13806 [==>...........................] - ETA: 26s - loss: 0.2743 - categorical_accuracy: 0.9576
 1920/13806 [===>..........................] - ETA: 26s - loss: 0.2719 - categorical_accuracy: 0.9589
 2048/13806 [===>..........................] - ETA: 26s - loss: 0.2733 - categorical_accuracy: 0.9590
 2176/13806 [===>..........................] - ETA: 26s - loss: 0.2733 - categorical_accuracy: 0.9577
 2304/13806 [====>.........................] - ETA: 25s - loss: 0.2724 - categorical_accuracy: 0.9562
 2432/13806 [====>.........................] - ETA: 25s - loss: 0.2716 - categorical_accuracy: 0.9564
 2560/13806 [====>.........................] - ETA: 25s - loss: 0.2682 - categorical_accuracy: 0.9578
 2688/13806 [====>.........................] - ETA: 24s - loss: 0.2661 - categorical_accuracy: 0.9587
 2816/13806 [=====>........................] - ETA: 24s - loss: 0.2650 - categorical_accuracy: 0.9592
 2944/13806 [=====>........................] - ETA: 24s - loss: 0.2626 - categorical_accuracy: 0.9603
 3072/13806 [=====>........................] - ETA: 23s - loss: 0.2596 - categorical_accuracy: 0.9616
 3200/13806 [=====>........................] - ETA: 23s - loss: 0.2597 - categorical_accuracy: 0.9616
 3328/13806 [======>.......................] - ETA: 23s - loss: 0.2589 - categorical_accuracy: 0.9606
 3456/13806 [======>.......................] - ETA: 22s - loss: 0.2613 - categorical_accuracy: 0.9601
 3584/13806 [======>.......................] - ETA: 22s - loss: 0.2580 - categorical_accuracy: 0.9615
 3712/13806 [=======>......................] - ETA: 22s - loss: 0.2585 - categorical_accuracy: 0.9604
 3840/13806 [=======>......................] - ETA: 22s - loss: 0.2600 - categorical_accuracy: 0.9599
 3968/13806 [=======>......................] - ETA: 21s - loss: 0.2611 - categorical_accuracy: 0.9599
 4096/13806 [=======>......................] - ETA: 21s - loss: 0.2598 - categorical_accuracy: 0.9602
 4224/13806 [========>.....................] - ETA: 21s - loss: 0.2598 - categorical_accuracy: 0.9602
 4352/13806 [========>.....................] - ETA: 20s - loss: 0.2578 - categorical_accuracy: 0.9605
 4480/13806 [========>.....................] - ETA: 20s - loss: 0.2583 - categorical_accuracy: 0.9605
 4608/13806 [=========>....................] - ETA: 20s - loss: 0.2587 - categorical_accuracy: 0.9601
 4736/13806 [=========>....................] - ETA: 20s - loss: 0.2586 - categorical_accuracy: 0.9597
 4864/13806 [=========>....................] - ETA: 19s - loss: 0.2591 - categorical_accuracy: 0.9591
 4992/13806 [=========>....................] - ETA: 19s - loss: 0.2590 - categorical_accuracy: 0.9589
 5120/13806 [==========>...................] - ETA: 19s - loss: 0.2588 - categorical_accuracy: 0.9590
 5248/13806 [==========>...................] - ETA: 18s - loss: 0.2582 - categorical_accuracy: 0.9590
 5376/13806 [==========>...................] - ETA: 18s - loss: 0.2574 - categorical_accuracy: 0.9589
 5504/13806 [==========>...................] - ETA: 18s - loss: 0.2575 - categorical_accuracy: 0.9588
 5632/13806 [===========>..................] - ETA: 18s - loss: 0.2574 - categorical_accuracy: 0.9588
 5760/13806 [===========>..................] - ETA: 17s - loss: 0.2594 - categorical_accuracy: 0.9578
 5888/13806 [===========>..................] - ETA: 17s - loss: 0.2577 - categorical_accuracy: 0.9584
 6016/13806 [============>.................] - ETA: 17s - loss: 0.2568 - categorical_accuracy: 0.9584
 6144/13806 [============>.................] - ETA: 16s - loss: 0.2558 - categorical_accuracy: 0.9585
 6272/13806 [============>.................] - ETA: 16s - loss: 0.2562 - categorical_accuracy: 0.9587
 6400/13806 [============>.................] - ETA: 16s - loss: 0.2560 - categorical_accuracy: 0.9591
 6528/13806 [=============>................] - ETA: 16s - loss: 0.2567 - categorical_accuracy: 0.9586
 6656/13806 [=============>................] - ETA: 15s - loss: 0.2583 - categorical_accuracy: 0.9581
 6784/13806 [=============>................] - ETA: 15s - loss: 0.2573 - categorical_accuracy: 0.9581
 6912/13806 [==============>...............] - ETA: 15s - loss: 0.2577 - categorical_accuracy: 0.9583
 7040/13806 [==============>...............] - ETA: 15s - loss: 0.2578 - categorical_accuracy: 0.9587
 7168/13806 [==============>...............] - ETA: 14s - loss: 0.2578 - categorical_accuracy: 0.9584
 7296/13806 [==============>...............] - ETA: 14s - loss: 0.2567 - categorical_accuracy: 0.9586
 7424/13806 [===============>..............] - ETA: 14s - loss: 0.2553 - categorical_accuracy: 0.9589
 7552/13806 [===============>..............] - ETA: 13s - loss: 0.2559 - categorical_accuracy: 0.9587
 7680/13806 [===============>..............] - ETA: 13s - loss: 0.2565 - categorical_accuracy: 0.9590
 7808/13806 [===============>..............] - ETA: 13s - loss: 0.2567 - categorical_accuracy: 0.9590
 7936/13806 [================>.............] - ETA: 13s - loss: 0.2570 - categorical_accuracy: 0.9590
 8064/13806 [================>.............] - ETA: 12s - loss: 0.2559 - categorical_accuracy: 0.9592
 8192/13806 [================>.............] - ETA: 12s - loss: 0.2555 - categorical_accuracy: 0.9594
 8320/13806 [=================>............] - ETA: 12s - loss: 0.2556 - categorical_accuracy: 0.9593
 8448/13806 [=================>............] - ETA: 11s - loss: 0.2555 - categorical_accuracy: 0.9590
 8576/13806 [=================>............] - ETA: 11s - loss: 0.2546 - categorical_accuracy: 0.9593
 8704/13806 [=================>............] - ETA: 11s - loss: 0.2535 - categorical_accuracy: 0.9598
 8832/13806 [==================>...........] - ETA: 11s - loss: 0.2529 - categorical_accuracy: 0.9601
 8960/13806 [==================>...........] - ETA: 10s - loss: 0.2522 - categorical_accuracy: 0.9603
 9088/13806 [==================>...........] - ETA: 10s - loss: 0.2513 - categorical_accuracy: 0.9607
 9216/13806 [===================>..........] - ETA: 10s - loss: 0.2507 - categorical_accuracy: 0.9612
 9344/13806 [===================>..........] - ETA: 9s - loss: 0.2508 - categorical_accuracy: 0.9612 
 9472/13806 [===================>..........] - ETA: 9s - loss: 0.2500 - categorical_accuracy: 0.9611
 9600/13806 [===================>..........] - ETA: 9s - loss: 0.2518 - categorical_accuracy: 0.9608
 9728/13806 [====================>.........] - ETA: 9s - loss: 0.2512 - categorical_accuracy: 0.9610
 9856/13806 [====================>.........] - ETA: 8s - loss: 0.2509 - categorical_accuracy: 0.9611
 9984/13806 [====================>.........] - ETA: 8s - loss: 0.2505 - categorical_accuracy: 0.9611
10112/13806 [====================>.........] - ETA: 8s - loss: 0.2500 - categorical_accuracy: 0.9611
10240/13806 [=====================>........] - ETA: 7s - loss: 0.2500 - categorical_accuracy: 0.9609
10368/13806 [=====================>........] - ETA: 7s - loss: 0.2494 - categorical_accuracy: 0.9610
10496/13806 [=====================>........] - ETA: 7s - loss: 0.2485 - categorical_accuracy: 0.9613
10624/13806 [======================>.......] - ETA: 7s - loss: 0.2480 - categorical_accuracy: 0.9616
10752/13806 [======================>.......] - ETA: 6s - loss: 0.2476 - categorical_accuracy: 0.9613
10880/13806 [======================>.......] - ETA: 6s - loss: 0.2479 - categorical_accuracy: 0.9612
11008/13806 [======================>.......] - ETA: 6s - loss: 0.2485 - categorical_accuracy: 0.9608
11136/13806 [=======================>......] - ETA: 5s - loss: 0.2482 - categorical_accuracy: 0.9607
11264/13806 [=======================>......] - ETA: 5s - loss: 0.2482 - categorical_accuracy: 0.9606
11392/13806 [=======================>......] - ETA: 5s - loss: 0.2490 - categorical_accuracy: 0.9606
11520/13806 [========================>.....] - ETA: 5s - loss: 0.2486 - categorical_accuracy: 0.9604
11648/13806 [========================>.....] - ETA: 4s - loss: 0.2485 - categorical_accuracy: 0.9603
11776/13806 [========================>.....] - ETA: 4s - loss: 0.2486 - categorical_accuracy: 0.9604
11904/13806 [========================>.....] - ETA: 4s - loss: 0.2490 - categorical_accuracy: 0.9601
12032/13806 [=========================>....] - ETA: 3s - loss: 0.2490 - categorical_accuracy: 0.9601
12160/13806 [=========================>....] - ETA: 3s - loss: 0.2487 - categorical_accuracy: 0.9603
12288/13806 [=========================>....] - ETA: 3s - loss: 0.2487 - categorical_accuracy: 0.9601
12416/13806 [=========================>....] - ETA: 3s - loss: 0.2482 - categorical_accuracy: 0.9602
12544/13806 [==========================>...] - ETA: 2s - loss: 0.2481 - categorical_accuracy: 0.9601
12672/13806 [==========================>...] - ETA: 2s - loss: 0.2479 - categorical_accuracy: 0.9601
12800/13806 [==========================>...] - ETA: 2s - loss: 0.2499 - categorical_accuracy: 0.9598
12928/13806 [===========================>..] - ETA: 1s - loss: 0.2509 - categorical_accuracy: 0.9595
13056/13806 [===========================>..] - ETA: 1s - loss: 0.2506 - categorical_accuracy: 0.9596
13184/13806 [===========================>..] - ETA: 1s - loss: 0.2502 - categorical_accuracy: 0.9597
13312/13806 [===========================>..] - ETA: 1s - loss: 0.2497 - categorical_accuracy: 0.9600
13440/13806 [============================>.] - ETA: 0s - loss: 0.2495 - categorical_accuracy: 0.9598
13568/13806 [============================>.] - ETA: 0s - loss: 0.2495 - categorical_accuracy: 0.9596
13696/13806 [============================>.] - ETA: 0s - loss: 0.2497 - categorical_accuracy: 0.9596
13806/13806 [==============================] - 32s 2ms/step - loss: 0.2502 - categorical_accuracy: 0.9595 - val_loss: 1.4821 - val_categorical_accuracy: 0.5315

Epoch 00004: val_categorical_accuracy did not improve
Epoch 5/15

  128/13806 [..............................] - ETA: 29s - loss: 0.3269 - categorical_accuracy: 0.9531
  256/13806 [..............................] - ETA: 29s - loss: 0.2687 - categorical_accuracy: 0.9688
  384/13806 [..............................] - ETA: 28s - loss: 0.2473 - categorical_accuracy: 0.9688
  512/13806 [>.............................] - ETA: 28s - loss: 0.2375 - categorical_accuracy: 0.9688
  640/13806 [>.............................] - ETA: 28s - loss: 0.2373 - categorical_accuracy: 0.9688
  768/13806 [>.............................] - ETA: 28s - loss: 0.2555 - categorical_accuracy: 0.9635
  896/13806 [>.............................] - ETA: 27s - loss: 0.2689 - categorical_accuracy: 0.9565
 1024/13806 [=>............................] - ETA: 27s - loss: 0.2667 - categorical_accuracy: 0.9541
 1152/13806 [=>............................] - ETA: 27s - loss: 0.2622 - categorical_accuracy: 0.9566
 1280/13806 [=>............................] - ETA: 27s - loss: 0.2572 - categorical_accuracy: 0.9570
 1408/13806 [==>...........................] - ETA: 27s - loss: 0.2496 - categorical_accuracy: 0.9602
 1536/13806 [==>...........................] - ETA: 26s - loss: 0.2501 - categorical_accuracy: 0.9616
 1664/13806 [==>...........................] - ETA: 26s - loss: 0.2452 - categorical_accuracy: 0.9627
 1792/13806 [==>...........................] - ETA: 26s - loss: 0.2435 - categorical_accuracy: 0.9626
 1920/13806 [===>..........................] - ETA: 26s - loss: 0.2422 - categorical_accuracy: 0.9609
 2048/13806 [===>..........................] - ETA: 26s - loss: 0.2417 - categorical_accuracy: 0.9609
 2176/13806 [===>..........................] - ETA: 25s - loss: 0.2360 - categorical_accuracy: 0.9632
 2304/13806 [====>.........................] - ETA: 25s - loss: 0.2344 - categorical_accuracy: 0.9640
 2432/13806 [====>.........................] - ETA: 25s - loss: 0.2343 - categorical_accuracy: 0.9638
 2560/13806 [====>.........................] - ETA: 24s - loss: 0.2326 - categorical_accuracy: 0.9645
 2688/13806 [====>.........................] - ETA: 24s - loss: 0.2337 - categorical_accuracy: 0.9635
 2816/13806 [=====>........................] - ETA: 24s - loss: 0.2331 - categorical_accuracy: 0.9634
 2944/13806 [=====>........................] - ETA: 24s - loss: 0.2313 - categorical_accuracy: 0.9633
 3072/13806 [=====>........................] - ETA: 23s - loss: 0.2309 - categorical_accuracy: 0.9632
 3200/13806 [=====>........................] - ETA: 23s - loss: 0.2297 - categorical_accuracy: 0.9634
 3328/13806 [======>.......................] - ETA: 23s - loss: 0.2272 - categorical_accuracy: 0.9639
 3456/13806 [======>.......................] - ETA: 23s - loss: 0.2272 - categorical_accuracy: 0.9638
 3584/13806 [======>.......................] - ETA: 22s - loss: 0.2276 - categorical_accuracy: 0.9634
 3712/13806 [=======>......................] - ETA: 22s - loss: 0.2295 - categorical_accuracy: 0.9634
 3840/13806 [=======>......................] - ETA: 22s - loss: 0.2289 - categorical_accuracy: 0.9628
 3968/13806 [=======>......................] - ETA: 21s - loss: 0.2284 - categorical_accuracy: 0.9635
 4096/13806 [=======>......................] - ETA: 21s - loss: 0.2288 - categorical_accuracy: 0.9636
 4224/13806 [========>.....................] - ETA: 21s - loss: 0.2280 - categorical_accuracy: 0.9638
 4352/13806 [========>.....................] - ETA: 21s - loss: 0.2262 - categorical_accuracy: 0.9646
 4480/13806 [========>.....................] - ETA: 20s - loss: 0.2276 - categorical_accuracy: 0.9643
 4608/13806 [=========>....................] - ETA: 20s - loss: 0.2273 - categorical_accuracy: 0.9644
 4736/13806 [=========>....................] - ETA: 20s - loss: 0.2283 - categorical_accuracy: 0.9641
 4864/13806 [=========>....................] - ETA: 19s - loss: 0.2276 - categorical_accuracy: 0.9646
 4992/13806 [=========>....................] - ETA: 19s - loss: 0.2273 - categorical_accuracy: 0.9647
 5120/13806 [==========>...................] - ETA: 19s - loss: 0.2250 - categorical_accuracy: 0.9654
 5248/13806 [==========>...................] - ETA: 19s - loss: 0.2257 - categorical_accuracy: 0.9657
 5376/13806 [==========>...................] - ETA: 18s - loss: 0.2252 - categorical_accuracy: 0.9658
 5504/13806 [==========>...................] - ETA: 18s - loss: 0.2257 - categorical_accuracy: 0.9658
 5632/13806 [===========>..................] - ETA: 18s - loss: 0.2242 - categorical_accuracy: 0.9663
 5760/13806 [===========>..................] - ETA: 18s - loss: 0.2230 - categorical_accuracy: 0.9665
 5888/13806 [===========>..................] - ETA: 17s - loss: 0.2235 - categorical_accuracy: 0.9660
 6016/13806 [============>.................] - ETA: 17s - loss: 0.2230 - categorical_accuracy: 0.9659
 6144/13806 [============>.................] - ETA: 17s - loss: 0.2219 - categorical_accuracy: 0.9660
 6272/13806 [============>.................] - ETA: 16s - loss: 0.2217 - categorical_accuracy: 0.9662
 6400/13806 [============>.................] - ETA: 16s - loss: 0.2228 - categorical_accuracy: 0.9661
 6528/13806 [=============>................] - ETA: 16s - loss: 0.2221 - categorical_accuracy: 0.9661
 6656/13806 [=============>................] - ETA: 16s - loss: 0.2244 - categorical_accuracy: 0.9656
 6784/13806 [=============>................] - ETA: 15s - loss: 0.2256 - categorical_accuracy: 0.9657
 6912/13806 [==============>...............] - ETA: 15s - loss: 0.2258 - categorical_accuracy: 0.9653
 7040/13806 [==============>...............] - ETA: 15s - loss: 0.2256 - categorical_accuracy: 0.9649
 7168/13806 [==============>...............] - ETA: 14s - loss: 0.2253 - categorical_accuracy: 0.9648
 7296/13806 [==============>...............] - ETA: 14s - loss: 0.2247 - categorical_accuracy: 0.9649
 7424/13806 [===============>..............] - ETA: 14s - loss: 0.2243 - categorical_accuracy: 0.9650
 7552/13806 [===============>..............] - ETA: 14s - loss: 0.2244 - categorical_accuracy: 0.9649
 7680/13806 [===============>..............] - ETA: 13s - loss: 0.2239 - categorical_accuracy: 0.9648
 7808/13806 [===============>..............] - ETA: 13s - loss: 0.2237 - categorical_accuracy: 0.9648
 7936/13806 [================>.............] - ETA: 13s - loss: 0.2236 - categorical_accuracy: 0.9645
 8064/13806 [================>.............] - ETA: 12s - loss: 0.2239 - categorical_accuracy: 0.9643
 8192/13806 [================>.............] - ETA: 12s - loss: 0.2236 - categorical_accuracy: 0.9644
 8320/13806 [=================>............] - ETA: 12s - loss: 0.2245 - categorical_accuracy: 0.9641
 8448/13806 [=================>............] - ETA: 12s - loss: 0.2243 - categorical_accuracy: 0.9640
 8576/13806 [=================>............] - ETA: 11s - loss: 0.2240 - categorical_accuracy: 0.9642
 8704/13806 [=================>............] - ETA: 11s - loss: 0.2236 - categorical_accuracy: 0.9642
 8832/13806 [==================>...........] - ETA: 11s - loss: 0.2230 - categorical_accuracy: 0.9644
 8960/13806 [==================>...........] - ETA: 10s - loss: 0.2227 - categorical_accuracy: 0.9646
 9088/13806 [==================>...........] - ETA: 10s - loss: 0.2232 - categorical_accuracy: 0.9645
 9216/13806 [===================>..........] - ETA: 10s - loss: 0.2247 - categorical_accuracy: 0.9635
 9344/13806 [===================>..........] - ETA: 10s - loss: 0.2238 - categorical_accuracy: 0.9639
 9472/13806 [===================>..........] - ETA: 9s - loss: 0.2242 - categorical_accuracy: 0.9640 
 9600/13806 [===================>..........] - ETA: 9s - loss: 0.2247 - categorical_accuracy: 0.9640
 9728/13806 [====================>.........] - ETA: 9s - loss: 0.2250 - categorical_accuracy: 0.9638
 9856/13806 [====================>.........] - ETA: 8s - loss: 0.2246 - categorical_accuracy: 0.9638
 9984/13806 [====================>.........] - ETA: 8s - loss: 0.2245 - categorical_accuracy: 0.9636
10112/13806 [====================>.........] - ETA: 8s - loss: 0.2245 - categorical_accuracy: 0.9635
10240/13806 [=====================>........] - ETA: 8s - loss: 0.2244 - categorical_accuracy: 0.9636
10368/13806 [=====================>........] - ETA: 7s - loss: 0.2243 - categorical_accuracy: 0.9633
10496/13806 [=====================>........] - ETA: 7s - loss: 0.2233 - categorical_accuracy: 0.9637
10624/13806 [======================>.......] - ETA: 7s - loss: 0.2225 - categorical_accuracy: 0.9639
10752/13806 [======================>.......] - ETA: 6s - loss: 0.2227 - categorical_accuracy: 0.9636
10880/13806 [======================>.......] - ETA: 6s - loss: 0.2223 - categorical_accuracy: 0.9638
11008/13806 [======================>.......] - ETA: 6s - loss: 0.2230 - categorical_accuracy: 0.9635
11136/13806 [=======================>......] - ETA: 6s - loss: 0.2237 - categorical_accuracy: 0.9635
11264/13806 [=======================>......] - ETA: 5s - loss: 0.2229 - categorical_accuracy: 0.9638
11392/13806 [=======================>......] - ETA: 5s - loss: 0.2232 - categorical_accuracy: 0.9638
11520/13806 [========================>.....] - ETA: 5s - loss: 0.2226 - categorical_accuracy: 0.9638
11648/13806 [========================>.....] - ETA: 4s - loss: 0.2222 - categorical_accuracy: 0.9639
11776/13806 [========================>.....] - ETA: 4s - loss: 0.2219 - categorical_accuracy: 0.9640
11904/13806 [========================>.....] - ETA: 4s - loss: 0.2213 - categorical_accuracy: 0.9642
12032/13806 [=========================>....] - ETA: 4s - loss: 0.2213 - categorical_accuracy: 0.9644
12160/13806 [=========================>....] - ETA: 3s - loss: 0.2209 - categorical_accuracy: 0.9644
12288/13806 [=========================>....] - ETA: 3s - loss: 0.2204 - categorical_accuracy: 0.9644
12416/13806 [=========================>....] - ETA: 3s - loss: 0.2210 - categorical_accuracy: 0.9641
12544/13806 [==========================>...] - ETA: 2s - loss: 0.2206 - categorical_accuracy: 0.9641
12672/13806 [==========================>...] - ETA: 2s - loss: 0.2208 - categorical_accuracy: 0.9641
12800/13806 [==========================>...] - ETA: 2s - loss: 0.2210 - categorical_accuracy: 0.9640
12928/13806 [===========================>..] - ETA: 1s - loss: 0.2212 - categorical_accuracy: 0.9640
13056/13806 [===========================>..] - ETA: 1s - loss: 0.2208 - categorical_accuracy: 0.9640
13184/13806 [===========================>..] - ETA: 1s - loss: 0.2206 - categorical_accuracy: 0.9640
13312/13806 [===========================>..] - ETA: 1s - loss: 0.2202 - categorical_accuracy: 0.9642
13440/13806 [============================>.] - ETA: 0s - loss: 0.2209 - categorical_accuracy: 0.9638
13568/13806 [============================>.] - ETA: 0s - loss: 0.2202 - categorical_accuracy: 0.9639
13696/13806 [============================>.] - ETA: 0s - loss: 0.2197 - categorical_accuracy: 0.9639
13806/13806 [==============================] - 32s 2ms/step - loss: 0.2193 - categorical_accuracy: 0.9641 - val_loss: 1.5798 - val_categorical_accuracy: 0.5268

Epoch 00005: val_categorical_accuracy did not improve
Epoch 6/15

  128/13806 [..............................] - ETA: 30s - loss: 0.2227 - categorical_accuracy: 0.9609
  256/13806 [..............................] - ETA: 30s - loss: 0.1813 - categorical_accuracy: 0.9766
  384/13806 [..............................] - ETA: 30s - loss: 0.2140 - categorical_accuracy: 0.9688
  512/13806 [>.............................] - ETA: 29s - loss: 0.2266 - categorical_accuracy: 0.9570
  640/13806 [>.............................] - ETA: 29s - loss: 0.2217 - categorical_accuracy: 0.9578
  768/13806 [>.............................] - ETA: 29s - loss: 0.2328 - categorical_accuracy: 0.9570
  896/13806 [>.............................] - ETA: 28s - loss: 0.2270 - categorical_accuracy: 0.9554
 1024/13806 [=>............................] - ETA: 28s - loss: 0.2278 - categorical_accuracy: 0.9541
 1152/13806 [=>............................] - ETA: 28s - loss: 0.2258 - categorical_accuracy: 0.9523
 1280/13806 [=>............................] - ETA: 28s - loss: 0.2206 - categorical_accuracy: 0.9531
 1408/13806 [==>...........................] - ETA: 27s - loss: 0.2250 - categorical_accuracy: 0.9517
 1536/13806 [==>...........................] - ETA: 27s - loss: 0.2223 - categorical_accuracy: 0.9525
 1664/13806 [==>...........................] - ETA: 27s - loss: 0.2229 - categorical_accuracy: 0.9525
 1792/13806 [==>...........................] - ETA: 26s - loss: 0.2254 - categorical_accuracy: 0.9515
 1920/13806 [===>..........................] - ETA: 26s - loss: 0.2225 - categorical_accuracy: 0.9531
 2048/13806 [===>..........................] - ETA: 26s - loss: 0.2219 - categorical_accuracy: 0.9546
 2176/13806 [===>..........................] - ETA: 25s - loss: 0.2198 - categorical_accuracy: 0.9554
 2304/13806 [====>.........................] - ETA: 25s - loss: 0.2253 - categorical_accuracy: 0.9544
 2432/13806 [====>.........................] - ETA: 25s - loss: 0.2231 - categorical_accuracy: 0.9552
 2560/13806 [====>.........................] - ETA: 25s - loss: 0.2274 - categorical_accuracy: 0.9539
 2688/13806 [====>.........................] - ETA: 25s - loss: 0.2256 - categorical_accuracy: 0.9542
 2816/13806 [=====>........................] - ETA: 24s - loss: 0.2245 - categorical_accuracy: 0.9542
 2944/13806 [=====>........................] - ETA: 24s - loss: 0.2214 - categorical_accuracy: 0.9552
 3072/13806 [=====>........................] - ETA: 24s - loss: 0.2195 - categorical_accuracy: 0.9561
 3200/13806 [=====>........................] - ETA: 23s - loss: 0.2192 - categorical_accuracy: 0.9566
 3328/13806 [======>.......................] - ETA: 23s - loss: 0.2222 - categorical_accuracy: 0.9561
 3456/13806 [======>.......................] - ETA: 23s - loss: 0.2202 - categorical_accuracy: 0.9563
 3584/13806 [======>.......................] - ETA: 23s - loss: 0.2246 - categorical_accuracy: 0.9551
 3712/13806 [=======>......................] - ETA: 22s - loss: 0.2243 - categorical_accuracy: 0.9561
 3840/13806 [=======>......................] - ETA: 22s - loss: 0.2233 - categorical_accuracy: 0.9560
 3968/13806 [=======>......................] - ETA: 22s - loss: 0.2249 - categorical_accuracy: 0.9551
 4096/13806 [=======>......................] - ETA: 21s - loss: 0.2254 - categorical_accuracy: 0.9553
 4224/13806 [========>.....................] - ETA: 21s - loss: 0.2240 - categorical_accuracy: 0.9555
 4352/13806 [========>.....................] - ETA: 21s - loss: 0.2234 - categorical_accuracy: 0.9554
 4480/13806 [========>.....................] - ETA: 21s - loss: 0.2242 - categorical_accuracy: 0.9558
 4608/13806 [=========>....................] - ETA: 20s - loss: 0.2236 - categorical_accuracy: 0.9562
 4736/13806 [=========>....................] - ETA: 20s - loss: 0.2231 - categorical_accuracy: 0.9571
 4864/13806 [=========>....................] - ETA: 20s - loss: 0.2241 - categorical_accuracy: 0.9568
 4992/13806 [=========>....................] - ETA: 19s - loss: 0.2232 - categorical_accuracy: 0.9569
 5120/13806 [==========>...................] - ETA: 19s - loss: 0.2240 - categorical_accuracy: 0.9572
 5248/13806 [==========>...................] - ETA: 19s - loss: 0.2256 - categorical_accuracy: 0.9569
 5376/13806 [==========>...................] - ETA: 18s - loss: 0.2247 - categorical_accuracy: 0.9572
 5504/13806 [==========>...................] - ETA: 18s - loss: 0.2258 - categorical_accuracy: 0.9573
 5632/13806 [===========>..................] - ETA: 18s - loss: 0.2246 - categorical_accuracy: 0.9579
 5760/13806 [===========>..................] - ETA: 18s - loss: 0.2257 - categorical_accuracy: 0.9576
 5888/13806 [===========>..................] - ETA: 17s - loss: 0.2258 - categorical_accuracy: 0.9579
 6016/13806 [============>.................] - ETA: 17s - loss: 0.2253 - categorical_accuracy: 0.9583
 6144/13806 [============>.................] - ETA: 17s - loss: 0.2242 - categorical_accuracy: 0.9582
 6272/13806 [============>.................] - ETA: 16s - loss: 0.2237 - categorical_accuracy: 0.9582
 6400/13806 [============>.................] - ETA: 16s - loss: 0.2226 - categorical_accuracy: 0.9586
 6528/13806 [=============>................] - ETA: 16s - loss: 0.2235 - categorical_accuracy: 0.9585
 6656/13806 [=============>................] - ETA: 16s - loss: 0.2228 - categorical_accuracy: 0.9587
 6784/13806 [=============>................] - ETA: 15s - loss: 0.2216 - categorical_accuracy: 0.9589
 6912/13806 [==============>...............] - ETA: 15s - loss: 0.2209 - categorical_accuracy: 0.9592
 7040/13806 [==============>...............] - ETA: 15s - loss: 0.2201 - categorical_accuracy: 0.9594
 7168/13806 [==============>...............] - ETA: 14s - loss: 0.2198 - categorical_accuracy: 0.9595
 7296/13806 [==============>...............] - ETA: 14s - loss: 0.2205 - categorical_accuracy: 0.9594
 7424/13806 [===============>..............] - ETA: 14s - loss: 0.2197 - categorical_accuracy: 0.9596
 7552/13806 [===============>..............] - ETA: 14s - loss: 0.2201 - categorical_accuracy: 0.9592
 7680/13806 [===============>..............] - ETA: 13s - loss: 0.2192 - categorical_accuracy: 0.9596
 7808/13806 [===============>..............] - ETA: 13s - loss: 0.2182 - categorical_accuracy: 0.9597
 7936/13806 [================>.............] - ETA: 13s - loss: 0.2179 - categorical_accuracy: 0.9597
 8064/13806 [================>.............] - ETA: 12s - loss: 0.2182 - categorical_accuracy: 0.9591
 8192/13806 [================>.............] - ETA: 12s - loss: 0.2179 - categorical_accuracy: 0.9595
 8320/13806 [=================>............] - ETA: 12s - loss: 0.2173 - categorical_accuracy: 0.9599
 8448/13806 [=================>............] - ETA: 12s - loss: 0.2169 - categorical_accuracy: 0.9599
 8576/13806 [=================>............] - ETA: 11s - loss: 0.2158 - categorical_accuracy: 0.9600
 8704/13806 [=================>............] - ETA: 11s - loss: 0.2172 - categorical_accuracy: 0.9600
 8832/13806 [==================>...........] - ETA: 11s - loss: 0.2162 - categorical_accuracy: 0.9603
 8960/13806 [==================>...........] - ETA: 10s - loss: 0.2152 - categorical_accuracy: 0.9605
 9088/13806 [==================>...........] - ETA: 10s - loss: 0.2143 - categorical_accuracy: 0.9608
 9216/13806 [===================>..........] - ETA: 10s - loss: 0.2139 - categorical_accuracy: 0.9607
 9344/13806 [===================>..........] - ETA: 10s - loss: 0.2147 - categorical_accuracy: 0.9604
 9472/13806 [===================>..........] - ETA: 9s - loss: 0.2147 - categorical_accuracy: 0.9605 
 9600/13806 [===================>..........] - ETA: 9s - loss: 0.2138 - categorical_accuracy: 0.9608
 9728/13806 [====================>.........] - ETA: 9s - loss: 0.2129 - categorical_accuracy: 0.9611
 9856/13806 [====================>.........] - ETA: 8s - loss: 0.2119 - categorical_accuracy: 0.9614
 9984/13806 [====================>.........] - ETA: 8s - loss: 0.2121 - categorical_accuracy: 0.9611
10112/13806 [====================>.........] - ETA: 8s - loss: 0.2131 - categorical_accuracy: 0.9610
10240/13806 [=====================>........] - ETA: 8s - loss: 0.2133 - categorical_accuracy: 0.9609
10368/13806 [=====================>........] - ETA: 7s - loss: 0.2145 - categorical_accuracy: 0.9606
10496/13806 [=====================>........] - ETA: 7s - loss: 0.2159 - categorical_accuracy: 0.9604
10624/13806 [======================>.......] - ETA: 7s - loss: 0.2168 - categorical_accuracy: 0.9600
10752/13806 [======================>.......] - ETA: 6s - loss: 0.2164 - categorical_accuracy: 0.9601
10880/13806 [======================>.......] - ETA: 6s - loss: 0.2165 - categorical_accuracy: 0.9600
11008/13806 [======================>.......] - ETA: 6s - loss: 0.2179 - categorical_accuracy: 0.9600
11136/13806 [=======================>......] - ETA: 6s - loss: 0.2180 - categorical_accuracy: 0.9600
11264/13806 [=======================>......] - ETA: 5s - loss: 0.2171 - categorical_accuracy: 0.9604
11392/13806 [=======================>......] - ETA: 5s - loss: 0.2171 - categorical_accuracy: 0.9603
11520/13806 [========================>.....] - ETA: 5s - loss: 0.2179 - categorical_accuracy: 0.9603
11648/13806 [========================>.....] - ETA: 4s - loss: 0.2176 - categorical_accuracy: 0.9603
11776/13806 [========================>.....] - ETA: 4s - loss: 0.2177 - categorical_accuracy: 0.9603
11904/13806 [========================>.....] - ETA: 4s - loss: 0.2172 - categorical_accuracy: 0.9603
12032/13806 [=========================>....] - ETA: 4s - loss: 0.2170 - categorical_accuracy: 0.9604
12160/13806 [=========================>....] - ETA: 3s - loss: 0.2166 - categorical_accuracy: 0.9607
12288/13806 [=========================>....] - ETA: 3s - loss: 0.2160 - categorical_accuracy: 0.9609
12416/13806 [=========================>....] - ETA: 3s - loss: 0.2164 - categorical_accuracy: 0.9605
12544/13806 [==========================>...] - ETA: 2s - loss: 0.2158 - categorical_accuracy: 0.9608
12672/13806 [==========================>...] - ETA: 2s - loss: 0.2155 - categorical_accuracy: 0.9607
12800/13806 [==========================>...] - ETA: 2s - loss: 0.2150 - categorical_accuracy: 0.9609
12928/13806 [===========================>..] - ETA: 2s - loss: 0.2144 - categorical_accuracy: 0.9612
13056/13806 [===========================>..] - ETA: 1s - loss: 0.2139 - categorical_accuracy: 0.9612
13184/13806 [===========================>..] - ETA: 1s - loss: 0.2135 - categorical_accuracy: 0.9613
13312/13806 [===========================>..] - ETA: 1s - loss: 0.2133 - categorical_accuracy: 0.9616
13440/13806 [============================>.] - ETA: 0s - loss: 0.2140 - categorical_accuracy: 0.9613
13568/13806 [============================>.] - ETA: 0s - loss: 0.2145 - categorical_accuracy: 0.9611
13696/13806 [============================>.] - ETA: 0s - loss: 0.2150 - categorical_accuracy: 0.9610
13806/13806 [==============================] - 33s 2ms/step - loss: 0.2145 - categorical_accuracy: 0.9611 - val_loss: 1.4906 - val_categorical_accuracy: 0.5368

Epoch 00006: val_categorical_accuracy improved from 0.53280 to 0.53678, saving model to results/vardial2018/multi_input_half_with_dropout/model_weights.hdf5
Epoch 7/15

  128/13806 [..............................] - ETA: 31s - loss: 0.2145 - categorical_accuracy: 0.9609
  256/13806 [..............................] - ETA: 30s - loss: 0.1988 - categorical_accuracy: 0.9648
  384/13806 [..............................] - ETA: 30s - loss: 0.2545 - categorical_accuracy: 0.9505
  512/13806 [>.............................] - ETA: 30s - loss: 0.2415 - categorical_accuracy: 0.9570
  640/13806 [>.............................] - ETA: 29s - loss: 0.2208 - categorical_accuracy: 0.9609
  768/13806 [>.............................] - ETA: 29s - loss: 0.2238 - categorical_accuracy: 0.9609
  896/13806 [>.............................] - ETA: 28s - loss: 0.2274 - categorical_accuracy: 0.9576
 1024/13806 [=>............................] - ETA: 28s - loss: 0.2156 - categorical_accuracy: 0.9609
 1152/13806 [=>............................] - ETA: 28s - loss: 0.2126 - categorical_accuracy: 0.9627
 1280/13806 [=>............................] - ETA: 28s - loss: 0.2094 - categorical_accuracy: 0.9641
 1408/13806 [==>...........................] - ETA: 28s - loss: 0.2088 - categorical_accuracy: 0.9645
 1536/13806 [==>...........................] - ETA: 27s - loss: 0.2055 - categorical_accuracy: 0.9648
 1664/13806 [==>...........................] - ETA: 27s - loss: 0.2050 - categorical_accuracy: 0.9645
 1792/13806 [==>...........................] - ETA: 27s - loss: 0.2082 - categorical_accuracy: 0.9643
 1920/13806 [===>..........................] - ETA: 26s - loss: 0.2099 - categorical_accuracy: 0.9635
 2048/13806 [===>..........................] - ETA: 26s - loss: 0.2081 - categorical_accuracy: 0.9653
 2176/13806 [===>..........................] - ETA: 26s - loss: 0.2069 - categorical_accuracy: 0.9646
 2304/13806 [====>.........................] - ETA: 25s - loss: 0.2083 - categorical_accuracy: 0.9644
 2432/13806 [====>.........................] - ETA: 25s - loss: 0.2111 - categorical_accuracy: 0.9622
 2560/13806 [====>.........................] - ETA: 25s - loss: 0.2126 - categorical_accuracy: 0.9617
 2688/13806 [====>.........................] - ETA: 25s - loss: 0.2131 - categorical_accuracy: 0.9621
 2816/13806 [=====>........................] - ETA: 24s - loss: 0.2101 - categorical_accuracy: 0.9631
 2944/13806 [=====>........................] - ETA: 24s - loss: 0.2110 - categorical_accuracy: 0.9630
 3072/13806 [=====>........................] - ETA: 24s - loss: 0.2135 - categorical_accuracy: 0.9613
 3200/13806 [=====>........................] - ETA: 23s - loss: 0.2148 - categorical_accuracy: 0.9609
 3328/13806 [======>.......................] - ETA: 23s - loss: 0.2144 - categorical_accuracy: 0.9612
 3456/13806 [======>.......................] - ETA: 23s - loss: 0.2151 - categorical_accuracy: 0.9609
 3584/13806 [======>.......................] - ETA: 23s - loss: 0.2123 - categorical_accuracy: 0.9618
 3712/13806 [=======>......................] - ETA: 22s - loss: 0.2151 - categorical_accuracy: 0.9612
 3840/13806 [=======>......................] - ETA: 22s - loss: 0.2146 - categorical_accuracy: 0.9609
 3968/13806 [=======>......................] - ETA: 22s - loss: 0.2136 - categorical_accuracy: 0.9614
 4096/13806 [=======>......................] - ETA: 22s - loss: 0.2115 - categorical_accuracy: 0.9619
 4224/13806 [========>.....................] - ETA: 21s - loss: 0.2097 - categorical_accuracy: 0.9626
 4352/13806 [========>.....................] - ETA: 21s - loss: 0.2072 - categorical_accuracy: 0.9632
 4480/13806 [========>.....................] - ETA: 21s - loss: 0.2087 - categorical_accuracy: 0.9634
 4608/13806 [=========>....................] - ETA: 20s - loss: 0.2072 - categorical_accuracy: 0.9633
 4736/13806 [=========>....................] - ETA: 20s - loss: 0.2067 - categorical_accuracy: 0.9635
 4864/13806 [=========>....................] - ETA: 20s - loss: 0.2086 - categorical_accuracy: 0.9628
 4992/13806 [=========>....................] - ETA: 20s - loss: 0.2084 - categorical_accuracy: 0.9627
 5120/13806 [==========>...................] - ETA: 19s - loss: 0.2074 - categorical_accuracy: 0.9629
 5248/13806 [==========>...................] - ETA: 19s - loss: 0.2068 - categorical_accuracy: 0.9630
 5376/13806 [==========>...................] - ETA: 19s - loss: 0.2089 - categorical_accuracy: 0.9621
 5504/13806 [==========>...................] - ETA: 18s - loss: 0.2080 - categorical_accuracy: 0.9624
 5632/13806 [===========>..................] - ETA: 18s - loss: 0.2069 - categorical_accuracy: 0.9625
 5760/13806 [===========>..................] - ETA: 18s - loss: 0.2079 - categorical_accuracy: 0.9625
 5888/13806 [===========>..................] - ETA: 18s - loss: 0.2087 - categorical_accuracy: 0.9626
 6016/13806 [============>.................] - ETA: 17s - loss: 0.2101 - categorical_accuracy: 0.9623
 6144/13806 [============>.................] - ETA: 17s - loss: 0.2112 - categorical_accuracy: 0.9618
 6272/13806 [============>.................] - ETA: 17s - loss: 0.2109 - categorical_accuracy: 0.9617
 6400/13806 [============>.................] - ETA: 16s - loss: 0.2115 - categorical_accuracy: 0.9614
 6528/13806 [=============>................] - ETA: 16s - loss: 0.2114 - categorical_accuracy: 0.9616
 6656/13806 [=============>................] - ETA: 16s - loss: 0.2104 - categorical_accuracy: 0.9618
 6784/13806 [=============>................] - ETA: 15s - loss: 0.2091 - categorical_accuracy: 0.9623
 6912/13806 [==============>...............] - ETA: 15s - loss: 0.2097 - categorical_accuracy: 0.9624
 7040/13806 [==============>...............] - ETA: 15s - loss: 0.2082 - categorical_accuracy: 0.9628
 7168/13806 [==============>...............] - ETA: 15s - loss: 0.2065 - categorical_accuracy: 0.9633
 7296/13806 [==============>...............] - ETA: 14s - loss: 0.2090 - categorical_accuracy: 0.9624
 7424/13806 [===============>..............] - ETA: 14s - loss: 0.2113 - categorical_accuracy: 0.9616
 7552/13806 [===============>..............] - ETA: 14s - loss: 0.2098 - categorical_accuracy: 0.9620
 7680/13806 [===============>..............] - ETA: 13s - loss: 0.2105 - categorical_accuracy: 0.9620
 7808/13806 [===============>..............] - ETA: 13s - loss: 0.2109 - categorical_accuracy: 0.9614
 7936/13806 [================>.............] - ETA: 13s - loss: 0.2123 - categorical_accuracy: 0.9609
 8064/13806 [================>.............] - ETA: 13s - loss: 0.2115 - categorical_accuracy: 0.9613
 8192/13806 [================>.............] - ETA: 12s - loss: 0.2107 - categorical_accuracy: 0.9614
 8320/13806 [=================>............] - ETA: 12s - loss: 0.2101 - categorical_accuracy: 0.9615
 8448/13806 [=================>............] - ETA: 12s - loss: 0.2105 - categorical_accuracy: 0.9613
 8576/13806 [=================>............] - ETA: 11s - loss: 0.2099 - categorical_accuracy: 0.9614
 8704/13806 [=================>............] - ETA: 11s - loss: 0.2091 - categorical_accuracy: 0.9616
 8832/13806 [==================>...........] - ETA: 11s - loss: 0.2089 - categorical_accuracy: 0.9615
 8960/13806 [==================>...........] - ETA: 11s - loss: 0.2091 - categorical_accuracy: 0.9614
 9088/13806 [==================>...........] - ETA: 10s - loss: 0.2087 - categorical_accuracy: 0.9615
 9216/13806 [===================>..........] - ETA: 10s - loss: 0.2081 - categorical_accuracy: 0.9616
 9344/13806 [===================>..........] - ETA: 10s - loss: 0.2092 - categorical_accuracy: 0.9614
 9472/13806 [===================>..........] - ETA: 9s - loss: 0.2092 - categorical_accuracy: 0.9615 
 9600/13806 [===================>..........] - ETA: 9s - loss: 0.2094 - categorical_accuracy: 0.9614
 9728/13806 [====================>.........] - ETA: 9s - loss: 0.2092 - categorical_accuracy: 0.9613
 9856/13806 [====================>.........] - ETA: 8s - loss: 0.2086 - categorical_accuracy: 0.9616
 9984/13806 [====================>.........] - ETA: 8s - loss: 0.2090 - categorical_accuracy: 0.9615
10112/13806 [====================>.........] - ETA: 8s - loss: 0.2091 - categorical_accuracy: 0.9615
10240/13806 [=====================>........] - ETA: 8s - loss: 0.2089 - categorical_accuracy: 0.9614
10368/13806 [=====================>........] - ETA: 7s - loss: 0.2086 - categorical_accuracy: 0.9615
10496/13806 [=====================>........] - ETA: 7s - loss: 0.2094 - categorical_accuracy: 0.9615
10624/13806 [======================>.......] - ETA: 7s - loss: 0.2096 - categorical_accuracy: 0.9614
10752/13806 [======================>.......] - ETA: 6s - loss: 0.2091 - categorical_accuracy: 0.9614
10880/13806 [======================>.......] - ETA: 6s - loss: 0.2089 - categorical_accuracy: 0.9613
11008/13806 [======================>.......] - ETA: 6s - loss: 0.2084 - categorical_accuracy: 0.9615
11136/13806 [=======================>......] - ETA: 6s - loss: 0.2077 - categorical_accuracy: 0.9617
11264/13806 [=======================>......] - ETA: 5s - loss: 0.2089 - categorical_accuracy: 0.9616
11392/13806 [=======================>......] - ETA: 5s - loss: 0.2092 - categorical_accuracy: 0.9614
11520/13806 [========================>.....] - ETA: 5s - loss: 0.2088 - categorical_accuracy: 0.9617
11648/13806 [========================>.....] - ETA: 4s - loss: 0.2085 - categorical_accuracy: 0.9620
11776/13806 [========================>.....] - ETA: 4s - loss: 0.2080 - categorical_accuracy: 0.9620
11904/13806 [========================>.....] - ETA: 4s - loss: 0.2074 - categorical_accuracy: 0.9623
12032/13806 [=========================>....] - ETA: 4s - loss: 0.2074 - categorical_accuracy: 0.9621
12160/13806 [=========================>....] - ETA: 3s - loss: 0.2080 - categorical_accuracy: 0.9621
12288/13806 [=========================>....] - ETA: 3s - loss: 0.2098 - categorical_accuracy: 0.9618
12416/13806 [=========================>....] - ETA: 3s - loss: 0.2100 - categorical_accuracy: 0.9617
12544/13806 [==========================>...] - ETA: 2s - loss: 0.2099 - categorical_accuracy: 0.9619
12672/13806 [==========================>...] - ETA: 2s - loss: 0.2095 - categorical_accuracy: 0.9620
12800/13806 [==========================>...] - ETA: 2s - loss: 0.2088 - categorical_accuracy: 0.9623
12928/13806 [===========================>..] - ETA: 1s - loss: 0.2080 - categorical_accuracy: 0.9625
13056/13806 [===========================>..] - ETA: 1s - loss: 0.2083 - categorical_accuracy: 0.9622
13184/13806 [===========================>..] - ETA: 1s - loss: 0.2079 - categorical_accuracy: 0.9622
13312/13806 [===========================>..] - ETA: 1s - loss: 0.2081 - categorical_accuracy: 0.9615
13440/13806 [============================>.] - ETA: 0s - loss: 0.2077 - categorical_accuracy: 0.9616
13568/13806 [============================>.] - ETA: 0s - loss: 0.2078 - categorical_accuracy: 0.9617
13696/13806 [============================>.] - ETA: 0s - loss: 0.2078 - categorical_accuracy: 0.9617
13806/13806 [==============================] - 32s 2ms/step - loss: 0.2081 - categorical_accuracy: 0.9615 - val_loss: 1.4765 - val_categorical_accuracy: 0.5474

Epoch 00007: val_categorical_accuracy improved from 0.53678 to 0.54738, saving model to results/vardial2018/multi_input_half_with_dropout/model_weights.hdf5
Epoch 8/15

  128/13806 [..............................] - ETA: 29s - loss: 0.1948 - categorical_accuracy: 0.9766
  256/13806 [..............................] - ETA: 29s - loss: 0.2032 - categorical_accuracy: 0.9688
  384/13806 [..............................] - ETA: 30s - loss: 0.1882 - categorical_accuracy: 0.9740
  512/13806 [>.............................] - ETA: 29s - loss: 0.1824 - categorical_accuracy: 0.9707
  640/13806 [>.............................] - ETA: 29s - loss: 0.1861 - categorical_accuracy: 0.9672
  768/13806 [>.............................] - ETA: 29s - loss: 0.1885 - categorical_accuracy: 0.9674
  896/13806 [>.............................] - ETA: 29s - loss: 0.1935 - categorical_accuracy: 0.9654
 1024/13806 [=>............................] - ETA: 28s - loss: 0.1937 - categorical_accuracy: 0.9668
 1152/13806 [=>............................] - ETA: 28s - loss: 0.1954 - categorical_accuracy: 0.9653
 1280/13806 [=>............................] - ETA: 28s - loss: 0.1932 - categorical_accuracy: 0.9664
 1408/13806 [==>...........................] - ETA: 27s - loss: 0.1904 - categorical_accuracy: 0.9673
 1536/13806 [==>...........................] - ETA: 27s - loss: 0.1928 - categorical_accuracy: 0.9655
 1664/13806 [==>...........................] - ETA: 27s - loss: 0.1937 - categorical_accuracy: 0.9651
 1792/13806 [==>...........................] - ETA: 26s - loss: 0.1964 - categorical_accuracy: 0.9654
 1920/13806 [===>..........................] - ETA: 26s - loss: 0.1963 - categorical_accuracy: 0.9651
 2048/13806 [===>..........................] - ETA: 26s - loss: 0.2025 - categorical_accuracy: 0.9634
 2176/13806 [===>..........................] - ETA: 26s - loss: 0.2021 - categorical_accuracy: 0.9637
 2304/13806 [====>.........................] - ETA: 25s - loss: 0.1994 - categorical_accuracy: 0.9640
 2432/13806 [====>.........................] - ETA: 25s - loss: 0.1989 - categorical_accuracy: 0.9642
 2560/13806 [====>.........................] - ETA: 25s - loss: 0.1997 - categorical_accuracy: 0.9641
 2688/13806 [====>.........................] - ETA: 25s - loss: 0.1990 - categorical_accuracy: 0.9643
 2816/13806 [=====>........................] - ETA: 24s - loss: 0.1986 - categorical_accuracy: 0.9648
 2944/13806 [=====>........................] - ETA: 24s - loss: 0.2001 - categorical_accuracy: 0.9650
 3072/13806 [=====>........................] - ETA: 24s - loss: 0.2006 - categorical_accuracy: 0.9648
 3200/13806 [=====>........................] - ETA: 24s - loss: 0.2004 - categorical_accuracy: 0.9647
 3328/13806 [======>.......................] - ETA: 23s - loss: 0.1994 - categorical_accuracy: 0.9639
 3456/13806 [======>.......................] - ETA: 23s - loss: 0.1990 - categorical_accuracy: 0.9638
 3584/13806 [======>.......................] - ETA: 23s - loss: 0.1978 - categorical_accuracy: 0.9640
 3712/13806 [=======>......................] - ETA: 22s - loss: 0.1964 - categorical_accuracy: 0.9639
 3840/13806 [=======>......................] - ETA: 22s - loss: 0.1973 - categorical_accuracy: 0.9635
 3968/13806 [=======>......................] - ETA: 22s - loss: 0.1996 - categorical_accuracy: 0.9630
 4096/13806 [=======>......................] - ETA: 22s - loss: 0.2007 - categorical_accuracy: 0.9624
 4224/13806 [========>.....................] - ETA: 21s - loss: 0.2010 - categorical_accuracy: 0.9621
 4352/13806 [========>.....................] - ETA: 21s - loss: 0.2020 - categorical_accuracy: 0.9619
 4480/13806 [========>.....................] - ETA: 21s - loss: 0.2038 - categorical_accuracy: 0.9618
 4608/13806 [=========>....................] - ETA: 20s - loss: 0.2020 - categorical_accuracy: 0.9622
 4736/13806 [=========>....................] - ETA: 20s - loss: 0.2006 - categorical_accuracy: 0.9626
 4864/13806 [=========>....................] - ETA: 20s - loss: 0.1988 - categorical_accuracy: 0.9632
 4992/13806 [=========>....................] - ETA: 20s - loss: 0.2003 - categorical_accuracy: 0.9633
 5120/13806 [==========>...................] - ETA: 19s - loss: 0.2000 - categorical_accuracy: 0.9635
 5248/13806 [==========>...................] - ETA: 19s - loss: 0.2003 - categorical_accuracy: 0.9636
 5376/13806 [==========>...................] - ETA: 19s - loss: 0.1994 - categorical_accuracy: 0.9639
 5504/13806 [==========>...................] - ETA: 18s - loss: 0.2001 - categorical_accuracy: 0.9635
 5632/13806 [===========>..................] - ETA: 18s - loss: 0.2001 - categorical_accuracy: 0.9638
 5760/13806 [===========>..................] - ETA: 18s - loss: 0.1989 - categorical_accuracy: 0.9642
 5888/13806 [===========>..................] - ETA: 18s - loss: 0.1999 - categorical_accuracy: 0.9640
 6016/13806 [============>.................] - ETA: 17s - loss: 0.1985 - categorical_accuracy: 0.9643
 6144/13806 [============>.................] - ETA: 17s - loss: 0.1981 - categorical_accuracy: 0.9639
 6272/13806 [============>.................] - ETA: 17s - loss: 0.1980 - categorical_accuracy: 0.9641
 6400/13806 [============>.................] - ETA: 16s - loss: 0.1992 - categorical_accuracy: 0.9636
 6528/13806 [=============>................] - ETA: 16s - loss: 0.1989 - categorical_accuracy: 0.9637
 6656/13806 [=============>................] - ETA: 16s - loss: 0.1996 - categorical_accuracy: 0.9633
 6784/13806 [=============>................] - ETA: 16s - loss: 0.1987 - categorical_accuracy: 0.9636
 6912/13806 [==============>...............] - ETA: 15s - loss: 0.1984 - categorical_accuracy: 0.9640
 7040/13806 [==============>...............] - ETA: 15s - loss: 0.1973 - categorical_accuracy: 0.9643
 7168/13806 [==============>...............] - ETA: 15s - loss: 0.1981 - categorical_accuracy: 0.9641
 7296/13806 [==============>...............] - ETA: 14s - loss: 0.1999 - categorical_accuracy: 0.9640
 7424/13806 [===============>..............] - ETA: 14s - loss: 0.2008 - categorical_accuracy: 0.9635
 7552/13806 [===============>..............] - ETA: 14s - loss: 0.2013 - categorical_accuracy: 0.9635
 7680/13806 [===============>..............] - ETA: 13s - loss: 0.2010 - categorical_accuracy: 0.9635
 7808/13806 [===============>..............] - ETA: 13s - loss: 0.2011 - categorical_accuracy: 0.9630
 7936/13806 [================>.............] - ETA: 13s - loss: 0.2006 - categorical_accuracy: 0.9635
 8064/13806 [================>.............] - ETA: 13s - loss: 0.1999 - categorical_accuracy: 0.9635
 8192/13806 [================>.............] - ETA: 12s - loss: 0.1998 - categorical_accuracy: 0.9635
 8320/13806 [=================>............] - ETA: 12s - loss: 0.1987 - categorical_accuracy: 0.9638
 8448/13806 [=================>............] - ETA: 12s - loss: 0.1984 - categorical_accuracy: 0.9639
 8576/13806 [=================>............] - ETA: 11s - loss: 0.1980 - categorical_accuracy: 0.9641
 8704/13806 [=================>............] - ETA: 11s - loss: 0.1975 - categorical_accuracy: 0.9643
 8832/13806 [==================>...........] - ETA: 11s - loss: 0.2001 - categorical_accuracy: 0.9637
 8960/13806 [==================>...........] - ETA: 11s - loss: 0.1992 - categorical_accuracy: 0.9640
 9088/13806 [==================>...........] - ETA: 10s - loss: 0.1989 - categorical_accuracy: 0.9640
 9216/13806 [===================>..........] - ETA: 10s - loss: 0.1986 - categorical_accuracy: 0.9639
 9344/13806 [===================>..........] - ETA: 10s - loss: 0.1986 - categorical_accuracy: 0.9641
 9472/13806 [===================>..........] - ETA: 9s - loss: 0.1999 - categorical_accuracy: 0.9639 
 9600/13806 [===================>..........] - ETA: 9s - loss: 0.2002 - categorical_accuracy: 0.9639
 9728/13806 [====================>.........] - ETA: 9s - loss: 0.2001 - categorical_accuracy: 0.9642
 9856/13806 [====================>.........] - ETA: 8s - loss: 0.1998 - categorical_accuracy: 0.9642
 9984/13806 [====================>.........] - ETA: 8s - loss: 0.1990 - categorical_accuracy: 0.9644
10112/13806 [====================>.........] - ETA: 8s - loss: 0.1987 - categorical_accuracy: 0.9645
10240/13806 [=====================>........] - ETA: 8s - loss: 0.1993 - categorical_accuracy: 0.9646
10368/13806 [=====================>........] - ETA: 7s - loss: 0.1998 - categorical_accuracy: 0.9643
10496/13806 [=====================>........] - ETA: 7s - loss: 0.2000 - categorical_accuracy: 0.9644
10624/13806 [======================>.......] - ETA: 7s - loss: 0.2004 - categorical_accuracy: 0.9645
10752/13806 [======================>.......] - ETA: 6s - loss: 0.2011 - categorical_accuracy: 0.9643
10880/13806 [======================>.......] - ETA: 6s - loss: 0.2010 - categorical_accuracy: 0.9644
11008/13806 [======================>.......] - ETA: 6s - loss: 0.2003 - categorical_accuracy: 0.9647
11136/13806 [=======================>......] - ETA: 6s - loss: 0.1998 - categorical_accuracy: 0.9649
11264/13806 [=======================>......] - ETA: 5s - loss: 0.1995 - categorical_accuracy: 0.9650
11392/13806 [=======================>......] - ETA: 5s - loss: 0.1997 - categorical_accuracy: 0.9651
11520/13806 [========================>.....] - ETA: 5s - loss: 0.1993 - categorical_accuracy: 0.9652
11648/13806 [========================>.....] - ETA: 4s - loss: 0.1992 - categorical_accuracy: 0.9652
11776/13806 [========================>.....] - ETA: 4s - loss: 0.1997 - categorical_accuracy: 0.9650
11904/13806 [========================>.....] - ETA: 4s - loss: 0.1998 - categorical_accuracy: 0.9650
12032/13806 [=========================>....] - ETA: 4s - loss: 0.1994 - categorical_accuracy: 0.9650
12160/13806 [=========================>....] - ETA: 3s - loss: 0.1999 - categorical_accuracy: 0.9649
12288/13806 [=========================>....] - ETA: 3s - loss: 0.2000 - categorical_accuracy: 0.9648
12416/13806 [=========================>....] - ETA: 3s - loss: 0.1996 - categorical_accuracy: 0.9650
12544/13806 [==========================>...] - ETA: 2s - loss: 0.1994 - categorical_accuracy: 0.9652
12672/13806 [==========================>...] - ETA: 2s - loss: 0.2001 - categorical_accuracy: 0.9650
12800/13806 [==========================>...] - ETA: 2s - loss: 0.1998 - categorical_accuracy: 0.9651
12928/13806 [===========================>..] - ETA: 2s - loss: 0.1993 - categorical_accuracy: 0.9652
13056/13806 [===========================>..] - ETA: 1s - loss: 0.2000 - categorical_accuracy: 0.9650
13184/13806 [===========================>..] - ETA: 1s - loss: 0.2010 - categorical_accuracy: 0.9647
13312/13806 [===========================>..] - ETA: 1s - loss: 0.2010 - categorical_accuracy: 0.9648
13440/13806 [============================>.] - ETA: 0s - loss: 0.2009 - categorical_accuracy: 0.9647
13568/13806 [============================>.] - ETA: 0s - loss: 0.2004 - categorical_accuracy: 0.9648
13696/13806 [============================>.] - ETA: 0s - loss: 0.2001 - categorical_accuracy: 0.9650
13806/13806 [==============================] - 33s 2ms/step - loss: 0.1996 - categorical_accuracy: 0.9652 - val_loss: 1.4735 - val_categorical_accuracy: 0.5388

Epoch 00008: val_categorical_accuracy did not improve
Epoch 9/15

  128/13806 [..............................] - ETA: 30s - loss: 0.1633 - categorical_accuracy: 0.9609
  256/13806 [..............................] - ETA: 30s - loss: 0.2282 - categorical_accuracy: 0.9531
  384/13806 [..............................] - ETA: 30s - loss: 0.2033 - categorical_accuracy: 0.9609
  512/13806 [>.............................] - ETA: 30s - loss: 0.2077 - categorical_accuracy: 0.9551
  640/13806 [>.............................] - ETA: 29s - loss: 0.2052 - categorical_accuracy: 0.9563
  768/13806 [>.............................] - ETA: 29s - loss: 0.2073 - categorical_accuracy: 0.9518
  896/13806 [>.............................] - ETA: 29s - loss: 0.2023 - categorical_accuracy: 0.9531
 1024/13806 [=>............................] - ETA: 29s - loss: 0.2015 - categorical_accuracy: 0.9551
 1152/13806 [=>............................] - ETA: 28s - loss: 0.2144 - categorical_accuracy: 0.9557
 1280/13806 [=>............................] - ETA: 28s - loss: 0.2121 - categorical_accuracy: 0.9578
 1408/13806 [==>...........................] - ETA: 28s - loss: 0.2056 - categorical_accuracy: 0.9595
 1536/13806 [==>...........................] - ETA: 27s - loss: 0.2006 - categorical_accuracy: 0.9603
 1664/13806 [==>...........................] - ETA: 27s - loss: 0.1967 - categorical_accuracy: 0.9621
 1792/13806 [==>...........................] - ETA: 27s - loss: 0.1960 - categorical_accuracy: 0.9626
 1920/13806 [===>..........................] - ETA: 27s - loss: 0.2001 - categorical_accuracy: 0.9620
 2048/13806 [===>..........................] - ETA: 26s - loss: 0.1953 - categorical_accuracy: 0.9634
 2176/13806 [===>..........................] - ETA: 26s - loss: 0.1907 - categorical_accuracy: 0.9651
 2304/13806 [====>.........................] - ETA: 26s - loss: 0.1933 - categorical_accuracy: 0.9640
 2432/13806 [====>.........................] - ETA: 25s - loss: 0.1945 - categorical_accuracy: 0.9638
 2560/13806 [====>.........................] - ETA: 25s - loss: 0.1986 - categorical_accuracy: 0.9629
 2688/13806 [====>.........................] - ETA: 25s - loss: 0.1953 - categorical_accuracy: 0.9639
 2816/13806 [=====>........................] - ETA: 25s - loss: 0.1950 - categorical_accuracy: 0.9641
 2944/13806 [=====>........................] - ETA: 24s - loss: 0.1932 - categorical_accuracy: 0.9643
 3072/13806 [=====>........................] - ETA: 24s - loss: 0.1949 - categorical_accuracy: 0.9639
 3200/13806 [=====>........................] - ETA: 24s - loss: 0.1956 - categorical_accuracy: 0.9641
 3328/13806 [======>.......................] - ETA: 23s - loss: 0.1949 - categorical_accuracy: 0.9639
 3456/13806 [======>.......................] - ETA: 23s - loss: 0.1945 - categorical_accuracy: 0.9635
 3584/13806 [======>.......................] - ETA: 23s - loss: 0.1958 - categorical_accuracy: 0.9637
 3712/13806 [=======>......................] - ETA: 23s - loss: 0.1934 - categorical_accuracy: 0.9650
 3840/13806 [=======>......................] - ETA: 22s - loss: 0.1931 - categorical_accuracy: 0.9651
 3968/13806 [=======>......................] - ETA: 22s - loss: 0.1973 - categorical_accuracy: 0.9647
 4096/13806 [=======>......................] - ETA: 22s - loss: 0.1981 - categorical_accuracy: 0.9639
 4224/13806 [========>.....................] - ETA: 22s - loss: 0.1978 - categorical_accuracy: 0.9643
 4352/13806 [========>.....................] - ETA: 21s - loss: 0.1985 - categorical_accuracy: 0.9637
 4480/13806 [========>.....................] - ETA: 21s - loss: 0.1987 - categorical_accuracy: 0.9638
 4608/13806 [=========>....................] - ETA: 21s - loss: 0.1988 - categorical_accuracy: 0.9638
 4736/13806 [=========>....................] - ETA: 21s - loss: 0.1994 - categorical_accuracy: 0.9628
 4864/13806 [=========>....................] - ETA: 20s - loss: 0.1986 - categorical_accuracy: 0.9632
 4992/13806 [=========>....................] - ETA: 20s - loss: 0.1995 - categorical_accuracy: 0.9627
 5120/13806 [==========>...................] - ETA: 20s - loss: 0.1984 - categorical_accuracy: 0.9633
 5248/13806 [==========>...................] - ETA: 19s - loss: 0.1979 - categorical_accuracy: 0.9634
 5376/13806 [==========>...................] - ETA: 19s - loss: 0.1997 - categorical_accuracy: 0.9628
 5504/13806 [==========>...................] - ETA: 19s - loss: 0.1982 - categorical_accuracy: 0.9631
 5632/13806 [===========>..................] - ETA: 18s - loss: 0.1980 - categorical_accuracy: 0.9631
 5760/13806 [===========>..................] - ETA: 18s - loss: 0.1982 - categorical_accuracy: 0.9630
 5888/13806 [===========>..................] - ETA: 18s - loss: 0.1994 - categorical_accuracy: 0.9630
 6016/13806 [============>.................] - ETA: 17s - loss: 0.1983 - categorical_accuracy: 0.9633
 6144/13806 [============>.................] - ETA: 17s - loss: 0.1974 - categorical_accuracy: 0.9635
 6272/13806 [============>.................] - ETA: 17s - loss: 0.1965 - categorical_accuracy: 0.9638
 6400/13806 [============>.................] - ETA: 17s - loss: 0.1962 - categorical_accuracy: 0.9639
 6528/13806 [=============>................] - ETA: 16s - loss: 0.1959 - categorical_accuracy: 0.9643
 6656/13806 [=============>................] - ETA: 16s - loss: 0.1956 - categorical_accuracy: 0.9642
 6784/13806 [=============>................] - ETA: 16s - loss: 0.1950 - categorical_accuracy: 0.9642
 6912/13806 [==============>...............] - ETA: 15s - loss: 0.1949 - categorical_accuracy: 0.9641
 7040/13806 [==============>...............] - ETA: 15s - loss: 0.1954 - categorical_accuracy: 0.9641
 7168/13806 [==============>...............] - ETA: 15s - loss: 0.1956 - categorical_accuracy: 0.9644
 7296/13806 [==============>...............] - ETA: 14s - loss: 0.1955 - categorical_accuracy: 0.9645
 7424/13806 [===============>..............] - ETA: 14s - loss: 0.1942 - categorical_accuracy: 0.9651
 7552/13806 [===============>..............] - ETA: 14s - loss: 0.1944 - categorical_accuracy: 0.9650
 7680/13806 [===============>..............] - ETA: 14s - loss: 0.1952 - categorical_accuracy: 0.9646
 7808/13806 [===============>..............] - ETA: 13s - loss: 0.1943 - categorical_accuracy: 0.9649
 7936/13806 [================>.............] - ETA: 13s - loss: 0.1946 - categorical_accuracy: 0.9648
 8064/13806 [================>.............] - ETA: 13s - loss: 0.1952 - categorical_accuracy: 0.9647
 8192/13806 [================>.............] - ETA: 12s - loss: 0.1945 - categorical_accuracy: 0.9651
 8320/13806 [=================>............] - ETA: 12s - loss: 0.1938 - categorical_accuracy: 0.9655
 8448/13806 [=================>............] - ETA: 12s - loss: 0.1939 - categorical_accuracy: 0.9653
 8576/13806 [=================>............] - ETA: 12s - loss: 0.1935 - categorical_accuracy: 0.9655
 8704/13806 [=================>............] - ETA: 11s - loss: 0.1939 - categorical_accuracy: 0.9652
 8832/13806 [==================>...........] - ETA: 11s - loss: 0.1940 - categorical_accuracy: 0.9649
 8960/13806 [==================>...........] - ETA: 11s - loss: 0.1941 - categorical_accuracy: 0.9646
 9088/13806 [==================>...........] - ETA: 10s - loss: 0.1935 - categorical_accuracy: 0.9647
 9216/13806 [===================>..........] - ETA: 10s - loss: 0.1943 - categorical_accuracy: 0.9646
 9344/13806 [===================>..........] - ETA: 10s - loss: 0.1952 - categorical_accuracy: 0.9644
 9472/13806 [===================>..........] - ETA: 9s - loss: 0.1947 - categorical_accuracy: 0.9644 
 9600/13806 [===================>..........] - ETA: 9s - loss: 0.1955 - categorical_accuracy: 0.9645
 9728/13806 [====================>.........] - ETA: 9s - loss: 0.1952 - categorical_accuracy: 0.9645
 9856/13806 [====================>.........] - ETA: 9s - loss: 0.1947 - categorical_accuracy: 0.9648
 9984/13806 [====================>.........] - ETA: 8s - loss: 0.1952 - categorical_accuracy: 0.9643
10112/13806 [====================>.........] - ETA: 8s - loss: 0.1972 - categorical_accuracy: 0.9644
10240/13806 [=====================>........] - ETA: 8s - loss: 0.1969 - categorical_accuracy: 0.9644
10368/13806 [=====================>........] - ETA: 7s - loss: 0.1967 - categorical_accuracy: 0.9642
10496/13806 [=====================>........] - ETA: 7s - loss: 0.1966 - categorical_accuracy: 0.9641
10624/13806 [======================>.......] - ETA: 7s - loss: 0.1967 - categorical_accuracy: 0.9639
10752/13806 [======================>.......] - ETA: 7s - loss: 0.1982 - categorical_accuracy: 0.9637
10880/13806 [======================>.......] - ETA: 6s - loss: 0.1979 - categorical_accuracy: 0.9639
11008/13806 [======================>.......] - ETA: 6s - loss: 0.1978 - categorical_accuracy: 0.9639
11136/13806 [=======================>......] - ETA: 6s - loss: 0.1984 - categorical_accuracy: 0.9637
11264/13806 [=======================>......] - ETA: 5s - loss: 0.1982 - categorical_accuracy: 0.9638
11392/13806 [=======================>......] - ETA: 5s - loss: 0.1979 - categorical_accuracy: 0.9639
11520/13806 [========================>.....] - ETA: 5s - loss: 0.1986 - categorical_accuracy: 0.9635
11648/13806 [========================>.....] - ETA: 4s - loss: 0.1980 - categorical_accuracy: 0.9638
11776/13806 [========================>.....] - ETA: 4s - loss: 0.1976 - categorical_accuracy: 0.9637
11904/13806 [========================>.....] - ETA: 4s - loss: 0.1978 - categorical_accuracy: 0.9639
12032/13806 [=========================>....] - ETA: 4s - loss: 0.1993 - categorical_accuracy: 0.9633
12160/13806 [=========================>....] - ETA: 3s - loss: 0.1991 - categorical_accuracy: 0.9632
12288/13806 [=========================>....] - ETA: 3s - loss: 0.1991 - categorical_accuracy: 0.9634
12416/13806 [=========================>....] - ETA: 3s - loss: 0.1988 - categorical_accuracy: 0.9637
12544/13806 [==========================>...] - ETA: 2s - loss: 0.1985 - categorical_accuracy: 0.9638
12672/13806 [==========================>...] - ETA: 2s - loss: 0.1984 - categorical_accuracy: 0.9640
12800/13806 [==========================>...] - ETA: 2s - loss: 0.1979 - categorical_accuracy: 0.9642
12928/13806 [===========================>..] - ETA: 2s - loss: 0.1976 - categorical_accuracy: 0.9643
13056/13806 [===========================>..] - ETA: 1s - loss: 0.1980 - categorical_accuracy: 0.9642
13184/13806 [===========================>..] - ETA: 1s - loss: 0.1984 - categorical_accuracy: 0.9637
13312/13806 [===========================>..] - ETA: 1s - loss: 0.1979 - categorical_accuracy: 0.9639
13440/13806 [============================>.] - ETA: 0s - loss: 0.1978 - categorical_accuracy: 0.9641
13568/13806 [============================>.] - ETA: 0s - loss: 0.1974 - categorical_accuracy: 0.9643
13696/13806 [============================>.] - ETA: 0s - loss: 0.1977 - categorical_accuracy: 0.9640
13806/13806 [==============================] - 33s 2ms/step - loss: 0.1977 - categorical_accuracy: 0.9639 - val_loss: 1.4948 - val_categorical_accuracy: 0.5368

Epoch 00009: val_categorical_accuracy did not improve
Epoch 10/15

  128/13806 [..............................] - ETA: 31s - loss: 0.1753 - categorical_accuracy: 0.9531
  256/13806 [..............................] - ETA: 30s - loss: 0.2497 - categorical_accuracy: 0.9492
  384/13806 [..............................] - ETA: 30s - loss: 0.2281 - categorical_accuracy: 0.9557
  512/13806 [>.............................] - ETA: 29s - loss: 0.2099 - categorical_accuracy: 0.9590
  640/13806 [>.............................] - ETA: 29s - loss: 0.2040 - categorical_accuracy: 0.9625
  768/13806 [>.............................] - ETA: 29s - loss: 0.1963 - categorical_accuracy: 0.9622
  896/13806 [>.............................] - ETA: 29s - loss: 0.2087 - categorical_accuracy: 0.9621
 1024/13806 [=>............................] - ETA: 29s - loss: 0.2072 - categorical_accuracy: 0.9609
 1152/13806 [=>............................] - ETA: 28s - loss: 0.1971 - categorical_accuracy: 0.9635
 1280/13806 [=>............................] - ETA: 28s - loss: 0.1966 - categorical_accuracy: 0.9641
 1408/13806 [==>...........................] - ETA: 28s - loss: 0.1907 - categorical_accuracy: 0.9652
 1536/13806 [==>...........................] - ETA: 27s - loss: 0.1870 - categorical_accuracy: 0.9655
 1664/13806 [==>...........................] - ETA: 27s - loss: 0.1936 - categorical_accuracy: 0.9621
 1792/13806 [==>...........................] - ETA: 27s - loss: 0.1909 - categorical_accuracy: 0.9632
 1920/13806 [===>..........................] - ETA: 27s - loss: 0.1878 - categorical_accuracy: 0.9635
 2048/13806 [===>..........................] - ETA: 26s - loss: 0.1855 - categorical_accuracy: 0.9644
 2176/13806 [===>..........................] - ETA: 26s - loss: 0.1842 - categorical_accuracy: 0.9651
 2304/13806 [====>.........................] - ETA: 26s - loss: 0.1869 - categorical_accuracy: 0.9622
 2432/13806 [====>.........................] - ETA: 26s - loss: 0.1847 - categorical_accuracy: 0.9634
 2560/13806 [====>.........................] - ETA: 25s - loss: 0.1878 - categorical_accuracy: 0.9637
 2688/13806 [====>.........................] - ETA: 25s - loss: 0.1928 - categorical_accuracy: 0.9628
 2816/13806 [=====>........................] - ETA: 25s - loss: 0.1915 - categorical_accuracy: 0.9638
 2944/13806 [=====>........................] - ETA: 24s - loss: 0.1894 - categorical_accuracy: 0.9643
 3072/13806 [=====>........................] - ETA: 24s - loss: 0.1880 - categorical_accuracy: 0.9645
 3200/13806 [=====>........................] - ETA: 24s - loss: 0.1913 - categorical_accuracy: 0.9644
 3328/13806 [======>.......................] - ETA: 23s - loss: 0.1890 - categorical_accuracy: 0.9651
 3456/13806 [======>.......................] - ETA: 23s - loss: 0.1883 - categorical_accuracy: 0.9650
 3584/13806 [======>.......................] - ETA: 23s - loss: 0.1879 - categorical_accuracy: 0.9651
 3712/13806 [=======>......................] - ETA: 23s - loss: 0.1860 - categorical_accuracy: 0.9661
 3840/13806 [=======>......................] - ETA: 22s - loss: 0.1843 - categorical_accuracy: 0.9667
 3968/13806 [=======>......................] - ETA: 22s - loss: 0.1851 - categorical_accuracy: 0.9670
 4096/13806 [=======>......................] - ETA: 22s - loss: 0.1851 - categorical_accuracy: 0.9666
 4224/13806 [========>.....................] - ETA: 21s - loss: 0.1868 - categorical_accuracy: 0.9666
 4352/13806 [========>.....................] - ETA: 21s - loss: 0.1870 - categorical_accuracy: 0.9665
 4480/13806 [========>.....................] - ETA: 21s - loss: 0.1885 - categorical_accuracy: 0.9661
 4608/13806 [=========>....................] - ETA: 20s - loss: 0.1870 - categorical_accuracy: 0.9664
 4736/13806 [=========>....................] - ETA: 20s - loss: 0.1875 - categorical_accuracy: 0.9656
 4864/13806 [=========>....................] - ETA: 20s - loss: 0.1867 - categorical_accuracy: 0.9655
 4992/13806 [=========>....................] - ETA: 20s - loss: 0.1858 - categorical_accuracy: 0.9657
 5120/13806 [==========>...................] - ETA: 19s - loss: 0.1859 - categorical_accuracy: 0.9658
 5248/13806 [==========>...................] - ETA: 19s - loss: 0.1860 - categorical_accuracy: 0.9661
 5376/13806 [==========>...................] - ETA: 19s - loss: 0.1856 - categorical_accuracy: 0.9660
 5504/13806 [==========>...................] - ETA: 18s - loss: 0.1848 - categorical_accuracy: 0.9660
 5632/13806 [===========>..................] - ETA: 18s - loss: 0.1839 - categorical_accuracy: 0.9664
 5760/13806 [===========>..................] - ETA: 18s - loss: 0.1835 - categorical_accuracy: 0.9665
 5888/13806 [===========>..................] - ETA: 18s - loss: 0.1857 - categorical_accuracy: 0.9662
 6016/13806 [============>.................] - ETA: 17s - loss: 0.1866 - categorical_accuracy: 0.9661
 6144/13806 [============>.................] - ETA: 17s - loss: 0.1872 - categorical_accuracy: 0.9658
 6272/13806 [============>.................] - ETA: 17s - loss: 0.1879 - categorical_accuracy: 0.9657
 6400/13806 [============>.................] - ETA: 16s - loss: 0.1879 - categorical_accuracy: 0.9653
 6528/13806 [=============>................] - ETA: 16s - loss: 0.1878 - categorical_accuracy: 0.9655
 6656/13806 [=============>................] - ETA: 16s - loss: 0.1880 - categorical_accuracy: 0.9656
 6784/13806 [=============>................] - ETA: 16s - loss: 0.1865 - categorical_accuracy: 0.9662
 6912/13806 [==============>...............] - ETA: 15s - loss: 0.1877 - categorical_accuracy: 0.9657
 7040/13806 [==============>...............] - ETA: 15s - loss: 0.1866 - categorical_accuracy: 0.9661
 7168/13806 [==============>...............] - ETA: 15s - loss: 0.1875 - categorical_accuracy: 0.9662
 7296/13806 [==============>...............] - ETA: 14s - loss: 0.1867 - categorical_accuracy: 0.9663
 7424/13806 [===============>..............] - ETA: 14s - loss: 0.1860 - categorical_accuracy: 0.9663
 7552/13806 [===============>..............] - ETA: 14s - loss: 0.1887 - categorical_accuracy: 0.9657
 7680/13806 [===============>..............] - ETA: 14s - loss: 0.1899 - categorical_accuracy: 0.9655
 7808/13806 [===============>..............] - ETA: 13s - loss: 0.1904 - categorical_accuracy: 0.9655
 7936/13806 [================>.............] - ETA: 13s - loss: 0.1919 - categorical_accuracy: 0.9657
 8064/13806 [================>.............] - ETA: 13s - loss: 0.1918 - categorical_accuracy: 0.9655
 8192/13806 [================>.............] - ETA: 12s - loss: 0.1920 - categorical_accuracy: 0.9651
 8320/13806 [=================>............] - ETA: 12s - loss: 0.1913 - categorical_accuracy: 0.9651
 8448/13806 [=================>............] - ETA: 12s - loss: 0.1909 - categorical_accuracy: 0.9653
 8576/13806 [=================>............] - ETA: 11s - loss: 0.1915 - categorical_accuracy: 0.9655
 8704/13806 [=================>............] - ETA: 11s - loss: 0.1918 - categorical_accuracy: 0.9653
 8832/13806 [==================>...........] - ETA: 11s - loss: 0.1918 - categorical_accuracy: 0.9656
 8960/13806 [==================>...........] - ETA: 11s - loss: 0.1931 - categorical_accuracy: 0.9654
 9088/13806 [==================>...........] - ETA: 10s - loss: 0.1940 - categorical_accuracy: 0.9647
 9216/13806 [===================>..........] - ETA: 10s - loss: 0.1936 - categorical_accuracy: 0.9646
 9344/13806 [===================>..........] - ETA: 10s - loss: 0.1935 - categorical_accuracy: 0.9647
 9472/13806 [===================>..........] - ETA: 9s - loss: 0.1949 - categorical_accuracy: 0.9642 
 9600/13806 [===================>..........] - ETA: 9s - loss: 0.1942 - categorical_accuracy: 0.9645
 9728/13806 [====================>.........] - ETA: 9s - loss: 0.1938 - categorical_accuracy: 0.9644
 9856/13806 [====================>.........] - ETA: 9s - loss: 0.1937 - categorical_accuracy: 0.9644
 9984/13806 [====================>.........] - ETA: 8s - loss: 0.1930 - categorical_accuracy: 0.9645
10112/13806 [====================>.........] - ETA: 8s - loss: 0.1940 - categorical_accuracy: 0.9645
10240/13806 [=====================>........] - ETA: 8s - loss: 0.1949 - categorical_accuracy: 0.9643
10368/13806 [=====================>........] - ETA: 7s - loss: 0.1940 - categorical_accuracy: 0.9645
10496/13806 [=====================>........] - ETA: 7s - loss: 0.1938 - categorical_accuracy: 0.9645
10624/13806 [======================>.......] - ETA: 7s - loss: 0.1938 - categorical_accuracy: 0.9643
10752/13806 [======================>.......] - ETA: 7s - loss: 0.1936 - categorical_accuracy: 0.9641
10880/13806 [======================>.......] - ETA: 6s - loss: 0.1932 - categorical_accuracy: 0.9643
11008/13806 [======================>.......] - ETA: 6s - loss: 0.1934 - categorical_accuracy: 0.9642
11136/13806 [=======================>......] - ETA: 6s - loss: 0.1941 - categorical_accuracy: 0.9643
11264/13806 [=======================>......] - ETA: 5s - loss: 0.1936 - categorical_accuracy: 0.9642
11392/13806 [=======================>......] - ETA: 5s - loss: 0.1941 - categorical_accuracy: 0.9639
11520/13806 [========================>.....] - ETA: 5s - loss: 0.1935 - categorical_accuracy: 0.9641
11648/13806 [========================>.....] - ETA: 4s - loss: 0.1928 - categorical_accuracy: 0.9645
11776/13806 [========================>.....] - ETA: 4s - loss: 0.1923 - categorical_accuracy: 0.9645
11904/13806 [========================>.....] - ETA: 4s - loss: 0.1926 - categorical_accuracy: 0.9646
12032/13806 [=========================>....] - ETA: 4s - loss: 0.1927 - categorical_accuracy: 0.9646
12160/13806 [=========================>....] - ETA: 3s - loss: 0.1923 - categorical_accuracy: 0.9646
12288/13806 [=========================>....] - ETA: 3s - loss: 0.1916 - categorical_accuracy: 0.9648
12416/13806 [=========================>....] - ETA: 3s - loss: 0.1920 - categorical_accuracy: 0.9647
12544/13806 [==========================>...] - ETA: 2s - loss: 0.1925 - categorical_accuracy: 0.9647
12672/13806 [==========================>...] - ETA: 2s - loss: 0.1919 - categorical_accuracy: 0.9650
12800/13806 [==========================>...] - ETA: 2s - loss: 0.1917 - categorical_accuracy: 0.9652
12928/13806 [===========================>..] - ETA: 2s - loss: 0.1917 - categorical_accuracy: 0.9652
13056/13806 [===========================>..] - ETA: 1s - loss: 0.1920 - categorical_accuracy: 0.9652
13184/13806 [===========================>..] - ETA: 1s - loss: 0.1924 - categorical_accuracy: 0.9651
13312/13806 [===========================>..] - ETA: 1s - loss: 0.1919 - categorical_accuracy: 0.9651
13440/13806 [============================>.] - ETA: 0s - loss: 0.1927 - categorical_accuracy: 0.9650
13568/13806 [============================>.] - ETA: 0s - loss: 0.1923 - categorical_accuracy: 0.9651
13696/13806 [============================>.] - ETA: 0s - loss: 0.1926 - categorical_accuracy: 0.9652
13806/13806 [==============================] - 33s 2ms/step - loss: 0.1926 - categorical_accuracy: 0.9652 - val_loss: 1.4921 - val_categorical_accuracy: 0.5348

Epoch 00010: val_categorical_accuracy did not improve
Epoch 11/15

  128/13806 [..............................] - ETA: 30s - loss: 0.1823 - categorical_accuracy: 0.9688
  256/13806 [..............................] - ETA: 30s - loss: 0.1586 - categorical_accuracy: 0.9766
  384/13806 [..............................] - ETA: 31s - loss: 0.1623 - categorical_accuracy: 0.9766
  512/13806 [>.............................] - ETA: 30s - loss: 0.1713 - categorical_accuracy: 0.9707
  640/13806 [>.............................] - ETA: 30s - loss: 0.2132 - categorical_accuracy: 0.9672
  768/13806 [>.............................] - ETA: 30s - loss: 0.2183 - categorical_accuracy: 0.9648
  896/13806 [>.............................] - ETA: 29s - loss: 0.2041 - categorical_accuracy: 0.9688
 1024/13806 [=>............................] - ETA: 29s - loss: 0.2062 - categorical_accuracy: 0.9688
 1152/13806 [=>............................] - ETA: 29s - loss: 0.2109 - categorical_accuracy: 0.9688
 1280/13806 [=>............................] - ETA: 29s - loss: 0.2153 - categorical_accuracy: 0.9656
 1408/13806 [==>...........................] - ETA: 28s - loss: 0.2098 - categorical_accuracy: 0.9680
 1536/13806 [==>...........................] - ETA: 28s - loss: 0.2076 - categorical_accuracy: 0.9674
 1664/13806 [==>...........................] - ETA: 28s - loss: 0.2088 - categorical_accuracy: 0.9675
 1792/13806 [==>...........................] - ETA: 28s - loss: 0.2058 - categorical_accuracy: 0.9682
 1920/13806 [===>..........................] - ETA: 28s - loss: 0.2093 - categorical_accuracy: 0.9661
 2048/13806 [===>..........................] - ETA: 27s - loss: 0.2064 - categorical_accuracy: 0.9663
 2176/13806 [===>..........................] - ETA: 27s - loss: 0.2040 - categorical_accuracy: 0.9669
 2304/13806 [====>.........................] - ETA: 27s - loss: 0.2017 - categorical_accuracy: 0.9674
 2432/13806 [====>.........................] - ETA: 26s - loss: 0.1994 - categorical_accuracy: 0.9679
 2560/13806 [====>.........................] - ETA: 26s - loss: 0.1971 - categorical_accuracy: 0.9688
 2688/13806 [====>.........................] - ETA: 26s - loss: 0.1957 - categorical_accuracy: 0.9680
 2816/13806 [=====>........................] - ETA: 25s - loss: 0.1925 - categorical_accuracy: 0.9688
 2944/13806 [=====>........................] - ETA: 25s - loss: 0.1919 - categorical_accuracy: 0.9688
 3072/13806 [=====>........................] - ETA: 25s - loss: 0.1891 - categorical_accuracy: 0.9701
 3200/13806 [=====>........................] - ETA: 24s - loss: 0.1863 - categorical_accuracy: 0.9706
 3328/13806 [======>.......................] - ETA: 24s - loss: 0.1838 - categorical_accuracy: 0.9712
 3456/13806 [======>.......................] - ETA: 24s - loss: 0.1828 - categorical_accuracy: 0.9711
 3584/13806 [======>.......................] - ETA: 23s - loss: 0.1841 - categorical_accuracy: 0.9701
 3712/13806 [=======>......................] - ETA: 23s - loss: 0.1873 - categorical_accuracy: 0.9698
 3840/13806 [=======>......................] - ETA: 23s - loss: 0.1868 - categorical_accuracy: 0.9703
 3968/13806 [=======>......................] - ETA: 22s - loss: 0.1865 - categorical_accuracy: 0.9698
 4096/13806 [=======>......................] - ETA: 22s - loss: 0.1866 - categorical_accuracy: 0.9697
 4224/13806 [========>.....................] - ETA: 22s - loss: 0.1863 - categorical_accuracy: 0.9692
 4352/13806 [========>.....................] - ETA: 22s - loss: 0.1845 - categorical_accuracy: 0.9694
 4480/13806 [========>.....................] - ETA: 21s - loss: 0.1868 - categorical_accuracy: 0.9692
 4608/13806 [=========>....................] - ETA: 21s - loss: 0.1852 - categorical_accuracy: 0.9694
 4736/13806 [=========>....................] - ETA: 21s - loss: 0.1876 - categorical_accuracy: 0.9692
 4864/13806 [=========>....................] - ETA: 20s - loss: 0.1897 - categorical_accuracy: 0.9688
 4992/13806 [=========>....................] - ETA: 20s - loss: 0.1920 - categorical_accuracy: 0.9683
 5120/13806 [==========>...................] - ETA: 20s - loss: 0.1919 - categorical_accuracy: 0.9682
 5248/13806 [==========>...................] - ETA: 19s - loss: 0.1947 - categorical_accuracy: 0.9678
 5376/13806 [==========>...................] - ETA: 19s - loss: 0.1962 - categorical_accuracy: 0.9669
 5504/13806 [==========>...................] - ETA: 19s - loss: 0.1949 - categorical_accuracy: 0.9675
 5632/13806 [===========>..................] - ETA: 19s - loss: 0.1968 - categorical_accuracy: 0.9668
 5760/13806 [===========>..................] - ETA: 18s - loss: 0.1969 - categorical_accuracy: 0.9668
 5888/13806 [===========>..................] - ETA: 18s - loss: 0.1970 - categorical_accuracy: 0.9664
 6016/13806 [============>.................] - ETA: 18s - loss: 0.1964 - categorical_accuracy: 0.9664
 6144/13806 [============>.................] - ETA: 17s - loss: 0.1960 - categorical_accuracy: 0.9663
 6272/13806 [============>.................] - ETA: 17s - loss: 0.1949 - categorical_accuracy: 0.9667
 6400/13806 [============>.................] - ETA: 17s - loss: 0.1941 - categorical_accuracy: 0.9669
 6528/13806 [=============>................] - ETA: 16s - loss: 0.1939 - categorical_accuracy: 0.9669
 6656/13806 [=============>................] - ETA: 16s - loss: 0.1949 - categorical_accuracy: 0.9663
 6784/13806 [=============>................] - ETA: 16s - loss: 0.1937 - categorical_accuracy: 0.9667
 6912/13806 [==============>...............] - ETA: 16s - loss: 0.1938 - categorical_accuracy: 0.9663
 7040/13806 [==============>...............] - ETA: 15s - loss: 0.1932 - categorical_accuracy: 0.9665
 7168/13806 [==============>...............] - ETA: 15s - loss: 0.1936 - categorical_accuracy: 0.9664
 7296/13806 [==============>...............] - ETA: 15s - loss: 0.1934 - categorical_accuracy: 0.9666
 7424/13806 [===============>..............] - ETA: 14s - loss: 0.1925 - categorical_accuracy: 0.9667
 7552/13806 [===============>..............] - ETA: 14s - loss: 0.1934 - categorical_accuracy: 0.9664
 7680/13806 [===============>..............] - ETA: 14s - loss: 0.1938 - categorical_accuracy: 0.9664
 7808/13806 [===============>..............] - ETA: 14s - loss: 0.1943 - categorical_accuracy: 0.9662
 7936/13806 [================>.............] - ETA: 13s - loss: 0.1937 - categorical_accuracy: 0.9662
 8064/13806 [================>.............] - ETA: 13s - loss: 0.1960 - categorical_accuracy: 0.9659
 8192/13806 [================>.............] - ETA: 13s - loss: 0.1959 - categorical_accuracy: 0.9658
 8320/13806 [=================>............] - ETA: 12s - loss: 0.1957 - categorical_accuracy: 0.9659
 8448/13806 [=================>............] - ETA: 12s - loss: 0.1958 - categorical_accuracy: 0.9659
 8576/13806 [=================>............] - ETA: 12s - loss: 0.1951 - categorical_accuracy: 0.9662
 8704/13806 [=================>............] - ETA: 11s - loss: 0.1945 - categorical_accuracy: 0.9665
 8832/13806 [==================>...........] - ETA: 11s - loss: 0.1936 - categorical_accuracy: 0.9666
 8960/13806 [==================>...........] - ETA: 11s - loss: 0.1938 - categorical_accuracy: 0.9664
 9088/13806 [==================>...........] - ETA: 10s - loss: 0.1928 - categorical_accuracy: 0.9669
 9216/13806 [===================>..........] - ETA: 10s - loss: 0.1927 - categorical_accuracy: 0.9671
 9344/13806 [===================>..........] - ETA: 10s - loss: 0.1924 - categorical_accuracy: 0.9673
 9472/13806 [===================>..........] - ETA: 10s - loss: 0.1930 - categorical_accuracy: 0.9668
 9600/13806 [===================>..........] - ETA: 9s - loss: 0.1930 - categorical_accuracy: 0.9669 
 9728/13806 [====================>.........] - ETA: 9s - loss: 0.1930 - categorical_accuracy: 0.9670
 9856/13806 [====================>.........] - ETA: 9s - loss: 0.1949 - categorical_accuracy: 0.9666
 9984/13806 [====================>.........] - ETA: 8s - loss: 0.1941 - categorical_accuracy: 0.9668
10112/13806 [====================>.........] - ETA: 8s - loss: 0.1931 - categorical_accuracy: 0.9673
10240/13806 [=====================>........] - ETA: 8s - loss: 0.1938 - categorical_accuracy: 0.9671
10368/13806 [=====================>........] - ETA: 7s - loss: 0.1945 - categorical_accuracy: 0.9672
10496/13806 [=====================>........] - ETA: 7s - loss: 0.1952 - categorical_accuracy: 0.9669
10624/13806 [======================>.......] - ETA: 7s - loss: 0.1948 - categorical_accuracy: 0.9671
10752/13806 [======================>.......] - ETA: 7s - loss: 0.1944 - categorical_accuracy: 0.9673
10880/13806 [======================>.......] - ETA: 6s - loss: 0.1942 - categorical_accuracy: 0.9673
11008/13806 [======================>.......] - ETA: 6s - loss: 0.1939 - categorical_accuracy: 0.9674
11136/13806 [=======================>......] - ETA: 6s - loss: 0.1933 - categorical_accuracy: 0.9677
11264/13806 [=======================>......] - ETA: 5s - loss: 0.1930 - categorical_accuracy: 0.9676
11392/13806 [=======================>......] - ETA: 5s - loss: 0.1922 - categorical_accuracy: 0.9679
11520/13806 [========================>.....] - ETA: 5s - loss: 0.1939 - categorical_accuracy: 0.9670
11648/13806 [========================>.....] - ETA: 5s - loss: 0.1938 - categorical_accuracy: 0.9669
11776/13806 [========================>.....] - ETA: 4s - loss: 0.1938 - categorical_accuracy: 0.9666
11904/13806 [========================>.....] - ETA: 4s - loss: 0.1934 - categorical_accuracy: 0.9666
12032/13806 [=========================>....] - ETA: 4s - loss: 0.1932 - categorical_accuracy: 0.9667
12160/13806 [=========================>....] - ETA: 3s - loss: 0.1937 - categorical_accuracy: 0.9666
12288/13806 [=========================>....] - ETA: 3s - loss: 0.1935 - categorical_accuracy: 0.9664
12416/13806 [=========================>....] - ETA: 3s - loss: 0.1928 - categorical_accuracy: 0.9666
12544/13806 [==========================>...] - ETA: 2s - loss: 0.1927 - categorical_accuracy: 0.9667
12672/13806 [==========================>...] - ETA: 2s - loss: 0.1930 - categorical_accuracy: 0.9667
12800/13806 [==========================>...] - ETA: 2s - loss: 0.1923 - categorical_accuracy: 0.9669
12928/13806 [===========================>..] - ETA: 2s - loss: 0.1921 - categorical_accuracy: 0.9669
13056/13806 [===========================>..] - ETA: 1s - loss: 0.1923 - categorical_accuracy: 0.9668
13184/13806 [===========================>..] - ETA: 1s - loss: 0.1921 - categorical_accuracy: 0.9669
13312/13806 [===========================>..] - ETA: 1s - loss: 0.1923 - categorical_accuracy: 0.9669
13440/13806 [============================>.] - ETA: 0s - loss: 0.1928 - categorical_accuracy: 0.9667
13568/13806 [============================>.] - ETA: 0s - loss: 0.1930 - categorical_accuracy: 0.9667
13696/13806 [============================>.] - ETA: 0s - loss: 0.1929 - categorical_accuracy: 0.9668
13806/13806 [==============================] - 33s 2ms/step - loss: 0.1927 - categorical_accuracy: 0.9668 - val_loss: 1.5105 - val_categorical_accuracy: 0.5335

Epoch 00011: val_categorical_accuracy did not improve
Epoch 12/15

  128/13806 [..............................] - ETA: 30s - loss: 0.2479 - categorical_accuracy: 0.9609
  256/13806 [..............................] - ETA: 30s - loss: 0.2044 - categorical_accuracy: 0.9648
  384/13806 [..............................] - ETA: 30s - loss: 0.2014 - categorical_accuracy: 0.9661
  512/13806 [>.............................] - ETA: 30s - loss: 0.1945 - categorical_accuracy: 0.9668
  640/13806 [>.............................] - ETA: 29s - loss: 0.2162 - categorical_accuracy: 0.9656
  768/13806 [>.............................] - ETA: 29s - loss: 0.2166 - categorical_accuracy: 0.9648
  896/13806 [>.............................] - ETA: 29s - loss: 0.2166 - categorical_accuracy: 0.9676
 1024/13806 [=>............................] - ETA: 28s - loss: 0.2133 - categorical_accuracy: 0.9678
 1152/13806 [=>............................] - ETA: 29s - loss: 0.2054 - categorical_accuracy: 0.9688
 1280/13806 [=>............................] - ETA: 28s - loss: 0.2011 - categorical_accuracy: 0.9703
 1408/13806 [==>...........................] - ETA: 29s - loss: 0.1944 - categorical_accuracy: 0.9723
 1536/13806 [==>...........................] - ETA: 28s - loss: 0.1966 - categorical_accuracy: 0.9720
 1664/13806 [==>...........................] - ETA: 28s - loss: 0.1984 - categorical_accuracy: 0.9706
 1792/13806 [==>...........................] - ETA: 28s - loss: 0.1957 - categorical_accuracy: 0.9704
 1920/13806 [===>..........................] - ETA: 27s - loss: 0.1933 - categorical_accuracy: 0.9708
 2048/13806 [===>..........................] - ETA: 27s - loss: 0.1900 - categorical_accuracy: 0.9717
 2176/13806 [===>..........................] - ETA: 27s - loss: 0.1908 - categorical_accuracy: 0.9701
 2304/13806 [====>.........................] - ETA: 26s - loss: 0.1969 - categorical_accuracy: 0.9683
 2432/13806 [====>.........................] - ETA: 26s - loss: 0.1968 - categorical_accuracy: 0.9679
 2560/13806 [====>.........................] - ETA: 25s - loss: 0.1973 - categorical_accuracy: 0.9688
 2688/13806 [====>.........................] - ETA: 25s - loss: 0.1996 - categorical_accuracy: 0.9665
 2816/13806 [=====>........................] - ETA: 25s - loss: 0.2007 - categorical_accuracy: 0.9652
 2944/13806 [=====>........................] - ETA: 25s - loss: 0.1981 - categorical_accuracy: 0.9657
 3072/13806 [=====>........................] - ETA: 24s - loss: 0.1987 - categorical_accuracy: 0.9652
 3200/13806 [=====>........................] - ETA: 24s - loss: 0.1958 - categorical_accuracy: 0.9663
 3328/13806 [======>.......................] - ETA: 24s - loss: 0.1934 - categorical_accuracy: 0.9669
 3456/13806 [======>.......................] - ETA: 23s - loss: 0.1917 - categorical_accuracy: 0.9676
 3584/13806 [======>.......................] - ETA: 23s - loss: 0.1905 - categorical_accuracy: 0.9676
 3712/13806 [=======>......................] - ETA: 23s - loss: 0.1920 - categorical_accuracy: 0.9679
 3840/13806 [=======>......................] - ETA: 23s - loss: 0.1914 - categorical_accuracy: 0.9682
 3968/13806 [=======>......................] - ETA: 22s - loss: 0.1923 - categorical_accuracy: 0.9675
 4096/13806 [=======>......................] - ETA: 22s - loss: 0.1951 - categorical_accuracy: 0.9663
 4224/13806 [========>.....................] - ETA: 22s - loss: 0.1953 - categorical_accuracy: 0.9664
 4352/13806 [========>.....................] - ETA: 21s - loss: 0.1932 - categorical_accuracy: 0.9671
 4480/13806 [========>.....................] - ETA: 21s - loss: 0.1958 - categorical_accuracy: 0.9663
 4608/13806 [=========>....................] - ETA: 21s - loss: 0.1959 - categorical_accuracy: 0.9664
 4736/13806 [=========>....................] - ETA: 20s - loss: 0.1965 - categorical_accuracy: 0.9660
 4864/13806 [=========>....................] - ETA: 20s - loss: 0.1958 - categorical_accuracy: 0.9659
 4992/13806 [=========>....................] - ETA: 20s - loss: 0.1953 - categorical_accuracy: 0.9659
 5120/13806 [==========>...................] - ETA: 20s - loss: 0.1940 - categorical_accuracy: 0.9666
 5248/13806 [==========>...................] - ETA: 19s - loss: 0.1925 - categorical_accuracy: 0.9670
 5376/13806 [==========>...................] - ETA: 19s - loss: 0.1923 - categorical_accuracy: 0.9665
 5504/13806 [==========>...................] - ETA: 19s - loss: 0.1923 - categorical_accuracy: 0.9666
 5632/13806 [===========>..................] - ETA: 18s - loss: 0.1930 - categorical_accuracy: 0.9666
 5760/13806 [===========>..................] - ETA: 18s - loss: 0.1920 - categorical_accuracy: 0.9665
 5888/13806 [===========>..................] - ETA: 18s - loss: 0.1918 - categorical_accuracy: 0.9669
 6016/13806 [============>.................] - ETA: 18s - loss: 0.1910 - categorical_accuracy: 0.9669
 6144/13806 [============>.................] - ETA: 17s - loss: 0.1913 - categorical_accuracy: 0.9670
 6272/13806 [============>.................] - ETA: 17s - loss: 0.1897 - categorical_accuracy: 0.9673
 6400/13806 [============>.................] - ETA: 17s - loss: 0.1894 - categorical_accuracy: 0.9673
 6528/13806 [=============>................] - ETA: 16s - loss: 0.1893 - categorical_accuracy: 0.9671
 6656/13806 [=============>................] - ETA: 16s - loss: 0.1893 - categorical_accuracy: 0.9672
 6784/13806 [=============>................] - ETA: 16s - loss: 0.1891 - categorical_accuracy: 0.9671
 6912/13806 [==============>...............] - ETA: 15s - loss: 0.1900 - categorical_accuracy: 0.9673
 7040/13806 [==============>...............] - ETA: 15s - loss: 0.1921 - categorical_accuracy: 0.9665
 7168/13806 [==============>...............] - ETA: 15s - loss: 0.1918 - categorical_accuracy: 0.9665
 7296/13806 [==============>...............] - ETA: 15s - loss: 0.1912 - categorical_accuracy: 0.9668
 7424/13806 [===============>..............] - ETA: 14s - loss: 0.1910 - categorical_accuracy: 0.9673
 7552/13806 [===============>..............] - ETA: 14s - loss: 0.1906 - categorical_accuracy: 0.9672
 7680/13806 [===============>..............] - ETA: 14s - loss: 0.1902 - categorical_accuracy: 0.9672
 7808/13806 [===============>..............] - ETA: 13s - loss: 0.1901 - categorical_accuracy: 0.9672
 7936/13806 [================>.............] - ETA: 13s - loss: 0.1904 - categorical_accuracy: 0.9671
 8064/13806 [================>.............] - ETA: 13s - loss: 0.1915 - categorical_accuracy: 0.9670
 8192/13806 [================>.............] - ETA: 13s - loss: 0.1912 - categorical_accuracy: 0.9673
 8320/13806 [=================>............] - ETA: 12s - loss: 0.1913 - categorical_accuracy: 0.9672
 8448/13806 [=================>............] - ETA: 12s - loss: 0.1909 - categorical_accuracy: 0.9673
 8576/13806 [=================>............] - ETA: 12s - loss: 0.1902 - categorical_accuracy: 0.9676
 8704/13806 [=================>............] - ETA: 11s - loss: 0.1907 - categorical_accuracy: 0.9676
 8832/13806 [==================>...........] - ETA: 11s - loss: 0.1904 - categorical_accuracy: 0.9677
 8960/13806 [==================>...........] - ETA: 11s - loss: 0.1899 - categorical_accuracy: 0.9679
 9088/13806 [==================>...........] - ETA: 10s - loss: 0.1910 - categorical_accuracy: 0.9676
 9216/13806 [===================>..........] - ETA: 10s - loss: 0.1905 - categorical_accuracy: 0.9678
 9344/13806 [===================>..........] - ETA: 10s - loss: 0.1903 - categorical_accuracy: 0.9676
 9472/13806 [===================>..........] - ETA: 10s - loss: 0.1897 - categorical_accuracy: 0.9678
 9600/13806 [===================>..........] - ETA: 9s - loss: 0.1892 - categorical_accuracy: 0.9680 
 9728/13806 [====================>.........] - ETA: 9s - loss: 0.1901 - categorical_accuracy: 0.9679
 9856/13806 [====================>.........] - ETA: 9s - loss: 0.1902 - categorical_accuracy: 0.9678
 9984/13806 [====================>.........] - ETA: 8s - loss: 0.1907 - categorical_accuracy: 0.9676
10112/13806 [====================>.........] - ETA: 8s - loss: 0.1909 - categorical_accuracy: 0.9676
10240/13806 [=====================>........] - ETA: 8s - loss: 0.1914 - categorical_accuracy: 0.9673
10368/13806 [=====================>........] - ETA: 7s - loss: 0.1917 - categorical_accuracy: 0.9671
10496/13806 [=====================>........] - ETA: 7s - loss: 0.1909 - categorical_accuracy: 0.9673
10624/13806 [======================>.......] - ETA: 7s - loss: 0.1916 - categorical_accuracy: 0.9672
10752/13806 [======================>.......] - ETA: 7s - loss: 0.1916 - categorical_accuracy: 0.9672
10880/13806 [======================>.......] - ETA: 6s - loss: 0.1927 - categorical_accuracy: 0.9671
11008/13806 [======================>.......] - ETA: 6s - loss: 0.1922 - categorical_accuracy: 0.9670
11136/13806 [=======================>......] - ETA: 6s - loss: 0.1918 - categorical_accuracy: 0.9672
11264/13806 [=======================>......] - ETA: 5s - loss: 0.1924 - categorical_accuracy: 0.9672
11392/13806 [=======================>......] - ETA: 5s - loss: 0.1916 - categorical_accuracy: 0.9676
11520/13806 [========================>.....] - ETA: 5s - loss: 0.1913 - categorical_accuracy: 0.9674
11648/13806 [========================>.....] - ETA: 5s - loss: 0.1908 - categorical_accuracy: 0.9676
11776/13806 [========================>.....] - ETA: 4s - loss: 0.1918 - categorical_accuracy: 0.9673
11904/13806 [========================>.....] - ETA: 4s - loss: 0.1910 - categorical_accuracy: 0.9675
12032/13806 [=========================>....] - ETA: 4s - loss: 0.1910 - categorical_accuracy: 0.9675
12160/13806 [=========================>....] - ETA: 3s - loss: 0.1904 - categorical_accuracy: 0.9677
12288/13806 [=========================>....] - ETA: 3s - loss: 0.1906 - categorical_accuracy: 0.9674
12416/13806 [=========================>....] - ETA: 3s - loss: 0.1900 - categorical_accuracy: 0.9676
12544/13806 [==========================>...] - ETA: 2s - loss: 0.1910 - categorical_accuracy: 0.9675
12672/13806 [==========================>...] - ETA: 2s - loss: 0.1915 - categorical_accuracy: 0.9673
12800/13806 [==========================>...] - ETA: 2s - loss: 0.1918 - categorical_accuracy: 0.9670
12928/13806 [===========================>..] - ETA: 2s - loss: 0.1919 - categorical_accuracy: 0.9671
13056/13806 [===========================>..] - ETA: 1s - loss: 0.1915 - categorical_accuracy: 0.9671
13184/13806 [===========================>..] - ETA: 1s - loss: 0.1912 - categorical_accuracy: 0.9672
13312/13806 [===========================>..] - ETA: 1s - loss: 0.1925 - categorical_accuracy: 0.9669
13440/13806 [============================>.] - ETA: 0s - loss: 0.1920 - categorical_accuracy: 0.9670
13568/13806 [============================>.] - ETA: 0s - loss: 0.1914 - categorical_accuracy: 0.9673
13696/13806 [============================>.] - ETA: 0s - loss: 0.1911 - categorical_accuracy: 0.9673
13806/13806 [==============================] - 33s 2ms/step - loss: 0.1913 - categorical_accuracy: 0.9673 - val_loss: 1.5475 - val_categorical_accuracy: 0.5355
2018-03-23 14:43:54.286675: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1120] Creating TensorFlow device (/device:GPU:0) -> (device: 0, name: GeForce GTX 1080, pci bus id: 0000:04:00.0, compute capability: 6.1)
/home/michon/anaconda2/envs/py35/lib/python3.5/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  from ._conv import register_converters as _register_converters
Using TensorFlow backend.

Epoch 00012: val_categorical_accuracy did not improve
Epoch 00012: early stopping

Final evaluation

f1_score
 0.5264297286575974
accuracy_score
 0.5354539430086149

classification_report
              precision    recall  f1-score   support

        EGY       0.49      0.62      0.54       297
        GLF       0.45      0.52      0.48       259
        LAV       0.45      0.25      0.32       327
        MSA       0.65      0.76      0.70       280
        NOR       0.60      0.56      0.58       346

avg / total       0.53      0.54      0.52      1509


confusion_matrix
 [[183  28  37  23  26]
 [ 40 135  27  30  27]
 [ 71  71  82  41  62]
 [ 19  23  10 214  14]
 [ 63  42  25  22 194]]

Evaluation on best model

f1_score
 0.5387697749941923
accuracy_score
 0.5473823724320742

classification_report
              precision    recall  f1-score   support

        EGY       0.53      0.56      0.54       297
        GLF       0.52      0.49      0.50       259
        LAV       0.44      0.29      0.35       327
        MSA       0.63      0.75      0.68       280
        NOR       0.57      0.66      0.61       346

avg / total       0.54      0.55      0.54      1509


confusion_matrix
 [[165  18  53  30  31]
 [ 33 127  35  29  35]
 [ 54  53  96  45  79]
 [ 14  19  13 209  25]
 [ 47  29  23  18 229]]
Closing remaining open files:data/vardial2018/dataset.h5...done
############# train: DONE @ Fri Mar 23 14:43:57 CET 2018
